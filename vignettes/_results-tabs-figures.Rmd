---
title: "results-tabs"
output: html_document
---

```{r, include = FALSE}
# This is a child document meant to be included in other Rmd files
# Exit if being knit directly (not as a child)
if (!exists("dgm_names")) {
  message("This is a helper file that should be included as a child in other Rmd documents.")
  message("It requires 'dgm_names' to be defined in the parent document.")
  knitr::knit_exit()
}
```


#### Convergence

```{r fig.height = 8, echo=FALSE, warning=FALSE, fig.alt="Raincloud plot showing convergence rates across different methods"} 
create_raincloud_plot(this_results, "convergence", "Convergence", ylim_range = c(0, 1)) +
  scale_y_continuous(labels = scales::percent)
```

#### Bias

```{r fig.height = 8, echo=FALSE, warning=FALSE, fig.alt="Raincloud plot showing bias across different methods"} 
create_raincloud_plot(this_results, if (common_scale) "bias" else "bias_rank", if (common_scale) "Bias" else "Rank(Bias)" , ylim_range = if (common_scale) c(-0.5, 0.5), reference_line = if (common_scale) 0)
```

`r if (!common_scale) "Methods are compared using condition-wise ranks. Direct comparison using the average bias is not possible because the data generating mechanisms differ in the outcome scale. See the DGM-specific results (or subresults) to see the distribution of bias values on the corresponding outcome scale." else "Values lower than -0.5 or larger than 0.5 are visualized as -0.5 and 0.5 respectively."`

#### RMSE

```{r fig.height = 8, echo=FALSE, warning=FALSE, fig.alt="Raincloud plot showing RMSE (Root Mean Square Error) across different methods"} 
create_raincloud_plot(this_results, if (common_scale) "rmse" else "rmse_rank",  if (common_scale) "RMSE" else "Rank(RMSE)", ylim_range = if (common_scale) c(0, 0.5), reference_line = if (common_scale) 0)
```

`r if (!common_scale) "Methods are compared using condition-wise ranks. Direct comparison using the average RMSE is not possible because the data generating mechanisms differ in the outcome scale. See the DGM-specific results (or subresults) to see the distribution of RMSE values on the corresponding outcome scale." else "Values larger than 0.5 are visualized as 0.5."`

#### 95% CI Coverage

```{r fig.height = 8, echo=FALSE, warning=FALSE, fig.alt="Raincloud plot showing 95% confidence interval coverage across different methods"} 
create_raincloud_plot(this_results, "coverage", "95% CI Coverage", ylim_range = c(0, 1), reference_line = 0.95) +
  scale_y_continuous(labels = scales::percent)
```

#### CI Width

```{r fig.height = 8, echo=FALSE, warning=FALSE, fig.alt="Raincloud plot showing 95% confidence interval width across different methods"} 
create_raincloud_plot(this_results, "mean_ci_width", "CI Width")
```


#### Type I Error Rate

```{r fig.height = 8, echo=FALSE, warning=FALSE, fig.alt="Raincloud plot showing Type I Error rates across different methods"} 
create_raincloud_plot(this_results[this_results$H0,], "power", "Type I Error Rate", ylim_range = c(0, 1), reference_line = 0.05) +
  scale_y_continuous(labels = scales::percent)
```

#### Power

```{r fig.height = 8, echo=FALSE, warning=FALSE, fig.alt="Raincloud plot showing statistical power across different methods"} 
create_raincloud_plot(this_results[!this_results$H0,], "power", "Power", ylim_range = c(0, 1)) +
  scale_y_continuous(labels = scales::percent)
```

#### "Positive Likelihood Ratio"

```{r fig.height = 8, echo=FALSE, warning=FALSE, fig.alt="Raincloud plot showing positive likelihood ratio across different methods"} 
create_raincloud_plot(this_results[!this_results$H0,], "positive_likelihood_ratio", "Positive Likelihood Ratio")
```

#### Negative Likelihood Ratio

```{r fig.height = 8, echo=FALSE, warning=FALSE, fig.alt="Raincloud plot showing negative likelihood ratio across different methods"} 
create_raincloud_plot(this_results[!this_results$H0,], "negative_likelihood_ratio", "Negative Likelihood Ratio")
```
