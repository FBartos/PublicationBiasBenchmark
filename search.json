[{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_DGMs.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Adding New Data-Generating Mechanisms","text":"DGM package consists three key components: Main DGM function: Implements data-generating mechanism Validation function: Validates input parameters settings Conditions function: Defines pre-specified conditions three functions must implemented single file named dgm-{DGM_NAME}.R R/ directory.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_DGMs.html","id":"file-structure-and-naming","dir":"Articles","previous_headings":"","what":"File Structure and Naming","title":"Adding New Data-Generating Mechanisms","text":"DGM called “no_bias”, need create file named R/dgm-no_bias.R containing three functions: dgm.no_bias(): main data-generating mechanism implementation validate_dgm_setting.no_bias(): Parameter validation dgm_conditions.no_bias(): Pre-defined conditions naming pattern crucial package’s S3 method dispatch system work correctly.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_DGMs.html","id":"main-dgm-function-dgm-dgm_name","dir":"Articles","previous_headings":"","what":"1. Main DGM Function: dgm.{DGM_NAME}()","title":"Adding New Data-Generating Mechanisms","text":"core function implements data-generating mechanism. no_bias implementation example:","code":"#' @title Normal Unbiased Data-Generating Mechanism #' #' @description #' An example data-generating mechanism to simulate effect sizes without #' publication bias. #' #' @param dgm_name DGM name (automatically passed) #' @param settings List containing \\describe{ #'   \\item{mean_effect}{Mean effect} #'   \\item{heterogeneity}{Effect heterogeneity} #'   \\item{n_studies}{Number of effect size estimates} #' } #' #' #' @return Data frame with \\describe{ #'   \\item{yi}{effect size} #'   \\item{sei}{standard error} #' } #' #' @references #' \\insertAllCited{} #' #' @seealso [dgm()], [validate_dgm_setting()] #' @export dgm.no_bias <- function(dgm_name, settings) {    # Extract settings   n_studies     <- settings[[\"n_studies\"]]   mean_effect   <- settings[[\"mean_effect\"]]   heterogeneity <- settings[[\"heterogeneity\"]]    # Simulate sample sizes based on empirical distribution   N_shape <- 2   N_scale <- 58   N_low   <- 25   N_high  <- 500    N_seq <- seq(N_low, N_high, 1)   N_den <- stats::dnbinom(N_seq, size = N_shape, prob = 1/(N_scale+1)) /       (stats::pnbinom(N_high, size = N_shape, prob = 1/(N_scale+1)) -         stats::pnbinom(N_low - 1, size = N_shape, prob = 1/(N_scale+1)))    N <- sample(N_seq, n_studies, TRUE, N_den)    # Compute standard errors based on sample sizes (Cohen's d formula)   standard_errors <- sqrt(4/N)    # Simulate true effect sizes with heterogeneity   effect_sizes <- stats::rnorm(n_studies, mean_effect,                                sqrt(heterogeneity^2 + standard_errors^2))    # Return standardized data frame   data <- data.frame(     yi  = effect_sizes,     sei = standard_errors,     ni  = N   )    return(data) }"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_DGMs.html","id":"key-requirements-for-the-main-function","dir":"Articles","previous_headings":"1. Main DGM Function: dgm.{DGM_NAME}()","what":"Key Requirements for the Main Function:","title":"Adding New Data-Generating Mechanisms","text":"Input Parameters: dgm_name: Automatically passed framework settings: Named list containing DGM parameters condition_id value Output: Must return data frame required columns: yi: Effect sizes sei: Standard errors ni: Sample sizes es_type: Type effect size (e.g., “SMD”, “logOR”, “none”) Optional additional columns (commonly used): study_id: Unique identifier study/cluster (presence multilevel/clustered data)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_DGMs.html","id":"validation-function-validate_dgm_setting-dgm_name","dir":"Articles","previous_headings":"","what":"2. Validation Function: validate_dgm_setting.{DGM_NAME}()","title":"Adding New Data-Generating Mechanisms","text":"function validates required parameters provided valid values:","code":"#' @export validate_dgm_setting.no_bias <- function(dgm_name, settings) {    # Check that all required settings are specified   required_params <- c(\"n_studies\", \"mean_effect\", \"heterogeneity\")   missing_params <- setdiff(required_params, names(settings))   if (length(missing_params) > 0)     stop(\"Missing required settings: \", paste(missing_params, collapse = \", \"))    # Extract settings for validation   n_studies     <- settings[[\"n_studies\"]]   mean_effect   <- settings[[\"mean_effect\"]]   heterogeneity <- settings[[\"heterogeneity\"]]    # Validate each parameter   if (length(n_studies) != 1 || !is.numeric(n_studies) || is.na(n_studies) ||        !is.wholenumber(n_studies) || n_studies < 1)     stop(\"'n_studies' must be an integer larger than 0\")      if (length(mean_effect) != 1 || !is.numeric(mean_effect) || is.na(mean_effect))     stop(\"'mean_effect' must be numeric\")      if (length(heterogeneity) != 1 || !is.numeric(heterogeneity) ||        is.na(heterogeneity) || heterogeneity < 0)     stop(\"'heterogeneity' must be non-negative\")    return(invisible(TRUE)) }"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_DGMs.html","id":"key-points-for-validation","dir":"Articles","previous_headings":"2. Validation Function: validate_dgm_setting.{DGM_NAME}()","what":"Key Points for Validation:","title":"Adding New Data-Generating Mechanisms","text":"Check missing required parameters Validate parameter types (numeric, integer, character, etc.) Check parameter ranges constraints Provide clear, informative error messages Return invisible(TRUE) successful validation Use stop() validation failures","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_DGMs.html","id":"conditions-function-dgm_conditions-dgm_name","dir":"Articles","previous_headings":"","what":"3. Conditions Function: dgm_conditions.{DGM_NAME}()","title":"Adding New Data-Generating Mechanisms","text":"function defines pre-specified conditions benchmarking studies: Always add condition_id column unique identifiers. column used generating data pre-defined conditions. defined, settings changed retrospectively ensure reproducibility continuity benchmark.","code":"#' @export dgm_conditions.no_bias <- function(dgm_name) {    # Generate a grid of pre-specified settings   settings <- data.frame(expand.grid(     mean_effect    = c(0, 0.3),     heterogeneity  = c(0, 0.15),     n_studies      = c(10, 100)   ))    # Attach unique condition identifiers   settings$condition_id <- 1:nrow(settings)    return(settings) }"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_DGMs.html","id":"using-your-new-dgm","dir":"Articles","previous_headings":"","what":"Using Your New DGM","title":"Adding New Data-Generating Mechanisms","text":"implemented, DGM can used unified interface:","code":"# Use with custom settings data <- simulate_dgm(\"no_bias\", list(   mean_effect = 0.2,   heterogeneity = 0.1,   n_studies = 50 ))  # Use with pre-defined conditions data <- simulate_dgm(\"no_bias\", condition_id = 1)  # View available conditions conditions <- dgm_conditions(\"no_bias\") print(conditions)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_Methods.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Adding New Methods","text":"method package consists three key components: Main method function: Implements statistical method Settings function: Defines available method configurations Extra columns function: Specifies additional result columns three functions must implemented single file named method-{METHOD_NAME}.R R/ directory.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_Methods.html","id":"file-structure-and-naming","dir":"Articles","previous_headings":"","what":"File Structure and Naming","title":"Adding New Methods","text":"method called “PET”, need create file named R/method-PET.R containing three functions: method.PET(): main implementation method_settings.PET(): Available settings/configurations method_extra_columns.PET(): Additional result columns naming pattern crucial package’s S3 method dispatch system work correctly.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_Methods.html","id":"main-method-function-method-method_name","dir":"Articles","previous_headings":"","what":"1. Main Method Function: method.{METHOD_NAME}()","title":"Adding New Methods","text":"core function implements statistical method. PET implementation example:","code":"#' @title PET (Precision-Effect Test) Method #' #' @description #' Implements the Precision-Effect Test for publication bias correction. #' PET regresses effect sizes against standard errors to test for and correct #' publication bias. The intercept represents the bias-corrected effect size #' estimate. #' #' @param method_name Method name (automatically passed) #' @param data Data frame with yi (effect sizes) and sei (standard errors) #' @param settings List of method settings #' #' @return Data frame with PET results #' #' @export method.PET <- function(method_name, data, settings = NULL) {      # Extract data   effect_sizes    <- data$yi   standard_errors <- data$sei      # Input validation and error handling   if (length(effect_sizes) < 3)     stop(\"At least 3 estimates required for PET analysis\", call. = FALSE)      if (stats::var(standard_errors) <= 0)     stop(\"No variance in standard errors\", call. = FALSE)      # Implement the statistical method   pet_model <- stats::lm(effect_sizes ~ standard_errors,                          weights = 1/standard_errors^2)      # Extract and process results   coefficients    <- stats::coef(pet_model)   se_coefficients <- summary(pet_model)$coefficients[, \"Std. Error\"]   p_values        <- summary(pet_model)$coefficients[, \"Pr(>|t|)\"]      # Main estimates   estimate    <- coefficients[1]  # Intercept = bias-corrected effect   estimate_se <- se_coefficients[1]   estimate_p  <- p_values[1]      # Additional method-specific results   bias_coefficient <- coefficients[2]   bias_p_value     <- p_values[2]      # Calculate confidence intervals   estimate_lci <- estimate - 1.96 * estimate_se   estimate_uci <- estimate + 1.96 * estimate_se      # Return standardized results   return(data.frame(     method         = method_name,     estimate       = estimate,     standard_error = estimate_se,     ci_lower       = estimate_lci,     ci_upper       = estimate_uci,     p_value        = estimate_p,     BF             = NA,     convergence    = TRUE,     note           = NA,     # Method-specific columns     bias_coefficient = bias_coefficient,     bias_p_value     = bias_p_value   )) }"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_Methods.html","id":"key-requirements-for-the-main-function","dir":"Articles","previous_headings":"1. Main Method Function: method.{METHOD_NAME}()","what":"Key Requirements for the Main Function:","title":"Adding New Methods","text":"Input Parameters: method_name: Automatically passed framework data: Data frame yi (effect sizes), sei (standard errors), ni (sample sizes). settings: Optional list method-specific settings Output: Must return data frame required columns: method: Method name estimate: Meta-analytic effect size estimate standard_error: Standard error estimate ci_lower: Lower confidence interval bound (95%) ci_upper: Upper confidence interval bound (95%) p_value: P-value estimate BF: Bayes factor estimate convergence: Logical indicating successful convergence note: Character string notes method provide certain values (e.g., Bayes factor), use NA. Error Handling: Include input validation meaningful error messages Use stop() call. = FALSE user-friendly errors framework handles errors automatically - function can throw errors. package catch errors attach empty output convergence = FALSE error message note.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_Methods.html","id":"settings-function-method_settings-method_name","dir":"Articles","previous_headings":"","what":"2. Settings Function: method_settings.{METHOD_NAME}()","title":"Adding New Methods","text":"function defines available configurations method: selected settings passed main function settings parameter. , main function can use settings adjust behavior. defined, settings changed retrospectively ensure reproducibility continuity benchmark. example method defines several settings can examine random effects meta-analysis (RMA) method:","code":"#' @export method_settings.PET <- function(method_name) {      settings <- list(     \"default\" = list() # PET has no configurable settings   )      return(settings) } # Example with multiple settings (from RMA method) method_settings.RMA <- function(method_name) {      settings <- list(     \"default\" = list(       method = \"REML\",        test.uni = \"knha\",        test.mv = \"t\",        control = list(stepadj = 0.5, maxiter = 500)     )   )      return(settings) }"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_Methods.html","id":"extra-columns-function-method_extra_columns-method_name","dir":"Articles","previous_headings":"","what":"3. Extra Columns Function: method_extra_columns.{METHOD_NAME}()","title":"Adding New Methods","text":"function specifies additional columns method returns beyond required ones: column names must match exactly additional columns main function returns. columns included final output data frame alongside required columns guarantee results can merged case method fails error. Use character(0) c() method extra columns","code":"#' @export method_extra_columns.PET <- function(method_name) {   c(\"bias_coefficient\", \"bias_p_value\") }"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Adding_New_Methods.html","id":"using-your-new-method","dir":"Articles","previous_headings":"","what":"Using Your New Method","title":"Adding New Methods","text":"implemented, method can used unified interface:","code":"# Create example data data <- data.frame(   yi  = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Run your method result <- run_method(\"PET\", data) print(result)  # Use specific settings (if available) result <- run_method(\"PET\", data, \"default\")"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results.html","id":"complete-results","dir":"Articles","previous_headings":"","what":"Complete Results","title":"Results: Overall","text":"results based Stanley2017, Alinaghi2018, Bom2019, Carter2019 data-generating mechanisms total 1665 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results.html","id":"average-performance","dir":"Articles","previous_headings":"Complete Results","what":"Average Performance","title":"Results: Overall","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined Methods compared using condition-wise ranks. Direct comparison using average bias possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution bias values corresponding outcome scale. Methods compared using condition-wise ranks. Direct comparison using average RMSE possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution RMSE values corresponding outcome scale. positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results.html","id":"by-condition-performance-conditional-on-method-convergence","dir":"Articles","previous_headings":"Complete Results","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Overall","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Methods compared using condition-wise ranks. Direct comparison using average bias possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution bias values corresponding outcome scale.  Methods compared using condition-wise ranks. Direct comparison using average RMSE possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution RMSE values corresponding outcome scale.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results.html","id":"by-condition-performance-replacement-in-case-of-non-convergence","dir":"Articles","previous_headings":"Complete Results","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Overall","text":"results incorporate method replacement handle non-convergence. method fails converge, results replaced results simpler method (e.g., random-effects meta-analysis without publication bias adjustment). emulates data analyst may practice case method converge. However, note results correspond “pure” method performance might combine multiple different methods. See Method Replacement Strategy details method replacement specification. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Methods compared using condition-wise ranks. Direct comparison using average bias possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution bias values corresponding outcome scale.  Methods compared using condition-wise ranks. Direct comparison using average RMSE possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution RMSE values corresponding outcome scale.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results.html","id":"subset-publication-bias-present","dir":"Articles","previous_headings":"","what":"Subset: Publication Bias Present","title":"Results: Overall","text":"results based Stanley2017, Alinaghi2018, Bom2019, Carter2019 data-generating mechanisms total 1143 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results.html","id":"average-performance-1","dir":"Articles","previous_headings":"Subset: Publication Bias Present","what":"Average Performance","title":"Results: Overall","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined Methods compared using condition-wise ranks. Direct comparison using average bias possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution bias values corresponding outcome scale. Methods compared using condition-wise ranks. Direct comparison using average RMSE possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution RMSE values corresponding outcome scale. positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results.html","id":"by-condition-performance-conditional-on-method-convergence-1","dir":"Articles","previous_headings":"Subset: Publication Bias Present","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Overall","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Methods compared using condition-wise ranks. Direct comparison using average bias possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution bias values corresponding outcome scale.  Methods compared using condition-wise ranks. Direct comparison using average RMSE possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution RMSE values corresponding outcome scale.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results.html","id":"by-condition-performance-replacement-in-case-of-non-convergence-1","dir":"Articles","previous_headings":"Subset: Publication Bias Present","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Overall","text":"results incorporate method replacement handle non-convergence. method fails converge, results replaced results simpler method (e.g., random-effects meta-analysis without publication bias adjustment). emulates data analyst may practice case method converge. However, note results correspond “pure” method performance might combine multiple different methods. See Method Replacement Strategy details method replacement specification. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Methods compared using condition-wise ranks. Direct comparison using average bias possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution bias values corresponding outcome scale.  Methods compared using condition-wise ranks. Direct comparison using average RMSE possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution RMSE values corresponding outcome scale.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results.html","id":"subset-publication-bias-absent","dir":"Articles","previous_headings":"","what":"Subset: Publication Bias Absent","title":"Results: Overall","text":"results based Stanley2017, Alinaghi2018, Bom2019, Carter2019 data-generating mechanisms total 522 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results.html","id":"average-performance-2","dir":"Articles","previous_headings":"Subset: Publication Bias Absent","what":"Average Performance","title":"Results: Overall","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined Methods compared using condition-wise ranks. Direct comparison using average bias possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution bias values corresponding outcome scale. Methods compared using condition-wise ranks. Direct comparison using average RMSE possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution RMSE values corresponding outcome scale. positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results.html","id":"by-condition-performance-conditional-on-method-convergence-2","dir":"Articles","previous_headings":"Subset: Publication Bias Absent","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Overall","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Methods compared using condition-wise ranks. Direct comparison using average bias possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution bias values corresponding outcome scale.  Methods compared using condition-wise ranks. Direct comparison using average RMSE possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution RMSE values corresponding outcome scale.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results.html","id":"by-condition-performance-replacement-in-case-of-non-convergence-2","dir":"Articles","previous_headings":"Subset: Publication Bias Absent","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Overall","text":"results incorporate method replacement handle non-convergence. method fails converge, results replaced results simpler method (e.g., random-effects meta-analysis without publication bias adjustment). emulates data analyst may practice case method converge. However, note results correspond “pure” method performance might combine multiple different methods. See Method Replacement Strategy details method replacement specification. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Methods compared using condition-wise ranks. Direct comparison using average bias possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution bias values corresponding outcome scale.  Methods compared using condition-wise ranks. Direct comparison using average RMSE possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution RMSE values corresponding outcome scale.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"Results: Overall","text":"report compiled Mon Oct 13 10:16:18 2025 (UTC) using following computational environment","code":"sessionInfo() ## R version 4.5.1 (2025-06-13) ## Platform: x86_64-pc-linux-gnu ## Running under: Ubuntu 24.04.3 LTS ##  ## Matrix products: default ## BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  ## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 ##  ## locale: ##  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        ##  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    ##  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           ## [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    ##  ## time zone: UTC ## tzcode source: system (glibc) ##  ## attached base packages: ## [1] stats     graphics  grDevices utils     datasets  methods   base      ##  ## other attached packages: ## [1] scales_1.4.0                   ggdist_3.3.3                   ## [3] ggplot2_4.0.0                  PublicationBiasBenchmark_0.1.0 ## [5] devtools_2.4.6                 usethis_3.2.1                  ##  ## loaded via a namespace (and not attached): ##  [1] gtable_0.3.6         xfun_0.53            bslib_0.9.0          ##  [4] htmlwidgets_1.6.4    remotes_2.5.0        lattice_0.22-7       ##  [7] vctrs_0.6.5          tools_4.5.1          Rdpack_2.6.4         ## [10] generics_0.1.4       curl_7.0.0           sandwich_3.1-1       ## [13] tibble_3.3.0         pkgconfig_2.0.3      RColorBrewer_1.1-3   ## [16] S7_0.2.0             desc_1.4.3           distributional_0.5.0 ## [19] lifecycle_1.0.4      compiler_4.5.1       farver_2.1.2         ## [22] stringr_1.5.2        textshaping_1.0.4    htmltools_0.5.8.1    ## [25] sass_0.4.10          clubSandwich_0.6.1   yaml_2.3.10          ## [28] pillar_1.11.1        pkgdown_2.1.3        jquerylib_0.1.4      ## [31] ellipsis_0.3.2       cachem_1.1.0         sessioninfo_1.2.3    ## [34] digest_0.6.37        stringi_1.8.7        purrr_1.1.0          ## [37] labeling_0.4.3       fastmap_1.2.0        grid_4.5.1           ## [40] cli_3.6.5            magrittr_2.0.4       triebeard_0.4.1      ## [43] crul_1.6.0           pkgbuild_1.4.8       osfr_0.2.9           ## [46] withr_3.0.2          rmarkdown_2.30       httr_1.4.7           ## [49] ragg_1.5.0           zoo_1.8-14           kableExtra_1.4.0     ## [52] memoise_2.0.1        evaluate_1.0.5       knitr_1.50           ## [55] rbibutils_2.3        viridisLite_0.4.2    rlang_1.1.6          ## [58] urltools_1.7.3.1     Rcpp_1.1.0           glue_1.8.0           ## [61] httpcode_0.3.0       xml2_1.4.0           pkgload_1.4.1        ## [64] svglite_2.2.1        rstudioapi_0.17.1    jsonlite_2.0.0       ## [67] R6_2.6.1             systemfonts_1.3.1    fs_1.6.6"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"complete-results","dir":"Articles","previous_headings":"","what":"Complete Results","title":"Results: Alinaghi (2018)","text":"results based Alinaghi2018 data-generating mechanism total 81 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"average-performance","dir":"Articles","previous_headings":"Complete Results","what":"Average Performance","title":"Results: Alinaghi (2018)","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"by-condition-performance-conditional-on-method-convergence","dir":"Articles","previous_headings":"Complete Results","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Alinaghi (2018)","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"by-condition-performance-replacement-in-case-of-non-convergence","dir":"Articles","previous_headings":"Complete Results","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Alinaghi (2018)","text":"results incorporate method replacement handle non-convergence. method fails converge, results replaced results simpler method (e.g., random-effects meta-analysis without publication bias adjustment). emulates data analyst may practice case method converge. However, note results correspond “pure” method performance might combine multiple different methods. See Method Replacement Strategy details method replacement specification. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"subset-fixed-effects","dir":"Articles","previous_headings":"","what":"Subset: Fixed Effects","title":"Results: Alinaghi (2018)","text":"results based Alinaghi2018 data-generating mechanism total 27 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"average-performance-1","dir":"Articles","previous_headings":"Subset: Fixed Effects","what":"Average Performance","title":"Results: Alinaghi (2018)","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"by-condition-performance-conditional-on-method-convergence-1","dir":"Articles","previous_headings":"Subset: Fixed Effects","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Alinaghi (2018)","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"by-condition-performance-replacement-in-case-of-non-convergence-1","dir":"Articles","previous_headings":"Subset: Fixed Effects","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Alinaghi (2018)","text":"results incorporate method replacement handle non-convergence. method fails converge, results replaced results simpler method (e.g., random-effects meta-analysis without publication bias adjustment). emulates data analyst may practice case method converge. However, note results correspond “pure” method performance might combine multiple different methods. See Method Replacement Strategy details method replacement specification. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"subset-random-effects","dir":"Articles","previous_headings":"","what":"Subset: Random Effects","title":"Results: Alinaghi (2018)","text":"results based Alinaghi2018 data-generating mechanism total 27 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"average-performance-2","dir":"Articles","previous_headings":"Subset: Random Effects","what":"Average Performance","title":"Results: Alinaghi (2018)","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"by-condition-performance-conditional-on-method-convergence-2","dir":"Articles","previous_headings":"Subset: Random Effects","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Alinaghi (2018)","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"by-condition-performance-replacement-in-case-of-non-convergence-2","dir":"Articles","previous_headings":"Subset: Random Effects","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Alinaghi (2018)","text":"results incorporate method replacement handle non-convergence. method fails converge, results replaced results simpler method (e.g., random-effects meta-analysis without publication bias adjustment). emulates data analyst may practice case method converge. However, note results correspond “pure” method performance might combine multiple different methods. See Method Replacement Strategy details method replacement specification. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"subset-panel-random-effects","dir":"Articles","previous_headings":"","what":"Subset: Panel Random Effects","title":"Results: Alinaghi (2018)","text":"results based Alinaghi2018 data-generating mechanism total 27 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"average-performance-3","dir":"Articles","previous_headings":"Subset: Panel Random Effects","what":"Average Performance","title":"Results: Alinaghi (2018)","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"by-condition-performance-conditional-on-method-convergence-3","dir":"Articles","previous_headings":"Subset: Panel Random Effects","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Alinaghi (2018)","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"by-condition-performance-replacement-in-case-of-non-convergence-3","dir":"Articles","previous_headings":"Subset: Panel Random Effects","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Alinaghi (2018)","text":"results incorporate method replacement handle non-convergence. method fails converge, results replaced results simpler method (e.g., random-effects meta-analysis without publication bias adjustment). emulates data analyst may practice case method converge. However, note results correspond “pure” method performance might combine multiple different methods. See Method Replacement Strategy details method replacement specification. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Alinaghi2018.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"Results: Alinaghi (2018)","text":"report compiled Mon Oct 13 10:04:33 2025 (UTC) using following computational environment","code":"sessionInfo() ## R version 4.5.1 (2025-06-13) ## Platform: x86_64-pc-linux-gnu ## Running under: Ubuntu 24.04.3 LTS ##  ## Matrix products: default ## BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  ## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 ##  ## locale: ##  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        ##  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    ##  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           ## [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    ##  ## time zone: UTC ## tzcode source: system (glibc) ##  ## attached base packages: ## [1] stats     graphics  grDevices utils     datasets  methods   base      ##  ## other attached packages: ## [1] scales_1.4.0                   ggdist_3.3.3                   ## [3] ggplot2_4.0.0                  PublicationBiasBenchmark_0.1.0 ## [5] devtools_2.4.6                 usethis_3.2.1                  ##  ## loaded via a namespace (and not attached): ##  [1] gtable_0.3.6         xfun_0.53            bslib_0.9.0          ##  [4] htmlwidgets_1.6.4    remotes_2.5.0        lattice_0.22-7       ##  [7] vctrs_0.6.5          tools_4.5.1          Rdpack_2.6.4         ## [10] generics_0.1.4       curl_7.0.0           sandwich_3.1-1       ## [13] tibble_3.3.0         pkgconfig_2.0.3      RColorBrewer_1.1-3   ## [16] S7_0.2.0             desc_1.4.3           distributional_0.5.0 ## [19] lifecycle_1.0.4      compiler_4.5.1       farver_2.1.2         ## [22] stringr_1.5.2        textshaping_1.0.4    htmltools_0.5.8.1    ## [25] sass_0.4.10          clubSandwich_0.6.1   yaml_2.3.10          ## [28] pillar_1.11.1        pkgdown_2.1.3        jquerylib_0.1.4      ## [31] ellipsis_0.3.2       cachem_1.1.0         sessioninfo_1.2.3    ## [34] digest_0.6.37        stringi_1.8.7        purrr_1.1.0          ## [37] labeling_0.4.3       fastmap_1.2.0        grid_4.5.1           ## [40] cli_3.6.5            magrittr_2.0.4       triebeard_0.4.1      ## [43] crul_1.6.0           pkgbuild_1.4.8       osfr_0.2.9           ## [46] withr_3.0.2          rmarkdown_2.30       httr_1.4.7           ## [49] ragg_1.5.0           zoo_1.8-14           kableExtra_1.4.0     ## [52] memoise_2.0.1        evaluate_1.0.5       knitr_1.50           ## [55] rbibutils_2.3        viridisLite_0.4.2    rlang_1.1.6          ## [58] urltools_1.7.3.1     Rcpp_1.1.0           glue_1.8.0           ## [61] httpcode_0.3.0       xml2_1.4.0           pkgload_1.4.1        ## [64] svglite_2.2.1        rstudioapi_0.17.1    jsonlite_2.0.0       ## [67] R6_2.6.1             systemfonts_1.3.1    fs_1.6.6"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Bom2019.html","id":"complete-results","dir":"Articles","previous_headings":"","what":"Complete Results","title":"Results: Bom (2019)","text":"results based Bom2019 data-generating mechanism total 504 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Bom2019.html","id":"average-performance","dir":"Articles","previous_headings":"Complete Results","what":"Average Performance","title":"Results: Bom (2019)","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Bom2019.html","id":"by-condition-performance-conditional-on-method-convergence","dir":"Articles","previous_headings":"Complete Results","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Bom (2019)","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Bom2019.html","id":"by-condition-performance-replacement-in-case-of-non-convergence","dir":"Articles","previous_headings":"Complete Results","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Bom (2019)","text":"results incorporate method replacement handle non-convergence. method fails converge, results replaced results simpler method (e.g., random-effects meta-analysis without publication bias adjustment). emulates data analyst may practice case method converge. However, note results correspond “pure” method performance might combine multiple different methods. See Method Replacement Strategy details method replacement specification. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Bom2019.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"Results: Bom (2019)","text":"report compiled Mon Oct 13 10:05:47 2025 (UTC) using following computational environment","code":"sessionInfo() ## R version 4.5.1 (2025-06-13) ## Platform: x86_64-pc-linux-gnu ## Running under: Ubuntu 24.04.3 LTS ##  ## Matrix products: default ## BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  ## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 ##  ## locale: ##  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        ##  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    ##  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           ## [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    ##  ## time zone: UTC ## tzcode source: system (glibc) ##  ## attached base packages: ## [1] stats     graphics  grDevices utils     datasets  methods   base      ##  ## other attached packages: ## [1] scales_1.4.0                   ggdist_3.3.3                   ## [3] ggplot2_4.0.0                  PublicationBiasBenchmark_0.1.0 ## [5] devtools_2.4.6                 usethis_3.2.1                  ##  ## loaded via a namespace (and not attached): ##  [1] gtable_0.3.6         xfun_0.53            bslib_0.9.0          ##  [4] htmlwidgets_1.6.4    remotes_2.5.0        lattice_0.22-7       ##  [7] vctrs_0.6.5          tools_4.5.1          Rdpack_2.6.4         ## [10] generics_0.1.4       curl_7.0.0           sandwich_3.1-1       ## [13] tibble_3.3.0         pkgconfig_2.0.3      RColorBrewer_1.1-3   ## [16] S7_0.2.0             desc_1.4.3           distributional_0.5.0 ## [19] lifecycle_1.0.4      compiler_4.5.1       farver_2.1.2         ## [22] stringr_1.5.2        textshaping_1.0.4    htmltools_0.5.8.1    ## [25] sass_0.4.10          clubSandwich_0.6.1   yaml_2.3.10          ## [28] pillar_1.11.1        pkgdown_2.1.3        jquerylib_0.1.4      ## [31] ellipsis_0.3.2       cachem_1.1.0         sessioninfo_1.2.3    ## [34] digest_0.6.37        stringi_1.8.7        purrr_1.1.0          ## [37] labeling_0.4.3       fastmap_1.2.0        grid_4.5.1           ## [40] cli_3.6.5            magrittr_2.0.4       triebeard_0.4.1      ## [43] crul_1.6.0           pkgbuild_1.4.8       osfr_0.2.9           ## [46] withr_3.0.2          rmarkdown_2.30       httr_1.4.7           ## [49] ragg_1.5.0           zoo_1.8-14           kableExtra_1.4.0     ## [52] memoise_2.0.1        evaluate_1.0.5       knitr_1.50           ## [55] rbibutils_2.3        viridisLite_0.4.2    rlang_1.1.6          ## [58] urltools_1.7.3.1     Rcpp_1.1.0           glue_1.8.0           ## [61] httpcode_0.3.0       xml2_1.4.0           pkgload_1.4.1        ## [64] svglite_2.2.1        rstudioapi_0.17.1    jsonlite_2.0.0       ## [67] R6_2.6.1             systemfonts_1.3.1    fs_1.6.6"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"complete-results","dir":"Articles","previous_headings":"","what":"Complete Results","title":"Results: Carter (2019)","text":"results based Carter2019 data-generating mechanism total 756 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"average-performance","dir":"Articles","previous_headings":"Complete Results","what":"Average Performance","title":"Results: Carter (2019)","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"by-condition-performance-conditional-on-method-convergence","dir":"Articles","previous_headings":"Complete Results","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Carter (2019)","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"by-condition-performance-replacement-in-case-of-non-convergence","dir":"Articles","previous_headings":"Complete Results","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Carter (2019)","text":"results incorporate method replacement handle non-convergence. method fails converge, results replaced results simpler method (e.g., random-effects meta-analysis without publication bias adjustment). emulates data analyst may practice case method converge. However, note results correspond “pure” method performance might combine multiple different methods. See Method Replacement Strategy details method replacement specification. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"subset-no-questionable-research-practices","dir":"Articles","previous_headings":"","what":"Subset: No Questionable Research Practices","title":"Results: Carter (2019)","text":"results based Carter2019 data-generating mechanism total 252 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"average-performance-1","dir":"Articles","previous_headings":"Subset: No Questionable Research Practices","what":"Average Performance","title":"Results: Carter (2019)","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"by-condition-performance-conditional-on-method-convergence-1","dir":"Articles","previous_headings":"Subset: No Questionable Research Practices","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Carter (2019)","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"by-condition-performance-replacement-in-case-of-non-convergence-1","dir":"Articles","previous_headings":"Subset: No Questionable Research Practices","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Carter (2019)","text":"results incorporate method replacement handle non-convergence. method fails converge, results replaced results simpler method (e.g., random-effects meta-analysis without publication bias adjustment). emulates data analyst may practice case method converge. However, note results correspond “pure” method performance might combine multiple different methods. See Method Replacement Strategy details method replacement specification. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"subset-medium-questionable-research-practices","dir":"Articles","previous_headings":"","what":"Subset: Medium Questionable Research Practices","title":"Results: Carter (2019)","text":"results based Carter2019 data-generating mechanism total 252 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"average-performance-2","dir":"Articles","previous_headings":"Subset: Medium Questionable Research Practices","what":"Average Performance","title":"Results: Carter (2019)","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"by-condition-performance-conditional-on-method-convergence-2","dir":"Articles","previous_headings":"Subset: Medium Questionable Research Practices","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Carter (2019)","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"by-condition-performance-replacement-in-case-of-non-convergence-2","dir":"Articles","previous_headings":"Subset: Medium Questionable Research Practices","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Carter (2019)","text":"results incorporate method replacement handle non-convergence. method fails converge, results replaced results simpler method (e.g., random-effects meta-analysis without publication bias adjustment). emulates data analyst may practice case method converge. However, note results correspond “pure” method performance might combine multiple different methods. See Method Replacement Strategy details method replacement specification. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"subset-high-questionable-research-practices","dir":"Articles","previous_headings":"","what":"Subset: High Questionable Research Practices","title":"Results: Carter (2019)","text":"results based Carter2019 data-generating mechanism total 252 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"average-performance-3","dir":"Articles","previous_headings":"Subset: High Questionable Research Practices","what":"Average Performance","title":"Results: Carter (2019)","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"by-condition-performance-conditional-on-method-convergence-3","dir":"Articles","previous_headings":"Subset: High Questionable Research Practices","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Carter (2019)","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"by-condition-performance-replacement-in-case-of-non-convergence-3","dir":"Articles","previous_headings":"Subset: High Questionable Research Practices","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Carter (2019)","text":"results incorporate method replacement handle non-convergence. method fails converge, results replaced results simpler method (e.g., random-effects meta-analysis without publication bias adjustment). emulates data analyst may practice case method converge. However, note results correspond “pure” method performance might combine multiple different methods. See Method Replacement Strategy details method replacement specification. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Carter2019.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"Results: Carter (2019)","text":"report compiled Mon Oct 13 10:10:29 2025 (UTC) using following computational environment","code":"sessionInfo() ## R version 4.5.1 (2025-06-13) ## Platform: x86_64-pc-linux-gnu ## Running under: Ubuntu 24.04.3 LTS ##  ## Matrix products: default ## BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  ## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 ##  ## locale: ##  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        ##  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    ##  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           ## [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    ##  ## time zone: UTC ## tzcode source: system (glibc) ##  ## attached base packages: ## [1] stats     graphics  grDevices utils     datasets  methods   base      ##  ## other attached packages: ## [1] scales_1.4.0                   ggdist_3.3.3                   ## [3] ggplot2_4.0.0                  PublicationBiasBenchmark_0.1.0 ## [5] devtools_2.4.6                 usethis_3.2.1                  ##  ## loaded via a namespace (and not attached): ##  [1] gtable_0.3.6         xfun_0.53            bslib_0.9.0          ##  [4] htmlwidgets_1.6.4    remotes_2.5.0        lattice_0.22-7       ##  [7] vctrs_0.6.5          tools_4.5.1          Rdpack_2.6.4         ## [10] generics_0.1.4       curl_7.0.0           sandwich_3.1-1       ## [13] tibble_3.3.0         pkgconfig_2.0.3      RColorBrewer_1.1-3   ## [16] S7_0.2.0             desc_1.4.3           distributional_0.5.0 ## [19] lifecycle_1.0.4      compiler_4.5.1       farver_2.1.2         ## [22] stringr_1.5.2        textshaping_1.0.4    htmltools_0.5.8.1    ## [25] sass_0.4.10          clubSandwich_0.6.1   yaml_2.3.10          ## [28] pillar_1.11.1        pkgdown_2.1.3        jquerylib_0.1.4      ## [31] ellipsis_0.3.2       cachem_1.1.0         sessioninfo_1.2.3    ## [34] digest_0.6.37        stringi_1.8.7        purrr_1.1.0          ## [37] labeling_0.4.3       fastmap_1.2.0        grid_4.5.1           ## [40] cli_3.6.5            magrittr_2.0.4       triebeard_0.4.1      ## [43] crul_1.6.0           pkgbuild_1.4.8       osfr_0.2.9           ## [46] withr_3.0.2          rmarkdown_2.30       httr_1.4.7           ## [49] ragg_1.5.0           zoo_1.8-14           kableExtra_1.4.0     ## [52] memoise_2.0.1        evaluate_1.0.5       knitr_1.50           ## [55] rbibutils_2.3        viridisLite_0.4.2    rlang_1.1.6          ## [58] urltools_1.7.3.1     Rcpp_1.1.0           glue_1.8.0           ## [61] httpcode_0.3.0       xml2_1.4.0           pkgload_1.4.1        ## [64] svglite_2.2.1        rstudioapi_0.17.1    jsonlite_2.0.0       ## [67] R6_2.6.1             systemfonts_1.3.1    fs_1.6.6"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Method_Replacement.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Method Replacement Strategy","text":"handle cases methods fail converge, method replacement strategy implemented. approach emulates data analyst might practice: sophisticated method fails converge, fall back simpler, robust method. replacement applied sequentially: first replacement method also fails, next method sequence tried, . strategy allows method performance evaluated realistic scenario non-convergence handled pragmatically. However, noted results replacement longer reflect “pure” method performance, may combine estimates multiple different methods.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Method_Replacement.html","id":"replacement-specification","dir":"Articles","previous_headings":"","what":"Replacement Specification","title":"Method Replacement Strategy","text":"table shows replacement sequence method. method fails converge, methods “Replacement Sequence” column applied order convergence achieved replacement options exhausted. em-dash — indicates replacement (method assumed always converge). choice replacement methods based : Similarity: Replacement methods conceptually similar original method possible. Robustness: Simpler methods generally robust convergence issues. Practicality: sequence reflects applied researchers might reasonably faced convergence failures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Stanley2017.html","id":"complete-results","dir":"Articles","previous_headings":"","what":"Complete Results","title":"Results: Stanley (2017)","text":"results based Stanley2017 data-generating mechanism total 324 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Stanley2017.html","id":"average-performance","dir":"Articles","previous_headings":"Complete Results","what":"Average Performance","title":"Results: Stanley (2017)","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined Methods compared using condition-wise ranks. Direct comparison using average bias possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution bias values corresponding outcome scale. Methods compared using condition-wise ranks. Direct comparison using average RMSE possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution RMSE values corresponding outcome scale. positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Stanley2017.html","id":"by-condition-performance-conditional-on-method-convergence","dir":"Articles","previous_headings":"Complete Results","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Stanley (2017)","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Methods compared using condition-wise ranks. Direct comparison using average bias possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution bias values corresponding outcome scale.  Methods compared using condition-wise ranks. Direct comparison using average RMSE possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution RMSE values corresponding outcome scale.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Stanley2017.html","id":"by-condition-performance-replacement-in-case-of-non-convergence","dir":"Articles","previous_headings":"Complete Results","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Stanley (2017)","text":"results incorporate method replacement handle non-convergence. method fails converge, results replaced results simpler method (e.g., random-effects meta-analysis without publication bias adjustment). emulates data analyst may practice case method converge. However, note results correspond “pure” method performance might combine multiple different methods. See Method Replacement Strategy details method replacement specification. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Methods compared using condition-wise ranks. Direct comparison using average bias possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution bias values corresponding outcome scale.  Methods compared using condition-wise ranks. Direct comparison using average RMSE possible data-generating mechanisms differ outcome scale. See DGM-specific results (subresults) see distribution RMSE values corresponding outcome scale.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Stanley2017.html","id":"subset-standardized-mean-difference-effect-sizes","dir":"Articles","previous_headings":"","what":"Subset: Standardized Mean Difference Effect Sizes","title":"Results: Stanley (2017)","text":"results based Stanley2017 data-generating mechanism total 270 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Stanley2017.html","id":"average-performance-1","dir":"Articles","previous_headings":"Subset: Standardized Mean Difference Effect Sizes","what":"Average Performance","title":"Results: Stanley (2017)","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Stanley2017.html","id":"by-condition-performance-conditional-on-method-convergence-1","dir":"Articles","previous_headings":"Subset: Standardized Mean Difference Effect Sizes","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Stanley (2017)","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Stanley2017.html","id":"by-condition-performance-replacement-in-case-of-non-convergence-1","dir":"Articles","previous_headings":"Subset: Standardized Mean Difference Effect Sizes","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Stanley (2017)","text":"results incorporate method replacement handle non-convergence. method fails converge, results replaced results simpler method (e.g., random-effects meta-analysis without publication bias adjustment). emulates data analyst may practice case method converge. However, note results correspond “pure” method performance might combine multiple different methods. See Method Replacement Strategy details method replacement specification. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Stanley2017.html","id":"subset-log-odd-ratio-effect-sizes","dir":"Articles","previous_headings":"","what":"Subset: Log Odd Ratio Effect Sizes","title":"Results: Stanley (2017)","text":"results based Stanley2017 data-generating mechanism total 54 conditions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Stanley2017.html","id":"average-performance-2","dir":"Articles","previous_headings":"Subset: Log Odd Ratio Effect Sizes","what":"Average Performance","title":"Results: Stanley (2017)","text":"Method performance measures aggregated across simulated conditions provide overall impression method performance. However, keep mind method high overall ranking necessarily “best” method particular application. select suitable method application, consider also non-aggregated performance measures conditions relevant application. (TODO: add links non-aggregated data exploration tool) Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio Combined positive likelihood ratio indicates much significant test result changes odds H1 versus H0. negative likelihood ratio indicates much non-significant test result changes odds H1 versus H0. combined method rank mean method rank across performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Stanley2017.html","id":"by-condition-performance-conditional-on-method-convergence-2","dir":"Articles","previous_headings":"Subset: Log Odd Ratio Effect Sizes","what":"By-Condition Performance (Conditional on Method Convergence)","title":"Results: Stanley (2017)","text":"results conditional method convergence. Note methods might differ convergence rate therefore compared data sets. Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Stanley2017.html","id":"by-condition-performance-replacement-in-case-of-non-convergence-2","dir":"Articles","previous_headings":"Subset: Log Odd Ratio Effect Sizes","what":"By-Condition Performance (Replacement in Case of Non-Convergence)","title":"Results: Stanley (2017)","text":"Convergence Bias RMSE 95% CI Coverage 95% CI Width Interval Score Type Error Rate Power Log Positive Likelihood Ratio Log Negative Likelihood Ratio   Values lower -0.5 larger 0.5 visualized -0.5 0.5 respectively.  Values larger 0.5 visualized 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/articles/Results_Stanley2017.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"Results: Stanley (2017)","text":"report compiled Mon Oct 13 10:14:06 2025 (UTC) using following computational environment","code":"sessionInfo() ## R version 4.5.1 (2025-06-13) ## Platform: x86_64-pc-linux-gnu ## Running under: Ubuntu 24.04.3 LTS ##  ## Matrix products: default ## BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  ## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 ##  ## locale: ##  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        ##  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    ##  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           ## [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    ##  ## time zone: UTC ## tzcode source: system (glibc) ##  ## attached base packages: ## [1] stats     graphics  grDevices utils     datasets  methods   base      ##  ## other attached packages: ## [1] scales_1.4.0                   ggdist_3.3.3                   ## [3] ggplot2_4.0.0                  PublicationBiasBenchmark_0.1.0 ## [5] devtools_2.4.6                 usethis_3.2.1                  ##  ## loaded via a namespace (and not attached): ##  [1] gtable_0.3.6         xfun_0.53            bslib_0.9.0          ##  [4] htmlwidgets_1.6.4    remotes_2.5.0        lattice_0.22-7       ##  [7] vctrs_0.6.5          tools_4.5.1          Rdpack_2.6.4         ## [10] generics_0.1.4       curl_7.0.0           sandwich_3.1-1       ## [13] tibble_3.3.0         pkgconfig_2.0.3      RColorBrewer_1.1-3   ## [16] S7_0.2.0             desc_1.4.3           distributional_0.5.0 ## [19] lifecycle_1.0.4      compiler_4.5.1       farver_2.1.2         ## [22] stringr_1.5.2        textshaping_1.0.4    htmltools_0.5.8.1    ## [25] sass_0.4.10          clubSandwich_0.6.1   yaml_2.3.10          ## [28] pillar_1.11.1        pkgdown_2.1.3        jquerylib_0.1.4      ## [31] ellipsis_0.3.2       cachem_1.1.0         sessioninfo_1.2.3    ## [34] digest_0.6.37        stringi_1.8.7        purrr_1.1.0          ## [37] labeling_0.4.3       fastmap_1.2.0        grid_4.5.1           ## [40] cli_3.6.5            magrittr_2.0.4       triebeard_0.4.1      ## [43] crul_1.6.0           pkgbuild_1.4.8       osfr_0.2.9           ## [46] withr_3.0.2          rmarkdown_2.30       httr_1.4.7           ## [49] ragg_1.5.0           zoo_1.8-14           kableExtra_1.4.0     ## [52] memoise_2.0.1        evaluate_1.0.5       knitr_1.50           ## [55] rbibutils_2.3        viridisLite_0.4.2    rlang_1.1.6          ## [58] urltools_1.7.3.1     Rcpp_1.1.0           glue_1.8.0           ## [61] httpcode_0.3.0       xml2_1.4.0           pkgload_1.4.1        ## [64] svglite_2.2.1        rstudioapi_0.17.1    jsonlite_2.0.0       ## [67] R6_2.6.1             systemfonts_1.3.1    fs_1.6.6"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"František Bartoš. Author, maintainer. Samuel Pawel. Author. Björn S. Siepe. Author.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Bartoš F, Pawel S, Siepe B (2025). PublicationBiasBenchmark: Benchmark Methods Publication Bias Correction. R package version 0.1.0, https://github.com/FBartos/PublicationBiasBenchmark.","code":"@Manual{,   title = {PublicationBiasBenchmark: Benchmark Methods for Publication Bias Correction},   author = {František Bartoš and Samuel Pawel and Björn S. Siepe},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/FBartos/PublicationBiasBenchmark}, }"},{"path":[]},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"publicationbiasbenchmark","dir":"","previous_headings":"","what":"PublicationBiasBenchmark","title":"Benchmark Methods for Publication Bias Correction","text":"PublicationBiasBenchmark R package benchmarking publication bias correction methods simulation studies. provides: - Predefined data-generating mechanisms literature - Functions running meta-analytic methods simulated data - Pre-simulated datasets pre-computed results reproducible benchmarks - Tools visualizing comparing method performance datasets results hosted OSF: https://doi.org/10.17605/OSF.IO/EXF3M use package research, please cite: Bartoš, F., Pawel, S., Siepe, B. S. (2025). Rethinking Simulation Studies: Living Synthetic Benchmarks Cumulative Methodological Research. Working paper. https://github.com/FBartos/PublicationBiasBenchmark BibTeX entry given Overviews benchmark results available articles package website: Overall Results Stanley (2017) Alinaghi (2018) Bom (2019) Carter (2019) Contributor guidelines extending package data-generating mechanisms methods available : add new data-generating mechanism add new method rest file overviews main features package.","code":"@misc{Bartos2025,   year = {2025},   author = {Franti{\\v{s}}ek Barto{\\v{s}} and Samuel Pawel and Bj{\\\"o}rn S. Siepe},   title = {Rethinking Simulation Studies: {L}iving Synthetic Benchmarks for Cumulative Methodological Research},   url = {https://github.com/FBartos/PublicationBiasBenchmark},   note = {Working paper} }"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Benchmark Methods for Publication Bias Correction","text":"","code":"# Install from GitHub remotes::install_github(\"FBartos/PublicationBiasBenchmark\")"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Benchmark Methods for Publication Bias Correction","text":"","code":"#> Data, results, and measures will be saved to '/home/sam/Downloads/PublicationBiasBenchmark/resources'. #> To change the default location, use `PublicationBiasBenchmark.options(simulation_directory = `/path/`)` #>  #> Attaching package: 'PublicationBiasBenchmark' #> The following object is masked from 'package:stats': #>  #>     power"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"simulating-from-existing-data-generating-mechanisms","dir":"","previous_headings":"Usage","what":"Simulating From Existing Data-Generating Mechanisms","title":"Benchmark Methods for Publication Bias Correction","text":"","code":"# Obtain a data.frame with pre-defined conditions dgm_conditions(\"Stanley2017\")  # simulate the data from the second condition df <- simulate_dgm(\"Stanley2017\", 2)  # fit a method run_method(\"RMA\", df)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"using-pre-simulated-datasets","dir":"","previous_headings":"Usage","what":"Using Pre-Simulated Datasets","title":"Benchmark Methods for Publication Bias Correction","text":"","code":"# download the pre-simulated datasets # the default settings downloads the datasets to the `resources` directory, use # PublicationBiasBenchmark.options(simulation_directory = \"/path/\") # to change the settings download_dgm_datasets(\"no_bias\")  # retrieve first repetition of first condition from the downloaded datasets retrieve_dgm_dataset(\"no_bias\", condition_id = 1, repetition_id = 1)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"using-pre-computed-results","dir":"","previous_headings":"Usage","what":"Using Pre-Computed Results","title":"Benchmark Methods for Publication Bias Correction","text":"","code":"# download the pre-computed results download_dgm_results(\"no_bias\")  # retrieve results the first repetition of first condition of RMA from the downloaded results retrieve_dgm_results(\"no_bias\", method = \"RMA\", condition_id = 1, repetition_id = 1)  # retrieve all results across all conditions and repetitions retrieve_dgm_results(\"no_bias\")"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"using-pre-computed-measures","dir":"","previous_headings":"Usage","what":"Using Pre-Computed Measures","title":"Benchmark Methods for Publication Bias Correction","text":"","code":"# download the pre-computed measures download_dgm_measures(\"no_bias\")  # retrieve measures of bias the first condition of RMA from the downloaded results retrieve_dgm_measures(\"no_bias\", measure = \"bias\", method = \"RMA\", condition_id = 1)  # retrieve all measures across all conditions and measures retrieve_dgm_measures(\"no_bias\")"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"visualizing-pre-computed-results","dir":"","previous_headings":"Usage","what":"Visualizing Pre-Computed Results","title":"Benchmark Methods for Publication Bias Correction","text":"","code":"# retrieve all measures across all conditions and measures df <- retrieve_dgm_measures(\"no_bias\")  # retrieve conditions conditions <- dgm_conditions(\"no_bias\")  # add labels df$label <- with(df, paste0(method, \" (\", method_setting, \")\"))  # distinguish between H0 and H1 df$H0 <- df$condition_id %in% conditions$condition_id[conditions$mean_effect == 0]  par(mfrow = c(3, 2)) par(mar = c(4, 10, 1, 1)) boxplot(convergence*100 ~ label, horizontal = T, las = 1, ylab = \"\", ylim = c(20, 100), data = df, xlab = \"Convergence (%)\") boxplot(rmse ~ label, horizontal = T, las = 1, ylab = \"\", ylim = c(0, 0.6), data = df, xlab = \"RMSE\") boxplot(bias ~ label, horizontal = T, las = 1, ylab = \"\", ylim = c(-0.25, 0.25), data = df, xlab = \"Bias\") abline(v = 0, lty = 3) boxplot(coverage*100 ~ label, horizontal = T, las = 1, ylab = \"\", ylim = c(30, 100), data = df, xlab = \"95% CI Coverage (%)\") abline(v = 95, lty = 3) boxplot(power*100 ~ label, horizontal = T, las = 1, ylab = \"\", ylim = c(0, 40), data = df[df$H0,], xlab = \"Type I Error Rate (%)\") abline(v = 5, lty = 3) boxplot(power*100 ~ label, horizontal = T, las = 1, ylab = \"\", ylim = c(10, 100), data = df[!df$H0,], xlab = \"Power (%)\")"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"simulating-from-an-existing-dgm-with-custom-settings","dir":"","previous_headings":"Usage","what":"Simulating From an Existing DGM With Custom Settings","title":"Benchmark Methods for Publication Bias Correction","text":"","code":"# define sim setting sim_settings <- list(   n_studies     = 100,   mean_effect   = 0.3,   heterogeneity = 0.1 )  # check whether it is feasible # (defined outside of the function - not to decrease performance during simulation) validate_dgm_setting(\"no_bias\", sim_settings)  # simulate the data df <- simulate_dgm(\"no_bias\", sim_settings)  # fit a method run_method(\"RMA\", df)"},{"path":[]},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"data-generating-mechanisms","dir":"","previous_headings":"Usage > Key Functions","what":"Data-Generating Mechanisms","title":"Benchmark Methods for Publication Bias Correction","text":"simulate_dgm(): Generates simulated data according specified data-generating mechanism settings. dgm_conditions(): Lists prespecified conditions data-generating mechanism. validate_dgm_setting(): Validates (custom) setting data-generating mechanism. download_dgm_datasets(): Downloads pre-simulated datasets OSF repository. retrieve_dgm_dataset(): Retrieves pre-simulated dataset given condition repetition downloaded pre-downloaded OSF repository.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"method-estimation-and-results","dir":"","previous_headings":"Usage > Key Functions","what":"Method Estimation And Results","title":"Benchmark Methods for Publication Bias Correction","text":"run_method(): Estimates method supplied data according specified settings. method_settings(): Lists prespecified settings method. download_dgm_results(): Downloads pre-computed results OSF repository. retrieve_dgm_results(): Retrieves pre-computed results given method, condition, repetition pre-downloaded OSF repository.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"performance-measures-and-results","dir":"","previous_headings":"Usage > Key Functions","what":"Performance measures And Results","title":"Benchmark Methods for Publication Bias Correction","text":"bias(), bias_mcse(), etc.: Functions compute performance measures Monte Carlo standard errors. download_dgm_measures(): Downloads pre-computed performance measures OSF repository. retrieve_dgm_measures(): Retrieves pre-computed performance measures given method, condition, repetition pre-downloaded OSF repository.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"available-data-generating-mechanisms","dir":"","previous_headings":"Usage","what":"Available Data-Generating Mechanisms","title":"Benchmark Methods for Publication Bias Correction","text":"See methods(\"dgm\") full list: \"no_bias\": Generates data without publication bias (test simulation) \"Stanley2017\": Tom D. Stanley et al. (2017) \"Alinaghi2018\": Alinaghi & Reed (2018) \"Bom2019\": Bom & Rachinger (2019) \"Carter2019\": Carter et al. (2019)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"available-methods","dir":"","previous_headings":"Usage","what":"Available Methods","title":"Benchmark Methods for Publication Bias Correction","text":"See methods(\"method\") full list: \"mean\": Mean effects size \"FMA\": Fixed effects meta-analysis \"RMA\": Random effects meta-analysis \"WLS\": Weighted Least Squares \"trimfill\": Trim--Fill (Duval & Tweedie, 2000) \"WAAPWLS\": Weighted Least Squares - Weighted Average Adequately Power Studies (Tom D. Stanley et al., 2017) \"WILS\": Weighted Iterated Least Squares (T. D. Stanley & Doucouliagos, 2024) \"PET\": Precision-Effect Test (PET) publication bias adjustment (Tom D. Stanley & Doucouliagos, 2014) \"PEESE\": Precision-Effect Estimate Standard Errors (PEESE) publication bias adjustment (Tom D. Stanley & Doucouliagos, 2014) \"PETPEESE\": Precision-Effect Test Precision-Effect Estimate Standard Errors (PET-PEESE) publication bias adjustment (Tom D. Stanley & Doucouliagos, 2014) \"EK\": Endogenous Kink (Bom & Rachinger, 2019) \"SM\": Selection Models (3PSM, 4PSM) (Vevea & Hedges, 1995) \"pcurve\": P-curve (Simonsohn et al., 2014) \"puniform\": P-uniform P-uniform* Aert & Assen (2025)  \"RoBMA\": Robust Bayesian Meta-Analysis (Bartoš et al., 2023)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"available-performance-measures","dir":"","previous_headings":"Usage","what":"Available Performance Measures","title":"Benchmark Methods for Publication Bias Correction","text":"See ?measures full list performance measures Monte Carlo standard errors/","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/index.html","id":"dgm-osf-repositories","dir":"","previous_headings":"Usage","what":"DGM OSF Repositories","title":"Benchmark Methods for Publication Bias Correction","text":"DGMs linked OSF repository (https://osf.io/exf3m/) contain following elements: data : folder containing -condition simulated datasets repetitions results : folder containing -method results conditions * repetitions measures : folder containing -measure performance methods * conditions dgm-conditions.csv : file mapping conditions corresponding settings dgm-generation.R : file code exact reproduction pre-simulated datasets dgm-sessionInfo.txt: file reproducibility details pre-simulated datasets dgm-session.log: file reproducibility details pre-simulated datasets (based sessioninfo package) results.R : file code exact reproduction method results (might method / method groups specific) results-sessionInfo.txt: file reproducibility details precomputed results (might method / method groups specific) pm-computation.R : file code computation performance measures","code":""},{"path":[]},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/PublicationBiasBenchmark-package.html","id":null,"dir":"Reference","previous_headings":"","what":"PublicationBiasBenchmark: Benchmark Methods for Publication Bias Correction — PublicationBiasBenchmark-package","title":"PublicationBiasBenchmark: Benchmark Methods for Publication Bias Correction — PublicationBiasBenchmark-package","text":"Implements unified interface benchmarking meta-analytic publication bias correction methods simulation studies. provides 1) predefined data-generating mechanisms literature, 2) functions running meta-analytic methods simulated data, 3) pre-simulated datasets pre-computed results reproducible benchmarks, 4) tools visualizing comparing method performance.","code":""},{"path":[]},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/PublicationBiasBenchmark-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"PublicationBiasBenchmark: Benchmark Methods for Publication Bias Correction — PublicationBiasBenchmark-package","text":"Maintainer: František Bartoš f.bartos96@gmail.com (ORCID) Authors: Samuel Pawel (ORCID) Björn S. Siepe (ORCID)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/PublicationBiasBenchmark_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Options for the PublicationBiasBenchmark package — PublicationBiasBenchmark_options","title":"Options for the PublicationBiasBenchmark package — PublicationBiasBenchmark_options","text":"placeholder object functions PublicationBiasBenchmark package.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/PublicationBiasBenchmark_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Options for the PublicationBiasBenchmark package — PublicationBiasBenchmark_options","text":"","code":"PublicationBiasBenchmark.options(...)  PublicationBiasBenchmark.get_option(name)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/PublicationBiasBenchmark_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Options for the PublicationBiasBenchmark package — PublicationBiasBenchmark_options","text":"... named option(s) change - list available options, see details . name name option get current value - list available options, see details .","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/PublicationBiasBenchmark_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Options for the PublicationBiasBenchmark package — PublicationBiasBenchmark_options","text":"current value available PublicationBiasBenchmark options (applying changes specified) returned invisibly named list.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/PublicationBiasBenchmark_options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Options for the PublicationBiasBenchmark package — PublicationBiasBenchmark_options","text":"\"simulation_directory\" Location benchmark data/results/measures stored \"prompt_for_download\" Whether file download ask explicit approval","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_G_squared.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate sample variance of generic statistic — S_G_squared","title":"Calculate sample variance of generic statistic — S_G_squared","text":"Calculate sample variance generic statistic","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_G_squared.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate sample variance of generic statistic — S_G_squared","text":"","code":"S_G_squared(G)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_G_squared.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate sample variance of generic statistic — S_G_squared","text":"G Vector generic statistics","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_G_squared.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate sample variance of generic statistic — S_G_squared","text":"Sample variance S_G^2","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_theta_minus_theta_squared.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate sample variance of squared errors — S_theta_minus_theta_squared","title":"Calculate sample variance of squared errors — S_theta_minus_theta_squared","text":"Calculate sample variance squared errors","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_theta_minus_theta_squared.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate sample variance of squared errors — S_theta_minus_theta_squared","text":"","code":"S_theta_minus_theta_squared(theta_hat, theta)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_theta_minus_theta_squared.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate sample variance of squared errors — S_theta_minus_theta_squared","text":"theta_hat Vector estimates theta True parameter value","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_theta_minus_theta_squared.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate sample variance of squared errors — S_theta_minus_theta_squared","text":"Sample variance S_(theta_hat - theta)^2","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_theta_squared.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate sample variance of estimates — S_theta_squared","title":"Calculate sample variance of estimates — S_theta_squared","text":"Calculate sample variance estimates","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_theta_squared.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate sample variance of estimates — S_theta_squared","text":"","code":"S_theta_squared(theta_hat)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_theta_squared.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate sample variance of estimates — S_theta_squared","text":"theta_hat Vector estimates","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_theta_squared.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate sample variance of estimates — S_theta_squared","text":"Sample variance S_theta^2","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_w_squared.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate sample variance of CI widths — S_w_squared","title":"Calculate sample variance of CI widths — S_w_squared","text":"Calculate sample variance CI widths","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_w_squared.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate sample variance of CI widths — S_w_squared","text":"","code":"S_w_squared(ci_upper, ci_lower)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_w_squared.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate sample variance of CI widths — S_w_squared","text":"ci_upper Vector upper CI bounds ci_lower Vector lower CI bounds","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/S_w_squared.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate sample variance of CI widths — S_w_squared","text":"Sample variance S_w^2","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compare_measures.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare method with Multiple Measures for a DGM — compare_measures","title":"Compare method with Multiple Measures for a DGM — compare_measures","text":"high-level wrapper function computes multiple pairwise comparison measures Data-Generating Mechanism (DGM) saves results CSV files. provides clean extensible interface comparing method performance.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compare_measures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare method with Multiple Measures for a DGM — compare_measures","text":"","code":"compare_measures(   dgm_name,   method,   method_setting,   measures = NULL,   verbose = TRUE,   estimate_col = \"estimate\",   true_effect_col = \"mean_effect\",   convergence_col = \"convergence\",   method_replacements = NULL,   n_repetitions = 1000,   overwrite = FALSE,   conditions = NULL,   path = NULL )"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compare_measures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare method with Multiple Measures for a DGM — compare_measures","text":"dgm_name Character string specifying name DGM dataset download. method Character vector method names method_setting Character vector method settings, must length method measures Character vector measures compute. NULL, computes standard measures. verbose Print detailed progress calculation. estimate_col Character string specifying column name containing parameter estimates. Default \"estimate\" true_effect_col Character string specifying column name conditions data frame containing true effect sizes. Default \"mean_effect\" convergence_col Character string specifying column name containing convergence indicators. Default \"convergence\" method_replacements Named list replacement method specifications. element named \"method-method_setting\" combination (e.g., \"RMA-default\") contain named list : method: Character vector replacement method names method_setting: Character vector replacement method settings (length methods) power_test_type: Optional character vector power test types replacement method (length methods). specified, uses main power_test_type parameter multiple elements specified within vectors, replacements applied consecutively case previous replacements also failed converge. Defaults NULL, .e., omitting repetitions without converged results method--method basis. n_repetitions Number repetitions condition. Neccessary method replacement. Defaults 1000. overwrite Logical indicating whether overwrite existing files. Defaults FALSE, means missing files downloaded. conditions Data frame conditions dgm_conditions() path Character string specifying directory path datasets/results/measures saved. Defaults location specified via PublicationBiasBenchmark.get_option(\"simulation_directory\"). objects stored dgm_name/datasets, dgm_name/results, dgm_name/measures subfolders.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compare_measures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare method with Multiple Measures for a DGM — compare_measures","text":"Invisible list computed comparison data frames","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compare_single_measure.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare method with a Single Measure for a DGM — compare_single_measure","title":"Compare method with a Single Measure for a DGM — compare_single_measure","text":"function provides pairwise comparison method Data-Generating Mechanisms (DGMs). compares method performance condition--condition basis using estimates. pair method, method estimate closer true value method B, gets score 1, gets 0, equal gets 0.5.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compare_single_measure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare method with a Single Measure for a DGM — compare_single_measure","text":"","code":"compare_single_measure(   dgm_name,   measure_name,   method,   method_setting,   conditions,   estimate_col = \"estimate\",   true_effect_col = \"mean_effect\",   convergence_col = \"convergence\",   method_replacements = NULL,   n_repetitions = 1000,   overwrite = FALSE,   path = NULL,   ... )"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compare_single_measure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare method with a Single Measure for a DGM — compare_single_measure","text":"dgm_name Character string specifying name DGM dataset download. measure_name Name measure compute (e.g., \"bias\", \"mse\") method Character vector method names method_setting Character vector method settings, must length method conditions Data frame conditions dgm_conditions() estimate_col Character string specifying column name containing parameter estimates. Default \"estimate\" true_effect_col Character string specifying column name conditions data frame containing true effect sizes. Default \"mean_effect\" convergence_col Character string specifying column name containing convergence indicators. Default \"convergence\" method_replacements Named list replacement method specifications. element named \"method-method_setting\" combination (e.g., \"RMA-default\") contain named list : method: Character vector replacement method names method_setting: Character vector replacement method settings (length methods) power_test_type: Optional character vector power test types replacement method (length methods). specified, uses main power_test_type parameter multiple elements specified within vectors, replacements applied consecutively case previous replacements also failed converge. Defaults NULL, .e., omitting repetitions without converged results method--method basis. n_repetitions Number repetitions condition. Neccessary method replacement. Defaults 1000. overwrite Logical indicating whether overwrite existing files. Defaults FALSE, means missing files downloaded. path Character string specifying directory path datasets/results/measures saved. Defaults location specified via PublicationBiasBenchmark.get_option(\"simulation_directory\"). objects stored dgm_name/datasets, dgm_name/results, dgm_name/measures subfolders. ... Additional arguments passed measure functions","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compare_single_measure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare method with a Single Measure for a DGM — compare_single_measure","text":"Data frame pairwise comparison scores long format (method_a, method_b, score)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compute_measures.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Multiple Performance measures for a DGM — compute_measures","title":"Compute Multiple Performance measures for a DGM — compute_measures","text":"high-level wrapper function computes multiple performance measures Data-Generating Mechanism (DGM) saves results CSV files. provides clean extensible interface computing standard simulation performance measures.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compute_measures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Multiple Performance measures for a DGM — compute_measures","text":"","code":"compute_measures(   dgm_name,   method,   method_setting,   measures = NULL,   verbose = TRUE,   power_test_type = \"p_value\",   power_threshold_p_value = 0.05,   power_threshold_bayes_factor = 10,   estimate_col = \"estimate\",   true_effect_col = \"mean_effect\",   ci_lower_col = \"ci_lower\",   ci_upper_col = \"ci_upper\",   p_value_col = \"p_value\",   bf_col = \"BF\",   convergence_col = \"convergence\",   method_replacements = NULL,   n_repetitions = 1000,   overwrite = FALSE,   conditions = NULL,   path = NULL )"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compute_measures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Multiple Performance measures for a DGM — compute_measures","text":"dgm_name Character string specifying DGM name method Character vector method names method_setting Character vector method settings, must length method measures Character vector measures compute. NULL, computes standard measures. verbose Print detailed progress calculation. power_test_type Character vector specifying test type power computation: \"p_value\" (default) \"bayes_factor\" method. single value provided, repeated methods. power_threshold_p_value Numeric threshold power computation p-values. Default 0.05 (reject H0 p < 0.05). power_threshold_bayes_factor Numeric threshold power computation Bayes factors. Default 10 (reject H0 BF > 10) estimate_col Character string specifying column name containing parameter estimates. Default \"estimate\" true_effect_col Character string specifying column name conditions data frame containing true effect sizes. Default \"mean_effect\" ci_lower_col Character string specifying column name containing lower confidence interval bounds. Default \"ci_lower\" ci_upper_col Character string specifying column name containing upper confidence interval bounds. Default \"ci_upper\" p_value_col Character string specifying column name containing p-values. Default \"p_value\" bf_col Character string specifying column name containing Bayes factors. Default \"BF\" convergence_col Character string specifying column name containing convergence indicators. Default \"convergence\" method_replacements Named list replacement method specifications. element named \"method-method_setting\" combination (e.g., \"RMA-default\") contain named list : method: Character vector replacement method names method_setting: Character vector replacement method settings (length methods) power_test_type: Optional character vector power test types replacement method (length methods). specified, uses main power_test_type parameter multiple elements specified within vectors, replacements applied consecutively case previous replacements also failed converge. Defaults NULL, .e., omitting repetitions without converged results method--method basis. n_repetitions Number repetitions condition. Neccessary method replacement. Defaults 1000. overwrite Logical indicating whether overwrite existing results. FALSE (default), skip computation method-measure combinations already exist conditions Data frame conditions dgm_conditions() path Character string specifying directory path datasets/results/measures saved. Defaults location specified via PublicationBiasBenchmark.get_option(\"simulation_directory\"). objects stored dgm_name/datasets, dgm_name/results, dgm_name/measures subfolders.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compute_measures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Multiple Performance measures for a DGM — compute_measures","text":"Invisible list computed measures data frames","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compute_measures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Multiple Performance measures for a DGM — compute_measures","text":"","code":"if (FALSE) { # \\dontrun{ # Download DGM results dgm_name <- \"no_bias\" download_dgm_results(dgm_name)  # Basic usage compute_measures(   dgm_name        = dgm_name,   method          = c(\"mean\", \"RMA\", \"PET\"),   method_setting  = c(\"default\", \"default\", \"default\"),   measures        = c(\"bias\", \"mse\", \"coverage\") )  # With method replacements for non-converged results method_replacements <- list(   \"RMA-default\" = list(method = \"FMA\", method_setting = \"default\"),   \"PET-default\" = list(method = c(\"WLS\", \"FMA\"),                         method_setting = c(\"default\", \"default\")) )  compute_measures(   dgm_name            = dgm_name,   method              = c(\"RMA\", \"PET\"),   method_setting      = c(\"default\", \"default\"),   method_replacements = method_replacements,   measures            = c(\"bias\", \"mse\") ) } # }"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compute_single_measure.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Performance Measures — compute_single_measure","title":"Compute Performance Measures — compute_single_measure","text":"function provides modular extensible way compute performance measures (PM) Data-Generating Mechanisms (DGMs). handles different types measures automatically determines required arguments measure function.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compute_single_measure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Performance Measures — compute_single_measure","text":"","code":"compute_single_measure(   dgm_name,   measure_name,   method,   method_setting,   conditions,   measure_fun,   measure_mcse_fun,   power_test_type = \"p_value\",   estimate_col = \"estimate\",   true_effect_col = \"mean_effect\",   ci_lower_col = \"ci_lower\",   ci_upper_col = \"ci_upper\",   p_value_col = \"p_value\",   bf_col = \"BF\",   convergence_col = \"convergence\",   power_threshold_p_value = 0.05,   power_threshold_bayes_factor = 10,   method_replacements = NULL,   n_repetitions = 1000,   overwrite = FALSE,   path = NULL,   ... )"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compute_single_measure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Performance Measures — compute_single_measure","text":"dgm_name Character string specifying DGM name measure_name Name measure compute (e.g., \"bias\", \"mse\") method Character vector method names method_setting Character vector method settings, must length method conditions Data frame conditions dgm_conditions() measure_fun Function compute measure measure_mcse_fun Function compute MCSE measure power_test_type Character vector specifying test type power computation: \"p_value\" (default) \"bayes_factor\" method. single value provided, repeated methods. estimate_col Character string specifying column name containing parameter estimates. Default \"estimate\" true_effect_col Character string specifying column name conditions data frame containing true effect sizes. Default \"mean_effect\" ci_lower_col Character string specifying column name containing lower confidence interval bounds. Default \"ci_lower\" ci_upper_col Character string specifying column name containing upper confidence interval bounds. Default \"ci_upper\" p_value_col Character string specifying column name containing p-values. Default \"p_value\" bf_col Character string specifying column name containing Bayes factors. Default \"BF\" convergence_col Character string specifying column name containing convergence indicators. Default \"convergence\" power_threshold_p_value Numeric threshold power computation p-values. Default 0.05 (reject H0 p < 0.05). power_threshold_bayes_factor Numeric threshold power computation Bayes factors. Default 10 (reject H0 BF > 10) method_replacements Named list replacement method specifications. element named \"method-method_setting\" combination (e.g., \"RMA-default\") contain named list : method: Character vector replacement method names method_setting: Character vector replacement method settings (length methods) power_test_type: Optional character vector power test types replacement method (length methods). specified, uses main power_test_type parameter multiple elements specified within vectors, replacements applied consecutively case previous replacements also failed converge. Defaults NULL, .e., omitting repetitions without converged results method--method basis. n_repetitions Number repetitions condition. Neccessary method replacement. Defaults 1000. overwrite Logical indicating whether overwrite existing results. FALSE (default), skip computation method-measure combinations already exist path Character string specifying directory path datasets/results/measures saved. Defaults location specified via PublicationBiasBenchmark.get_option(\"simulation_directory\"). objects stored dgm_name/datasets, dgm_name/results, dgm_name/measures subfolders. ... Additional arguments passed measure functions","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compute_single_measure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Performance Measures — compute_single_measure","text":"Data frame computed measures MCSEs","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/compute_single_measure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Performance Measures — compute_single_measure","text":"","code":"if (FALSE) { # \\dontrun{ # Get conditions for a DGM conditions <- dgm_conditions(\"no_bias\")   } # }"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/create_empty_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Create standardized empty method result for convergence failures — create_empty_result","title":"Create standardized empty method result for convergence failures — create_empty_result","text":"Create standardized empty method result convergence failures","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/create_empty_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create standardized empty method result for convergence failures — create_empty_result","text":"","code":"create_empty_result(method_name, note, extra_columns = NULL)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/create_empty_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create standardized empty method result for convergence failures — create_empty_result","text":"method_name Character string method name note Character string describing failure reason extra_columns Character vector additional empty columns add table","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/create_empty_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create standardized empty method result for convergence failures — create_empty_result","text":"Data frame standardized empty result structure","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Alinaghi2018.html","id":null,"dir":"Reference","previous_headings":"","what":"Alinaghi and Reed (2018) Data-Generating Mechansim — dgm.Alinaghi2018","title":"Alinaghi and Reed (2018) Data-Generating Mechansim — dgm.Alinaghi2018","text":"data-generating mechanism simulates univariate regression studies variable X affects continuous outcome Y. study estimates coefficient X, consists fixed component (α1) representing overall mean effect, random component varies across studies constant within study. \"Random Effects\" environment (\"RE\"), study produces one estimate, population effect differs across studies. description code based Hong Reed (2021) . data-generating mechanism introduced Alinaghi Reed (2018) .","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Alinaghi2018.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Alinaghi and Reed (2018) Data-Generating Mechansim — dgm.Alinaghi2018","text":"","code":"# S3 method for class 'Alinaghi2018' dgm(dgm_name, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Alinaghi2018.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Alinaghi and Reed (2018) Data-Generating Mechansim — dgm.Alinaghi2018","text":"dgm_name DGM name (automatically passed) settings List containing environment Type simulation environment. One \"FE\", \"RE\", \"PRE\". mean_effect Mean effect bias Type publication bias. One \"none\", \"positive\", \"significant\".","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Alinaghi2018.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Alinaghi and Reed (2018) Data-Generating Mechansim — dgm.Alinaghi2018","text":"Data frame yi effect size sei standard error ni sample size study_id study identifier es_type effect size type","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Alinaghi2018.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Alinaghi and Reed (2018) Data-Generating Mechansim — dgm.Alinaghi2018","text":"data-generating mechanism based Alinaghi & Reed (2018), study univariate regression models variable X affects continuous variable Y. parameter interest coefficient X. \"Random Effects\" environment, study produces one estimate, population effect differs across studies. coefficient X equals fixed component (α1) plus random component fixed within study varies across studies. overall mean effect X Y given α1. distinctive feature Alinaghi & Reed's experiments sample size estimated effects fixed publication selection, making meta-analyst's sample size endogenous affected effect size. Large population effects subject less publication selection, estimates satisfy selection criteria (statistical significance correct sign). Another feature separation statistical significance sign estimated effect criteria selection. Significant/correctly-signed estimates always \"published,\" insignificant/wrong-signed estimates 10% chance published. allows different sometimes conflicting consequences estimator performance. simulations designed representative meta-analyses economics business, typically several hundred estimates substantial effect heterogeneity. addition \"Random Effects\" environment, \"Panel Random Effects\" environment included, study 10 estimates, modeling common scenario multiple estimates per study. Effect estimates standard errors simulated similar within studies across studies, publication selection targets study rather individual estimates. inclusion meta-analyst's sample, study must least 7 10 estimates significant correctly signed.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Alinaghi2018.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Alinaghi and Reed (2018) Data-Generating Mechansim — dgm.Alinaghi2018","text":"Alinaghi N, Reed WR (2018). “Meta-analysis publication bias: well FAT-PET-PEESE procedure work?” Research Synthesis Methods, 9(2), 285-311. doi:10.1002/jrsm.1298 . Hong S, Reed WR (2021). “Using Monte Carlo experiments select meta-analytic estimators.” Research Synthesis Methods, 12(2), 192-215. doi:10.1002/jrsm.1467 .","code":""},{"path":[]},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Bom2019.html","id":null,"dir":"Reference","previous_headings":"","what":"Bom and Rachinger (2019) Data-Generating Mechanism — dgm.Bom2019","title":"Bom and Rachinger (2019) Data-Generating Mechanism — dgm.Bom2019","text":"Simulates univariate regression environments estimate effect X1 Y (parameter α1). Effect heterogeneity introduced via omitted variable (X2) correlated X1, whose coefficient (α2) randomly distributed mean zero variance σ2_h. description code based Hong Reed (2021) . data-generating mechanism introduced Bom Rachinger (2019) .","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Bom2019.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bom and Rachinger (2019) Data-Generating Mechanism — dgm.Bom2019","text":"","code":"# S3 method for class 'Bom2019' dgm(dgm_name, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Bom2019.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bom and Rachinger (2019) Data-Generating Mechanism — dgm.Bom2019","text":"dgm_name DGM name (automatically passed) settings List containing mean_effect Mean effect effect_heterogeneity Mean effect heterogeneity bias Proportion studies affected publication bias n_studies Number effect size estimates sample_sizes Sample sizes effect size estimates. vector sample sizes needs supplied. sample sizes vector sequentially reused effect size estimates generated.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Bom2019.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bom and Rachinger (2019) Data-Generating Mechanism — dgm.Bom2019","text":"Data frame yi effect size sei standard error ni sample size es_type effect size type","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Bom2019.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bom and Rachinger (2019) Data-Generating Mechanism — dgm.Bom2019","text":"function simulates univariate regression environments, focusing estimating effect variable X1 dependent variable Y, represented parameter α1. simulation introduces variation standard errors estimated effects allowing sample sizes differ across primary studies. Effect heterogeneity modeled omitted variable (X2) correlated X1, coefficient omitted variable, α2, randomly distributed across studies mean zero variance σ2_h. Individual estimates α1 subject bias α2 nonzero due omitted variable. Across population studies, omitted variable bias averages . However, publication selection present—selection depends sign significance estimated effect α^1—bias induced meta-analyst's sample. Publication selection modeled two regimes: (1) selection, (2) 50% selection. 50% selection, estimate 50% chance evaluated inclusion. selected, positive statistically significant estimates published; otherwise, new estimates generated criterion met. process continues meta-analyst’s sample reaches predetermined size.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Bom2019.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bom and Rachinger (2019) Data-Generating Mechanism — dgm.Bom2019","text":"Bom PR, Rachinger H (2019). “kinked meta-regression model publication bias correction.” Research Synthesis Methods, 10(4), 497-514. doi:10.1002/jrsm.1352 . Hong S, Reed WR (2021). “Using Monte Carlo experiments select meta-analytic estimators.” Research Synthesis Methods, 12(2), 192-215. doi:10.1002/jrsm.1467 .","code":""},{"path":[]},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Carter2019.html","id":null,"dir":"Reference","previous_headings":"","what":"Carter et al. (2019) Data-Generating Mechanism — dgm.Carter2019","title":"Carter et al. (2019) Data-Generating Mechanism — dgm.Carter2019","text":"data-generating mechanism simulates primary studies estimating treatment effects using Cohen's d. observed effect size modeled fixed mean plus random heterogeneity across studies, sample sizes varying generate differences standard errors. simulation introduces publication bias via selection algorithm probability publication depends nonlinearly sign p-value effect, regimes , medium, strong publication bias. also incorporates questionable research practices (QRPs) optional outlier removal, selection dependent variables, use moderators, optional stopping. description code based Hong Reed (2021) . data-generating mechanism introduced Carter et al. (2019) .","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Carter2019.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Carter et al. (2019) Data-Generating Mechanism — dgm.Carter2019","text":"","code":"# S3 method for class 'Carter2019' dgm(dgm_name, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Carter2019.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Carter et al. (2019) Data-Generating Mechanism — dgm.Carter2019","text":"dgm_name DGM name (automatically passed) settings List containing mean_effect Mean effect effect_heterogeneity Mean effect heterogeneity bias Degree publication bias one following levels: \"none\", \"medium\", \"high\". QRP Degree questionable research practices one following levels: \"none\", \"medium\", \"high\". n_studies Number effect size estimates","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Carter2019.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Carter et al. (2019) Data-Generating Mechanism — dgm.Carter2019","text":"Data frame yi effect size sei standard error ni sample size es_type effect size type","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Carter2019.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Carter et al. (2019) Data-Generating Mechanism — dgm.Carter2019","text":"simulation environment based framework described Carter, Schönbrodt, Gervais, Hilgard (2019). setup, primary studies estimate effect treatment using Cohen's d effect size metric. observed difference treatment control groups modeled sum fixed effect (α1) random component, introduces effect heterogeneity across studies. degree heterogeneity controlled parameter σ2_h. Variability standard errors d generated simulating primary studies different sample sizes. simulation incorporates two main types distortions research environment. First, publication selection algorithm used, probability study \"published\" depends nonlinearly sign estimated effect P-value. Three publication selection regimes modeled: \"Publication Bias,\" \"Medium Publication Bias,\" \"Strong Publication Bias,\" defined different parameters selection algorithm. Second, simulation includes four types questionable research practices (QRPs): () optional removal outliers, (b) optional selection two dependent variables, (c) optional use moderators, (d) optional stopping.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Carter2019.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Carter et al. (2019) Data-Generating Mechanism — dgm.Carter2019","text":"Carter EC, Schönbrodt FD, Gervais WM, Hilgard J (2019). “Correcting bias psychology: comparison meta-analytic methods.” Advances Methods Practices Psychological Science, 2(2), 115-144. doi:10.1177/2515245919847196 . Hong S, Reed WR (2021). “Using Monte Carlo experiments select meta-analytic estimators.” Research Synthesis Methods, 12(2), 192-215. doi:10.1002/jrsm.1467 .","code":""},{"path":[]},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Stanley2017.html","id":null,"dir":"Reference","previous_headings":"","what":"Stanley, Doucouliagos, and Ioannidis (2017) Data-Generating Mechanism — dgm.Stanley2017","title":"Stanley, Doucouliagos, and Ioannidis (2017) Data-Generating Mechanism — dgm.Stanley2017","text":"Simulates two scenarios meta-analysis studies investigating effect treatment : (1) Log Odds Ratio scenario, outcome binary effect heterogeneity controlled random component, (2) Cohen's d scenario, outcome continuous effect heterogeneity introduced random component. scenarios allow varying sample sizes publication selection regimes, affecting inclusion study estimates based statistical significance sign. description code based Hong Reed (2021) . data-generating mechanism introduced Stanley et al. (2017) .","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Stanley2017.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stanley, Doucouliagos, and Ioannidis (2017) Data-Generating Mechanism — dgm.Stanley2017","text":"","code":"# S3 method for class 'Stanley2017' dgm(dgm_name, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Stanley2017.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stanley, Doucouliagos, and Ioannidis (2017) Data-Generating Mechanism — dgm.Stanley2017","text":"dgm_name DGM name (automatically passed) settings List containing environment Type simulation environment. One \"LogOR\" \"Cohens_d\". mean_effect Mean effect effect_heterogeneity Mean effect heterogeneity bias Proportion studies affected publication bias n_studies Number effect size estimates sample_sizes Sample sizes effect size estimates. vector sample sizes needs supplied. sample sizes vector sequentially reused effect size estimates generated.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Stanley2017.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stanley, Doucouliagos, and Ioannidis (2017) Data-Generating Mechanism — dgm.Stanley2017","text":"Data frame yi effect size sei standard error ni sample size es_type effect size type","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Stanley2017.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Stanley, Doucouliagos, and Ioannidis (2017) Data-Generating Mechanism — dgm.Stanley2017","text":"function simulates two meta-analysis scenarios evaluate effect binary treatment variable (treat = {0, 1}) study outcomes, incorporating effect heterogeneity publication selection mechanisms. Log Odds Ratio (\"LogOR\") scenario, primary studies assess impact treatment binary success indicator (Y = 1). control group fixed 10% probability success, treatment group’s probability increased fixed effect mean-zero random component, whose variance (σ²_h) controls effect heterogeneity. study estimates logistic regression, coefficient treat (α₁) effect interest. Study sample sizes vary, resulting different standard errors estimated effects. Cohen's d (\"Cohens_d\") scenario, outcome variable continuous. treatment effect modeled fixed effect (α₁) plus random component (variance σ²_h). study computes Cohen's d, standardized mean difference treatment control groups. Study sample sizes vary, affecting standard errors d. Publication selection modeled two regimes: (1) selection, (2) 50% selection. 50% selection, estimate 50% chance evaluated inclusion. selected, positive statistically significant estimates published; otherwise, new estimates generated criterion met. process continues meta-analyst’s sample reaches predetermined size.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.Stanley2017.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stanley, Doucouliagos, and Ioannidis (2017) Data-Generating Mechanism — dgm.Stanley2017","text":"Hong S, Reed WR (2021). “Using Monte Carlo experiments select meta-analytic estimators.” Research Synthesis Methods, 12(2), 192-215. doi:10.1002/jrsm.1467 . Stanley TD, Doucouliagos H, Ioannidis JP (2017). “Finding power reduce publication bias.” Statistics Medicine, 36(10), 1580-1598. doi:10.1002/sim.7228 .","code":""},{"path":[]},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Default DGM handler — dgm.default","title":"Default DGM handler — dgm.default","text":"Default DGM handler","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default DGM handler — dgm.default","text":"","code":"# Default S3 method dgm(dgm_name, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default DGM handler — dgm.default","text":"dgm_name Character string specifying DGM type settings List containing required parameters DGM numeric condition_id","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.html","id":null,"dir":"Reference","previous_headings":"","what":"DGM Method — dgm","title":"DGM Method — dgm","text":"S3 Method defining data-generating mechanisms. See simulate_dgm() usage details.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DGM Method — dgm","text":"","code":"dgm(dgm_name, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DGM Method — dgm","text":"dgm_name Character string specifying DGM type settings List containing required parameters DGM numeric condition_id","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.html","id":"output-structure","dir":"Reference","previous_headings":"","what":"Output Structure","title":"DGM Method — dgm","text":"returned data frame follows standardized schema downstream functions rely . Across currently implemented DGMs, following columns used: yi (numeric): effect size estimate. sei (numeric): Standard error yi. ni (integer): Total sample size estimate (e.g., sum groups applicable). es_type (character): Effect size type, used disambiguate scale yi. Currently used values \"SMD\" (standardized mean difference / Cohen's d), \"logOR\" (log odds ratio), \"none\" (unspecified generic continuous coefficient). study_id (integer/character, optional): Identifier primary study/cluster DGM yields multiple estimates per study (e.g., Alinaghi2018, PRE). absent, row treated independent study.","code":""},{"path":[]},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"DGM Method — dgm","text":"","code":"simulate_dgm(\"Carter2019\", 1) #>              yi        sei  ni es_type #> 1  -0.266375111 0.35511784  32     SMD #> 2  -0.034256712 0.28869631  48     SMD #> 3   0.853607266 0.39480206  28     SMD #> 4   0.048247281 0.13547680 218     SMD #> 5   0.035897696 0.11010524 330     SMD #> 6  -0.022978317 0.42641550  22     SMD #> 7   0.088991270 0.09432756 450     SMD #> 8   0.266440019 0.44919345  20     SMD #> 9   0.214691131 0.15662302 164     SMD #> 10  0.001202358 0.44721364  20     SMD"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.no_bias.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal Unbiased Data-Generating Mechanism — dgm.no_bias","title":"Normal Unbiased Data-Generating Mechanism — dgm.no_bias","text":"example data-generating mechanism simulate effect sizes without publication bias.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.no_bias.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal Unbiased Data-Generating Mechanism — dgm.no_bias","text":"","code":"# S3 method for class 'no_bias' dgm(dgm_name, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.no_bias.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal Unbiased Data-Generating Mechanism — dgm.no_bias","text":"dgm_name DGM name (automatically passed) settings List containing mean_effect Mean effect heterogeneity Effect heterogeneity n_studies Number effect size estimates","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.no_bias.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normal Unbiased Data-Generating Mechanism — dgm.no_bias","text":"Data frame yi effect size sei standard error es_type effect size type","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.no_bias.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normal Unbiased Data-Generating Mechanism — dgm.no_bias","text":"Sample sizes individual effect size estimates generated negative binomial distribution based empirical sample size distribution presented Appendix B Maier et al. (2023)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm.no_bias.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Normal Unbiased Data-Generating Mechanism — dgm.no_bias","text":"Maier M, Bartoš F, Wagenmakers E (2023). “Robust Bayesian meta-analysis: Addressing publication bias model-averaging.” Psychological Methods, 28(1), 107-122. doi:10.1037/met0000405 .","code":""},{"path":[]},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm_conditions.html","id":null,"dir":"Reference","previous_headings":"","what":"Return Pre-specified DGM Settings — dgm_conditions","title":"Return Pre-specified DGM Settings — dgm_conditions","text":"function returns list pre-specified settings given Data Generating Mechanism (DGM).","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm_conditions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return Pre-specified DGM Settings — dgm_conditions","text":"","code":"dgm_conditions(dgm_name)  get_dgm_condition(dgm_name, condition_id)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm_conditions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return Pre-specified DGM Settings — dgm_conditions","text":"dgm_name Character string specifying DGM type condition_id conditions settings returned .","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm_conditions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return Pre-specified DGM Settings — dgm_conditions","text":"data frame containing pre-specified settings including condition_id column maps settings id corresponding settings.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/dgm_conditions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return Pre-specified DGM Settings — dgm_conditions","text":"","code":"dgm_conditions(\"Carter2019\") #>     n_studies mean_effect    QRP   bias effect_heterogeneity condition_id #> 1          10         0.0   none   none                  0.0            1 #> 2          30         0.0   none   none                  0.0            2 #> 3          60         0.0   none   none                  0.0            3 #> 4         100         0.0   none   none                  0.0            4 #> 5          10         0.2   none   none                  0.0            5 #> 6          30         0.2   none   none                  0.0            6 #> 7          60         0.2   none   none                  0.0            7 #> 8         100         0.2   none   none                  0.0            8 #> 9          10         0.5   none   none                  0.0            9 #> 10         30         0.5   none   none                  0.0           10 #> 11         60         0.5   none   none                  0.0           11 #> 12        100         0.5   none   none                  0.0           12 #> 13         10         0.8   none   none                  0.0           13 #> 14         30         0.8   none   none                  0.0           14 #> 15         60         0.8   none   none                  0.0           15 #> 16        100         0.8   none   none                  0.0           16 #> 17         10         0.0 medium   none                  0.0           17 #> 18         30         0.0 medium   none                  0.0           18 #> 19         60         0.0 medium   none                  0.0           19 #> 20        100         0.0 medium   none                  0.0           20 #> 21         10         0.2 medium   none                  0.0           21 #> 22         30         0.2 medium   none                  0.0           22 #> 23         60         0.2 medium   none                  0.0           23 #> 24        100         0.2 medium   none                  0.0           24 #> 25         10         0.5 medium   none                  0.0           25 #> 26         30         0.5 medium   none                  0.0           26 #> 27         60         0.5 medium   none                  0.0           27 #> 28        100         0.5 medium   none                  0.0           28 #> 29         10         0.8 medium   none                  0.0           29 #> 30         30         0.8 medium   none                  0.0           30 #> 31         60         0.8 medium   none                  0.0           31 #> 32        100         0.8 medium   none                  0.0           32 #> 33         10         0.0   high   none                  0.0           33 #> 34         30         0.0   high   none                  0.0           34 #> 35         60         0.0   high   none                  0.0           35 #> 36        100         0.0   high   none                  0.0           36 #> 37         10         0.2   high   none                  0.0           37 #> 38         30         0.2   high   none                  0.0           38 #> 39         60         0.2   high   none                  0.0           39 #> 40        100         0.2   high   none                  0.0           40 #> 41         10         0.5   high   none                  0.0           41 #> 42         30         0.5   high   none                  0.0           42 #> 43         60         0.5   high   none                  0.0           43 #> 44        100         0.5   high   none                  0.0           44 #> 45         10         0.8   high   none                  0.0           45 #> 46         30         0.8   high   none                  0.0           46 #> 47         60         0.8   high   none                  0.0           47 #> 48        100         0.8   high   none                  0.0           48 #> 49         10         0.0   none medium                  0.0           49 #> 50         30         0.0   none medium                  0.0           50 #> 51         60         0.0   none medium                  0.0           51 #> 52        100         0.0   none medium                  0.0           52 #> 53         10         0.2   none medium                  0.0           53 #> 54         30         0.2   none medium                  0.0           54 #> 55         60         0.2   none medium                  0.0           55 #> 56        100         0.2   none medium                  0.0           56 #> 57         10         0.5   none medium                  0.0           57 #> 58         30         0.5   none medium                  0.0           58 #> 59         60         0.5   none medium                  0.0           59 #> 60        100         0.5   none medium                  0.0           60 #> 61         10         0.8   none medium                  0.0           61 #> 62         30         0.8   none medium                  0.0           62 #> 63         60         0.8   none medium                  0.0           63 #> 64        100         0.8   none medium                  0.0           64 #> 65         10         0.0 medium medium                  0.0           65 #> 66         30         0.0 medium medium                  0.0           66 #> 67         60         0.0 medium medium                  0.0           67 #> 68        100         0.0 medium medium                  0.0           68 #> 69         10         0.2 medium medium                  0.0           69 #> 70         30         0.2 medium medium                  0.0           70 #> 71         60         0.2 medium medium                  0.0           71 #> 72        100         0.2 medium medium                  0.0           72 #> 73         10         0.5 medium medium                  0.0           73 #> 74         30         0.5 medium medium                  0.0           74 #> 75         60         0.5 medium medium                  0.0           75 #> 76        100         0.5 medium medium                  0.0           76 #> 77         10         0.8 medium medium                  0.0           77 #> 78         30         0.8 medium medium                  0.0           78 #> 79         60         0.8 medium medium                  0.0           79 #> 80        100         0.8 medium medium                  0.0           80 #> 81         10         0.0   high medium                  0.0           81 #> 82         30         0.0   high medium                  0.0           82 #> 83         60         0.0   high medium                  0.0           83 #> 84        100         0.0   high medium                  0.0           84 #> 85         10         0.2   high medium                  0.0           85 #> 86         30         0.2   high medium                  0.0           86 #> 87         60         0.2   high medium                  0.0           87 #> 88        100         0.2   high medium                  0.0           88 #> 89         10         0.5   high medium                  0.0           89 #> 90         30         0.5   high medium                  0.0           90 #> 91         60         0.5   high medium                  0.0           91 #> 92        100         0.5   high medium                  0.0           92 #> 93         10         0.8   high medium                  0.0           93 #> 94         30         0.8   high medium                  0.0           94 #> 95         60         0.8   high medium                  0.0           95 #> 96        100         0.8   high medium                  0.0           96 #> 97         10         0.0   none   high                  0.0           97 #> 98         30         0.0   none   high                  0.0           98 #> 99         60         0.0   none   high                  0.0           99 #> 100       100         0.0   none   high                  0.0          100 #> 101        10         0.2   none   high                  0.0          101 #> 102        30         0.2   none   high                  0.0          102 #> 103        60         0.2   none   high                  0.0          103 #> 104       100         0.2   none   high                  0.0          104 #> 105        10         0.5   none   high                  0.0          105 #> 106        30         0.5   none   high                  0.0          106 #> 107        60         0.5   none   high                  0.0          107 #> 108       100         0.5   none   high                  0.0          108 #> 109        10         0.8   none   high                  0.0          109 #> 110        30         0.8   none   high                  0.0          110 #> 111        60         0.8   none   high                  0.0          111 #> 112       100         0.8   none   high                  0.0          112 #> 113        10         0.0 medium   high                  0.0          113 #> 114        30         0.0 medium   high                  0.0          114 #> 115        60         0.0 medium   high                  0.0          115 #> 116       100         0.0 medium   high                  0.0          116 #> 117        10         0.2 medium   high                  0.0          117 #> 118        30         0.2 medium   high                  0.0          118 #> 119        60         0.2 medium   high                  0.0          119 #> 120       100         0.2 medium   high                  0.0          120 #> 121        10         0.5 medium   high                  0.0          121 #> 122        30         0.5 medium   high                  0.0          122 #> 123        60         0.5 medium   high                  0.0          123 #> 124       100         0.5 medium   high                  0.0          124 #> 125        10         0.8 medium   high                  0.0          125 #> 126        30         0.8 medium   high                  0.0          126 #> 127        60         0.8 medium   high                  0.0          127 #> 128       100         0.8 medium   high                  0.0          128 #> 129        10         0.0   high   high                  0.0          129 #> 130        30         0.0   high   high                  0.0          130 #> 131        60         0.0   high   high                  0.0          131 #> 132       100         0.0   high   high                  0.0          132 #> 133        10         0.2   high   high                  0.0          133 #> 134        30         0.2   high   high                  0.0          134 #> 135        60         0.2   high   high                  0.0          135 #> 136       100         0.2   high   high                  0.0          136 #> 137        10         0.5   high   high                  0.0          137 #> 138        30         0.5   high   high                  0.0          138 #> 139        60         0.5   high   high                  0.0          139 #> 140       100         0.5   high   high                  0.0          140 #> 141        10         0.8   high   high                  0.0          141 #> 142        30         0.8   high   high                  0.0          142 #> 143        60         0.8   high   high                  0.0          143 #> 144       100         0.8   high   high                  0.0          144 #> 145        10         0.0   none   none                  0.2          145 #> 146        30         0.0   none   none                  0.2          146 #> 147        60         0.0   none   none                  0.2          147 #> 148       100         0.0   none   none                  0.2          148 #> 149        10         0.2   none   none                  0.2          149 #> 150        30         0.2   none   none                  0.2          150 #> 151        60         0.2   none   none                  0.2          151 #> 152       100         0.2   none   none                  0.2          152 #> 153        10         0.5   none   none                  0.2          153 #> 154        30         0.5   none   none                  0.2          154 #> 155        60         0.5   none   none                  0.2          155 #> 156       100         0.5   none   none                  0.2          156 #> 157        10         0.8   none   none                  0.2          157 #> 158        30         0.8   none   none                  0.2          158 #> 159        60         0.8   none   none                  0.2          159 #> 160       100         0.8   none   none                  0.2          160 #> 161        10         0.0 medium   none                  0.2          161 #> 162        30         0.0 medium   none                  0.2          162 #> 163        60         0.0 medium   none                  0.2          163 #> 164       100         0.0 medium   none                  0.2          164 #> 165        10         0.2 medium   none                  0.2          165 #> 166        30         0.2 medium   none                  0.2          166 #> 167        60         0.2 medium   none                  0.2          167 #> 168       100         0.2 medium   none                  0.2          168 #> 169        10         0.5 medium   none                  0.2          169 #> 170        30         0.5 medium   none                  0.2          170 #> 171        60         0.5 medium   none                  0.2          171 #> 172       100         0.5 medium   none                  0.2          172 #> 173        10         0.8 medium   none                  0.2          173 #> 174        30         0.8 medium   none                  0.2          174 #> 175        60         0.8 medium   none                  0.2          175 #> 176       100         0.8 medium   none                  0.2          176 #> 177        10         0.0   high   none                  0.2          177 #> 178        30         0.0   high   none                  0.2          178 #> 179        60         0.0   high   none                  0.2          179 #> 180       100         0.0   high   none                  0.2          180 #> 181        10         0.2   high   none                  0.2          181 #> 182        30         0.2   high   none                  0.2          182 #> 183        60         0.2   high   none                  0.2          183 #> 184       100         0.2   high   none                  0.2          184 #> 185        10         0.5   high   none                  0.2          185 #> 186        30         0.5   high   none                  0.2          186 #> 187        60         0.5   high   none                  0.2          187 #> 188       100         0.5   high   none                  0.2          188 #> 189        10         0.8   high   none                  0.2          189 #> 190        30         0.8   high   none                  0.2          190 #> 191        60         0.8   high   none                  0.2          191 #> 192       100         0.8   high   none                  0.2          192 #> 193        10         0.0   none medium                  0.2          193 #> 194        30         0.0   none medium                  0.2          194 #> 195        60         0.0   none medium                  0.2          195 #> 196       100         0.0   none medium                  0.2          196 #> 197        10         0.2   none medium                  0.2          197 #> 198        30         0.2   none medium                  0.2          198 #> 199        60         0.2   none medium                  0.2          199 #> 200       100         0.2   none medium                  0.2          200 #> 201        10         0.5   none medium                  0.2          201 #> 202        30         0.5   none medium                  0.2          202 #> 203        60         0.5   none medium                  0.2          203 #> 204       100         0.5   none medium                  0.2          204 #> 205        10         0.8   none medium                  0.2          205 #> 206        30         0.8   none medium                  0.2          206 #> 207        60         0.8   none medium                  0.2          207 #> 208       100         0.8   none medium                  0.2          208 #> 209        10         0.0 medium medium                  0.2          209 #> 210        30         0.0 medium medium                  0.2          210 #> 211        60         0.0 medium medium                  0.2          211 #> 212       100         0.0 medium medium                  0.2          212 #> 213        10         0.2 medium medium                  0.2          213 #> 214        30         0.2 medium medium                  0.2          214 #> 215        60         0.2 medium medium                  0.2          215 #> 216       100         0.2 medium medium                  0.2          216 #> 217        10         0.5 medium medium                  0.2          217 #> 218        30         0.5 medium medium                  0.2          218 #> 219        60         0.5 medium medium                  0.2          219 #> 220       100         0.5 medium medium                  0.2          220 #> 221        10         0.8 medium medium                  0.2          221 #> 222        30         0.8 medium medium                  0.2          222 #> 223        60         0.8 medium medium                  0.2          223 #> 224       100         0.8 medium medium                  0.2          224 #> 225        10         0.0   high medium                  0.2          225 #> 226        30         0.0   high medium                  0.2          226 #> 227        60         0.0   high medium                  0.2          227 #> 228       100         0.0   high medium                  0.2          228 #> 229        10         0.2   high medium                  0.2          229 #> 230        30         0.2   high medium                  0.2          230 #> 231        60         0.2   high medium                  0.2          231 #> 232       100         0.2   high medium                  0.2          232 #> 233        10         0.5   high medium                  0.2          233 #> 234        30         0.5   high medium                  0.2          234 #> 235        60         0.5   high medium                  0.2          235 #> 236       100         0.5   high medium                  0.2          236 #> 237        10         0.8   high medium                  0.2          237 #> 238        30         0.8   high medium                  0.2          238 #> 239        60         0.8   high medium                  0.2          239 #> 240       100         0.8   high medium                  0.2          240 #> 241        10         0.0   none   high                  0.2          241 #> 242        30         0.0   none   high                  0.2          242 #> 243        60         0.0   none   high                  0.2          243 #> 244       100         0.0   none   high                  0.2          244 #> 245        10         0.2   none   high                  0.2          245 #> 246        30         0.2   none   high                  0.2          246 #> 247        60         0.2   none   high                  0.2          247 #> 248       100         0.2   none   high                  0.2          248 #> 249        10         0.5   none   high                  0.2          249 #> 250        30         0.5   none   high                  0.2          250 #> 251        60         0.5   none   high                  0.2          251 #> 252       100         0.5   none   high                  0.2          252 #> 253        10         0.8   none   high                  0.2          253 #> 254        30         0.8   none   high                  0.2          254 #> 255        60         0.8   none   high                  0.2          255 #> 256       100         0.8   none   high                  0.2          256 #> 257        10         0.0 medium   high                  0.2          257 #> 258        30         0.0 medium   high                  0.2          258 #> 259        60         0.0 medium   high                  0.2          259 #> 260       100         0.0 medium   high                  0.2          260 #> 261        10         0.2 medium   high                  0.2          261 #> 262        30         0.2 medium   high                  0.2          262 #> 263        60         0.2 medium   high                  0.2          263 #> 264       100         0.2 medium   high                  0.2          264 #> 265        10         0.5 medium   high                  0.2          265 #> 266        30         0.5 medium   high                  0.2          266 #> 267        60         0.5 medium   high                  0.2          267 #> 268       100         0.5 medium   high                  0.2          268 #> 269        10         0.8 medium   high                  0.2          269 #> 270        30         0.8 medium   high                  0.2          270 #> 271        60         0.8 medium   high                  0.2          271 #> 272       100         0.8 medium   high                  0.2          272 #> 273        10         0.0   high   high                  0.2          273 #> 274        30         0.0   high   high                  0.2          274 #> 275        60         0.0   high   high                  0.2          275 #> 276       100         0.0   high   high                  0.2          276 #> 277        10         0.2   high   high                  0.2          277 #> 278        30         0.2   high   high                  0.2          278 #> 279        60         0.2   high   high                  0.2          279 #> 280       100         0.2   high   high                  0.2          280 #> 281        10         0.5   high   high                  0.2          281 #> 282        30         0.5   high   high                  0.2          282 #> 283        60         0.5   high   high                  0.2          283 #> 284       100         0.5   high   high                  0.2          284 #> 285        10         0.8   high   high                  0.2          285 #> 286        30         0.8   high   high                  0.2          286 #> 287        60         0.8   high   high                  0.2          287 #> 288       100         0.8   high   high                  0.2          288 #> 289        10         0.0   none   none                  0.4          289 #> 290        30         0.0   none   none                  0.4          290 #> 291        60         0.0   none   none                  0.4          291 #> 292       100         0.0   none   none                  0.4          292 #> 293        10         0.2   none   none                  0.4          293 #> 294        30         0.2   none   none                  0.4          294 #> 295        60         0.2   none   none                  0.4          295 #> 296       100         0.2   none   none                  0.4          296 #> 297        10         0.5   none   none                  0.4          297 #> 298        30         0.5   none   none                  0.4          298 #> 299        60         0.5   none   none                  0.4          299 #> 300       100         0.5   none   none                  0.4          300 #> 301        10         0.8   none   none                  0.4          301 #> 302        30         0.8   none   none                  0.4          302 #> 303        60         0.8   none   none                  0.4          303 #> 304       100         0.8   none   none                  0.4          304 #> 305        10         0.0 medium   none                  0.4          305 #> 306        30         0.0 medium   none                  0.4          306 #> 307        60         0.0 medium   none                  0.4          307 #> 308       100         0.0 medium   none                  0.4          308 #> 309        10         0.2 medium   none                  0.4          309 #> 310        30         0.2 medium   none                  0.4          310 #> 311        60         0.2 medium   none                  0.4          311 #> 312       100         0.2 medium   none                  0.4          312 #> 313        10         0.5 medium   none                  0.4          313 #> 314        30         0.5 medium   none                  0.4          314 #> 315        60         0.5 medium   none                  0.4          315 #> 316       100         0.5 medium   none                  0.4          316 #> 317        10         0.8 medium   none                  0.4          317 #> 318        30         0.8 medium   none                  0.4          318 #> 319        60         0.8 medium   none                  0.4          319 #> 320       100         0.8 medium   none                  0.4          320 #> 321        10         0.0   high   none                  0.4          321 #> 322        30         0.0   high   none                  0.4          322 #> 323        60         0.0   high   none                  0.4          323 #> 324       100         0.0   high   none                  0.4          324 #> 325        10         0.2   high   none                  0.4          325 #> 326        30         0.2   high   none                  0.4          326 #> 327        60         0.2   high   none                  0.4          327 #> 328       100         0.2   high   none                  0.4          328 #> 329        10         0.5   high   none                  0.4          329 #> 330        30         0.5   high   none                  0.4          330 #> 331        60         0.5   high   none                  0.4          331 #> 332       100         0.5   high   none                  0.4          332 #> 333        10         0.8   high   none                  0.4          333 #> 334        30         0.8   high   none                  0.4          334 #> 335        60         0.8   high   none                  0.4          335 #> 336       100         0.8   high   none                  0.4          336 #> 337        10         0.0   none medium                  0.4          337 #> 338        30         0.0   none medium                  0.4          338 #> 339        60         0.0   none medium                  0.4          339 #> 340       100         0.0   none medium                  0.4          340 #> 341        10         0.2   none medium                  0.4          341 #> 342        30         0.2   none medium                  0.4          342 #> 343        60         0.2   none medium                  0.4          343 #> 344       100         0.2   none medium                  0.4          344 #> 345        10         0.5   none medium                  0.4          345 #> 346        30         0.5   none medium                  0.4          346 #> 347        60         0.5   none medium                  0.4          347 #> 348       100         0.5   none medium                  0.4          348 #> 349        10         0.8   none medium                  0.4          349 #> 350        30         0.8   none medium                  0.4          350 #> 351        60         0.8   none medium                  0.4          351 #> 352       100         0.8   none medium                  0.4          352 #> 353        10         0.0 medium medium                  0.4          353 #> 354        30         0.0 medium medium                  0.4          354 #> 355        60         0.0 medium medium                  0.4          355 #> 356       100         0.0 medium medium                  0.4          356 #> 357        10         0.2 medium medium                  0.4          357 #> 358        30         0.2 medium medium                  0.4          358 #> 359        60         0.2 medium medium                  0.4          359 #> 360       100         0.2 medium medium                  0.4          360 #> 361        10         0.5 medium medium                  0.4          361 #> 362        30         0.5 medium medium                  0.4          362 #> 363        60         0.5 medium medium                  0.4          363 #> 364       100         0.5 medium medium                  0.4          364 #> 365        10         0.8 medium medium                  0.4          365 #> 366        30         0.8 medium medium                  0.4          366 #> 367        60         0.8 medium medium                  0.4          367 #> 368       100         0.8 medium medium                  0.4          368 #> 369        10         0.0   high medium                  0.4          369 #> 370        30         0.0   high medium                  0.4          370 #> 371        60         0.0   high medium                  0.4          371 #> 372       100         0.0   high medium                  0.4          372 #> 373        10         0.2   high medium                  0.4          373 #> 374        30         0.2   high medium                  0.4          374 #> 375        60         0.2   high medium                  0.4          375 #> 376       100         0.2   high medium                  0.4          376 #> 377        10         0.5   high medium                  0.4          377 #> 378        30         0.5   high medium                  0.4          378 #> 379        60         0.5   high medium                  0.4          379 #> 380       100         0.5   high medium                  0.4          380 #> 381        10         0.8   high medium                  0.4          381 #> 382        30         0.8   high medium                  0.4          382 #> 383        60         0.8   high medium                  0.4          383 #> 384       100         0.8   high medium                  0.4          384 #> 385        10         0.0   none   high                  0.4          385 #> 386        30         0.0   none   high                  0.4          386 #> 387        60         0.0   none   high                  0.4          387 #> 388       100         0.0   none   high                  0.4          388 #> 389        10         0.2   none   high                  0.4          389 #> 390        30         0.2   none   high                  0.4          390 #> 391        60         0.2   none   high                  0.4          391 #> 392       100         0.2   none   high                  0.4          392 #> 393        10         0.5   none   high                  0.4          393 #> 394        30         0.5   none   high                  0.4          394 #> 395        60         0.5   none   high                  0.4          395 #> 396       100         0.5   none   high                  0.4          396 #> 397        10         0.8   none   high                  0.4          397 #> 398        30         0.8   none   high                  0.4          398 #> 399        60         0.8   none   high                  0.4          399 #> 400       100         0.8   none   high                  0.4          400 #> 401        10         0.0 medium   high                  0.4          401 #> 402        30         0.0 medium   high                  0.4          402 #> 403        60         0.0 medium   high                  0.4          403 #> 404       100         0.0 medium   high                  0.4          404 #> 405        10         0.2 medium   high                  0.4          405 #> 406        30         0.2 medium   high                  0.4          406 #> 407        60         0.2 medium   high                  0.4          407 #> 408       100         0.2 medium   high                  0.4          408 #> 409        10         0.5 medium   high                  0.4          409 #> 410        30         0.5 medium   high                  0.4          410 #> 411        60         0.5 medium   high                  0.4          411 #> 412       100         0.5 medium   high                  0.4          412 #> 413        10         0.8 medium   high                  0.4          413 #> 414        30         0.8 medium   high                  0.4          414 #> 415        60         0.8 medium   high                  0.4          415 #> 416       100         0.8 medium   high                  0.4          416 #> 417        10         0.0   high   high                  0.4          417 #> 418        30         0.0   high   high                  0.4          418 #> 419        60         0.0   high   high                  0.4          419 #> 420       100         0.0   high   high                  0.4          420 #> 421        10         0.2   high   high                  0.4          421 #> 422        30         0.2   high   high                  0.4          422 #> 423        60         0.2   high   high                  0.4          423 #> 424       100         0.2   high   high                  0.4          424 #> 425        10         0.5   high   high                  0.4          425 #> 426        30         0.5   high   high                  0.4          426 #> 427        60         0.5   high   high                  0.4          427 #> 428       100         0.5   high   high                  0.4          428 #> 429        10         0.8   high   high                  0.4          429 #> 430        30         0.8   high   high                  0.4          430 #> 431        60         0.8   high   high                  0.4          431 #> 432       100         0.8   high   high                  0.4          432 #> 433       200         0.0   none   none                  0.0          433 #> 434       400         0.0   none   none                  0.0          434 #> 435       800         0.0   none   none                  0.0          435 #> 436       200         0.2   none   none                  0.0          436 #> 437       400         0.2   none   none                  0.0          437 #> 438       800         0.2   none   none                  0.0          438 #> 439       200         0.5   none   none                  0.0          439 #> 440       400         0.5   none   none                  0.0          440 #> 441       800         0.5   none   none                  0.0          441 #> 442       200         0.8   none   none                  0.0          442 #> 443       400         0.8   none   none                  0.0          443 #> 444       800         0.8   none   none                  0.0          444 #> 445       200         0.0 medium   none                  0.0          445 #> 446       400         0.0 medium   none                  0.0          446 #> 447       800         0.0 medium   none                  0.0          447 #> 448       200         0.2 medium   none                  0.0          448 #> 449       400         0.2 medium   none                  0.0          449 #> 450       800         0.2 medium   none                  0.0          450 #> 451       200         0.5 medium   none                  0.0          451 #> 452       400         0.5 medium   none                  0.0          452 #> 453       800         0.5 medium   none                  0.0          453 #> 454       200         0.8 medium   none                  0.0          454 #> 455       400         0.8 medium   none                  0.0          455 #> 456       800         0.8 medium   none                  0.0          456 #> 457       200         0.0   high   none                  0.0          457 #> 458       400         0.0   high   none                  0.0          458 #> 459       800         0.0   high   none                  0.0          459 #> 460       200         0.2   high   none                  0.0          460 #> 461       400         0.2   high   none                  0.0          461 #> 462       800         0.2   high   none                  0.0          462 #> 463       200         0.5   high   none                  0.0          463 #> 464       400         0.5   high   none                  0.0          464 #> 465       800         0.5   high   none                  0.0          465 #> 466       200         0.8   high   none                  0.0          466 #> 467       400         0.8   high   none                  0.0          467 #> 468       800         0.8   high   none                  0.0          468 #> 469       200         0.0   none medium                  0.0          469 #> 470       400         0.0   none medium                  0.0          470 #> 471       800         0.0   none medium                  0.0          471 #> 472       200         0.2   none medium                  0.0          472 #> 473       400         0.2   none medium                  0.0          473 #> 474       800         0.2   none medium                  0.0          474 #> 475       200         0.5   none medium                  0.0          475 #> 476       400         0.5   none medium                  0.0          476 #> 477       800         0.5   none medium                  0.0          477 #> 478       200         0.8   none medium                  0.0          478 #> 479       400         0.8   none medium                  0.0          479 #> 480       800         0.8   none medium                  0.0          480 #> 481       200         0.0 medium medium                  0.0          481 #> 482       400         0.0 medium medium                  0.0          482 #> 483       800         0.0 medium medium                  0.0          483 #> 484       200         0.2 medium medium                  0.0          484 #> 485       400         0.2 medium medium                  0.0          485 #> 486       800         0.2 medium medium                  0.0          486 #> 487       200         0.5 medium medium                  0.0          487 #> 488       400         0.5 medium medium                  0.0          488 #> 489       800         0.5 medium medium                  0.0          489 #> 490       200         0.8 medium medium                  0.0          490 #> 491       400         0.8 medium medium                  0.0          491 #> 492       800         0.8 medium medium                  0.0          492 #> 493       200         0.0   high medium                  0.0          493 #> 494       400         0.0   high medium                  0.0          494 #> 495       800         0.0   high medium                  0.0          495 #> 496       200         0.2   high medium                  0.0          496 #> 497       400         0.2   high medium                  0.0          497 #> 498       800         0.2   high medium                  0.0          498 #> 499       200         0.5   high medium                  0.0          499 #> 500       400         0.5   high medium                  0.0          500 #> 501       800         0.5   high medium                  0.0          501 #> 502       200         0.8   high medium                  0.0          502 #> 503       400         0.8   high medium                  0.0          503 #> 504       800         0.8   high medium                  0.0          504 #> 505       200         0.0   none   high                  0.0          505 #> 506       400         0.0   none   high                  0.0          506 #> 507       800         0.0   none   high                  0.0          507 #> 508       200         0.2   none   high                  0.0          508 #> 509       400         0.2   none   high                  0.0          509 #> 510       800         0.2   none   high                  0.0          510 #> 511       200         0.5   none   high                  0.0          511 #> 512       400         0.5   none   high                  0.0          512 #> 513       800         0.5   none   high                  0.0          513 #> 514       200         0.8   none   high                  0.0          514 #> 515       400         0.8   none   high                  0.0          515 #> 516       800         0.8   none   high                  0.0          516 #> 517       200         0.0 medium   high                  0.0          517 #> 518       400         0.0 medium   high                  0.0          518 #> 519       800         0.0 medium   high                  0.0          519 #> 520       200         0.2 medium   high                  0.0          520 #> 521       400         0.2 medium   high                  0.0          521 #> 522       800         0.2 medium   high                  0.0          522 #> 523       200         0.5 medium   high                  0.0          523 #> 524       400         0.5 medium   high                  0.0          524 #> 525       800         0.5 medium   high                  0.0          525 #> 526       200         0.8 medium   high                  0.0          526 #> 527       400         0.8 medium   high                  0.0          527 #> 528       800         0.8 medium   high                  0.0          528 #> 529       200         0.0   high   high                  0.0          529 #> 530       400         0.0   high   high                  0.0          530 #> 531       800         0.0   high   high                  0.0          531 #> 532       200         0.2   high   high                  0.0          532 #> 533       400         0.2   high   high                  0.0          533 #> 534       800         0.2   high   high                  0.0          534 #> 535       200         0.5   high   high                  0.0          535 #> 536       400         0.5   high   high                  0.0          536 #> 537       800         0.5   high   high                  0.0          537 #> 538       200         0.8   high   high                  0.0          538 #> 539       400         0.8   high   high                  0.0          539 #> 540       800         0.8   high   high                  0.0          540 #> 541       200         0.0   none   none                  0.2          541 #> 542       400         0.0   none   none                  0.2          542 #> 543       800         0.0   none   none                  0.2          543 #> 544       200         0.2   none   none                  0.2          544 #> 545       400         0.2   none   none                  0.2          545 #> 546       800         0.2   none   none                  0.2          546 #> 547       200         0.5   none   none                  0.2          547 #> 548       400         0.5   none   none                  0.2          548 #> 549       800         0.5   none   none                  0.2          549 #> 550       200         0.8   none   none                  0.2          550 #> 551       400         0.8   none   none                  0.2          551 #> 552       800         0.8   none   none                  0.2          552 #> 553       200         0.0 medium   none                  0.2          553 #> 554       400         0.0 medium   none                  0.2          554 #> 555       800         0.0 medium   none                  0.2          555 #> 556       200         0.2 medium   none                  0.2          556 #> 557       400         0.2 medium   none                  0.2          557 #> 558       800         0.2 medium   none                  0.2          558 #> 559       200         0.5 medium   none                  0.2          559 #> 560       400         0.5 medium   none                  0.2          560 #> 561       800         0.5 medium   none                  0.2          561 #> 562       200         0.8 medium   none                  0.2          562 #> 563       400         0.8 medium   none                  0.2          563 #> 564       800         0.8 medium   none                  0.2          564 #> 565       200         0.0   high   none                  0.2          565 #> 566       400         0.0   high   none                  0.2          566 #> 567       800         0.0   high   none                  0.2          567 #> 568       200         0.2   high   none                  0.2          568 #> 569       400         0.2   high   none                  0.2          569 #> 570       800         0.2   high   none                  0.2          570 #> 571       200         0.5   high   none                  0.2          571 #> 572       400         0.5   high   none                  0.2          572 #> 573       800         0.5   high   none                  0.2          573 #> 574       200         0.8   high   none                  0.2          574 #> 575       400         0.8   high   none                  0.2          575 #> 576       800         0.8   high   none                  0.2          576 #> 577       200         0.0   none medium                  0.2          577 #> 578       400         0.0   none medium                  0.2          578 #> 579       800         0.0   none medium                  0.2          579 #> 580       200         0.2   none medium                  0.2          580 #> 581       400         0.2   none medium                  0.2          581 #> 582       800         0.2   none medium                  0.2          582 #> 583       200         0.5   none medium                  0.2          583 #> 584       400         0.5   none medium                  0.2          584 #> 585       800         0.5   none medium                  0.2          585 #> 586       200         0.8   none medium                  0.2          586 #> 587       400         0.8   none medium                  0.2          587 #> 588       800         0.8   none medium                  0.2          588 #> 589       200         0.0 medium medium                  0.2          589 #> 590       400         0.0 medium medium                  0.2          590 #> 591       800         0.0 medium medium                  0.2          591 #> 592       200         0.2 medium medium                  0.2          592 #> 593       400         0.2 medium medium                  0.2          593 #> 594       800         0.2 medium medium                  0.2          594 #> 595       200         0.5 medium medium                  0.2          595 #> 596       400         0.5 medium medium                  0.2          596 #> 597       800         0.5 medium medium                  0.2          597 #> 598       200         0.8 medium medium                  0.2          598 #> 599       400         0.8 medium medium                  0.2          599 #> 600       800         0.8 medium medium                  0.2          600 #> 601       200         0.0   high medium                  0.2          601 #> 602       400         0.0   high medium                  0.2          602 #> 603       800         0.0   high medium                  0.2          603 #> 604       200         0.2   high medium                  0.2          604 #> 605       400         0.2   high medium                  0.2          605 #> 606       800         0.2   high medium                  0.2          606 #> 607       200         0.5   high medium                  0.2          607 #> 608       400         0.5   high medium                  0.2          608 #> 609       800         0.5   high medium                  0.2          609 #> 610       200         0.8   high medium                  0.2          610 #> 611       400         0.8   high medium                  0.2          611 #> 612       800         0.8   high medium                  0.2          612 #> 613       200         0.0   none   high                  0.2          613 #> 614       400         0.0   none   high                  0.2          614 #> 615       800         0.0   none   high                  0.2          615 #> 616       200         0.2   none   high                  0.2          616 #> 617       400         0.2   none   high                  0.2          617 #> 618       800         0.2   none   high                  0.2          618 #> 619       200         0.5   none   high                  0.2          619 #> 620       400         0.5   none   high                  0.2          620 #> 621       800         0.5   none   high                  0.2          621 #> 622       200         0.8   none   high                  0.2          622 #> 623       400         0.8   none   high                  0.2          623 #> 624       800         0.8   none   high                  0.2          624 #> 625       200         0.0 medium   high                  0.2          625 #> 626       400         0.0 medium   high                  0.2          626 #> 627       800         0.0 medium   high                  0.2          627 #> 628       200         0.2 medium   high                  0.2          628 #> 629       400         0.2 medium   high                  0.2          629 #> 630       800         0.2 medium   high                  0.2          630 #> 631       200         0.5 medium   high                  0.2          631 #> 632       400         0.5 medium   high                  0.2          632 #> 633       800         0.5 medium   high                  0.2          633 #> 634       200         0.8 medium   high                  0.2          634 #> 635       400         0.8 medium   high                  0.2          635 #> 636       800         0.8 medium   high                  0.2          636 #> 637       200         0.0   high   high                  0.2          637 #> 638       400         0.0   high   high                  0.2          638 #> 639       800         0.0   high   high                  0.2          639 #> 640       200         0.2   high   high                  0.2          640 #> 641       400         0.2   high   high                  0.2          641 #> 642       800         0.2   high   high                  0.2          642 #> 643       200         0.5   high   high                  0.2          643 #> 644       400         0.5   high   high                  0.2          644 #> 645       800         0.5   high   high                  0.2          645 #> 646       200         0.8   high   high                  0.2          646 #> 647       400         0.8   high   high                  0.2          647 #> 648       800         0.8   high   high                  0.2          648 #> 649       200         0.0   none   none                  0.4          649 #> 650       400         0.0   none   none                  0.4          650 #> 651       800         0.0   none   none                  0.4          651 #> 652       200         0.2   none   none                  0.4          652 #> 653       400         0.2   none   none                  0.4          653 #> 654       800         0.2   none   none                  0.4          654 #> 655       200         0.5   none   none                  0.4          655 #> 656       400         0.5   none   none                  0.4          656 #> 657       800         0.5   none   none                  0.4          657 #> 658       200         0.8   none   none                  0.4          658 #> 659       400         0.8   none   none                  0.4          659 #> 660       800         0.8   none   none                  0.4          660 #> 661       200         0.0 medium   none                  0.4          661 #> 662       400         0.0 medium   none                  0.4          662 #> 663       800         0.0 medium   none                  0.4          663 #> 664       200         0.2 medium   none                  0.4          664 #> 665       400         0.2 medium   none                  0.4          665 #> 666       800         0.2 medium   none                  0.4          666 #> 667       200         0.5 medium   none                  0.4          667 #> 668       400         0.5 medium   none                  0.4          668 #> 669       800         0.5 medium   none                  0.4          669 #> 670       200         0.8 medium   none                  0.4          670 #> 671       400         0.8 medium   none                  0.4          671 #> 672       800         0.8 medium   none                  0.4          672 #> 673       200         0.0   high   none                  0.4          673 #> 674       400         0.0   high   none                  0.4          674 #> 675       800         0.0   high   none                  0.4          675 #> 676       200         0.2   high   none                  0.4          676 #> 677       400         0.2   high   none                  0.4          677 #> 678       800         0.2   high   none                  0.4          678 #> 679       200         0.5   high   none                  0.4          679 #> 680       400         0.5   high   none                  0.4          680 #> 681       800         0.5   high   none                  0.4          681 #> 682       200         0.8   high   none                  0.4          682 #> 683       400         0.8   high   none                  0.4          683 #> 684       800         0.8   high   none                  0.4          684 #> 685       200         0.0   none medium                  0.4          685 #> 686       400         0.0   none medium                  0.4          686 #> 687       800         0.0   none medium                  0.4          687 #> 688       200         0.2   none medium                  0.4          688 #> 689       400         0.2   none medium                  0.4          689 #> 690       800         0.2   none medium                  0.4          690 #> 691       200         0.5   none medium                  0.4          691 #> 692       400         0.5   none medium                  0.4          692 #> 693       800         0.5   none medium                  0.4          693 #> 694       200         0.8   none medium                  0.4          694 #> 695       400         0.8   none medium                  0.4          695 #> 696       800         0.8   none medium                  0.4          696 #> 697       200         0.0 medium medium                  0.4          697 #> 698       400         0.0 medium medium                  0.4          698 #> 699       800         0.0 medium medium                  0.4          699 #> 700       200         0.2 medium medium                  0.4          700 #> 701       400         0.2 medium medium                  0.4          701 #> 702       800         0.2 medium medium                  0.4          702 #> 703       200         0.5 medium medium                  0.4          703 #> 704       400         0.5 medium medium                  0.4          704 #> 705       800         0.5 medium medium                  0.4          705 #> 706       200         0.8 medium medium                  0.4          706 #> 707       400         0.8 medium medium                  0.4          707 #> 708       800         0.8 medium medium                  0.4          708 #> 709       200         0.0   high medium                  0.4          709 #> 710       400         0.0   high medium                  0.4          710 #> 711       800         0.0   high medium                  0.4          711 #> 712       200         0.2   high medium                  0.4          712 #> 713       400         0.2   high medium                  0.4          713 #> 714       800         0.2   high medium                  0.4          714 #> 715       200         0.5   high medium                  0.4          715 #> 716       400         0.5   high medium                  0.4          716 #> 717       800         0.5   high medium                  0.4          717 #> 718       200         0.8   high medium                  0.4          718 #> 719       400         0.8   high medium                  0.4          719 #> 720       800         0.8   high medium                  0.4          720 #> 721       200         0.0   none   high                  0.4          721 #> 722       400         0.0   none   high                  0.4          722 #> 723       800         0.0   none   high                  0.4          723 #> 724       200         0.2   none   high                  0.4          724 #> 725       400         0.2   none   high                  0.4          725 #> 726       800         0.2   none   high                  0.4          726 #> 727       200         0.5   none   high                  0.4          727 #> 728       400         0.5   none   high                  0.4          728 #> 729       800         0.5   none   high                  0.4          729 #> 730       200         0.8   none   high                  0.4          730 #> 731       400         0.8   none   high                  0.4          731 #> 732       800         0.8   none   high                  0.4          732 #> 733       200         0.0 medium   high                  0.4          733 #> 734       400         0.0 medium   high                  0.4          734 #> 735       800         0.0 medium   high                  0.4          735 #> 736       200         0.2 medium   high                  0.4          736 #> 737       400         0.2 medium   high                  0.4          737 #> 738       800         0.2 medium   high                  0.4          738 #> 739       200         0.5 medium   high                  0.4          739 #> 740       400         0.5 medium   high                  0.4          740 #> 741       800         0.5 medium   high                  0.4          741 #> 742       200         0.8 medium   high                  0.4          742 #> 743       400         0.8 medium   high                  0.4          743 #> 744       800         0.8 medium   high                  0.4          744 #> 745       200         0.0   high   high                  0.4          745 #> 746       400         0.0   high   high                  0.4          746 #> 747       800         0.0   high   high                  0.4          747 #> 748       200         0.2   high   high                  0.4          748 #> 749       400         0.2   high   high                  0.4          749 #> 750       800         0.2   high   high                  0.4          750 #> 751       200         0.5   high   high                  0.4          751 #> 752       400         0.5   high   high                  0.4          752 #> 753       800         0.5   high   high                  0.4          753 #> 754       200         0.8   high   high                  0.4          754 #> 755       400         0.8   high   high                  0.4          755 #> 756       800         0.8   high   high                  0.4          756 get_dgm_condition(\"Carter2019\", condition_id = 1) #>   n_studies mean_effect  QRP bias effect_heterogeneity condition_id #> 1        10           0 none none                    0            1  dgm_conditions(\"Alinaghi2018\") #>    environment mean_effect        bias condition_id #> 1           RE         0.0        none            1 #> 2          PRE         0.0        none            2 #> 3           FE         0.0        none            3 #> 4           RE         0.5        none            4 #> 5          PRE         0.5        none            5 #> 6           FE         0.5        none            6 #> 7           RE         1.0        none            7 #> 8          PRE         1.0        none            8 #> 9           FE         1.0        none            9 #> 10          RE         1.5        none           10 #> 11         PRE         1.5        none           11 #> 12          FE         1.5        none           12 #> 13          RE         2.0        none           13 #> 14         PRE         2.0        none           14 #> 15          FE         2.0        none           15 #> 16          RE         2.5        none           16 #> 17         PRE         2.5        none           17 #> 18          FE         2.5        none           18 #> 19          RE         3.0        none           19 #> 20         PRE         3.0        none           20 #> 21          FE         3.0        none           21 #> 22          RE         3.5        none           22 #> 23         PRE         3.5        none           23 #> 24          FE         3.5        none           24 #> 25          RE         4.0        none           25 #> 26         PRE         4.0        none           26 #> 27          FE         4.0        none           27 #> 28          RE         0.0    positive           28 #> 29         PRE         0.0    positive           29 #> 30          FE         0.0    positive           30 #> 31          RE         0.5    positive           31 #> 32         PRE         0.5    positive           32 #> 33          FE         0.5    positive           33 #> 34          RE         1.0    positive           34 #> 35         PRE         1.0    positive           35 #> 36          FE         1.0    positive           36 #> 37          RE         1.5    positive           37 #> 38         PRE         1.5    positive           38 #> 39          FE         1.5    positive           39 #> 40          RE         2.0    positive           40 #> 41         PRE         2.0    positive           41 #> 42          FE         2.0    positive           42 #> 43          RE         2.5    positive           43 #> 44         PRE         2.5    positive           44 #> 45          FE         2.5    positive           45 #> 46          RE         3.0    positive           46 #> 47         PRE         3.0    positive           47 #> 48          FE         3.0    positive           48 #> 49          RE         3.5    positive           49 #> 50         PRE         3.5    positive           50 #> 51          FE         3.5    positive           51 #> 52          RE         4.0    positive           52 #> 53         PRE         4.0    positive           53 #> 54          FE         4.0    positive           54 #> 55          RE         0.0 significant           55 #> 56         PRE         0.0 significant           56 #> 57          FE         0.0 significant           57 #> 58          RE         0.5 significant           58 #> 59         PRE         0.5 significant           59 #> 60          FE         0.5 significant           60 #> 61          RE         1.0 significant           61 #> 62         PRE         1.0 significant           62 #> 63          FE         1.0 significant           63 #> 64          RE         1.5 significant           64 #> 65         PRE         1.5 significant           65 #> 66          FE         1.5 significant           66 #> 67          RE         2.0 significant           67 #> 68         PRE         2.0 significant           68 #> 69          FE         2.0 significant           69 #> 70          RE         2.5 significant           70 #> 71         PRE         2.5 significant           71 #> 72          FE         2.5 significant           72 #> 73          RE         3.0 significant           73 #> 74         PRE         3.0 significant           74 #> 75          FE         3.0 significant           75 #> 76          RE         3.5 significant           76 #> 77         PRE         3.5 significant           77 #> 78          FE         3.5 significant           78 #> 79          RE         4.0 significant           79 #> 80         PRE         4.0 significant           80 #> 81          FE         4.0 significant           81  dgm_conditions(\"Stanley2017\") #>     mean_effect effect_heterogeneity bias n_studies environment #> 1          0.00               0.0000 0.00         5    Cohens_d #> 2          0.50               0.0000 0.00         5    Cohens_d #> 3          0.00               0.0625 0.00         5    Cohens_d #> 4          0.50               0.0625 0.00         5    Cohens_d #> 5          0.00               0.1250 0.00         5    Cohens_d #> 6          0.50               0.1250 0.00         5    Cohens_d #> 7          0.00               0.2500 0.00         5    Cohens_d #> 8          0.50               0.2500 0.00         5    Cohens_d #> 9          0.00               0.5000 0.00         5    Cohens_d #> 10         0.50               0.5000 0.00         5    Cohens_d #> 11         0.00               0.0000 0.50         5    Cohens_d #> 12         0.50               0.0000 0.50         5    Cohens_d #> 13         0.00               0.0625 0.50         5    Cohens_d #> 14         0.50               0.0625 0.50         5    Cohens_d #> 15         0.00               0.1250 0.50         5    Cohens_d #> 16         0.50               0.1250 0.50         5    Cohens_d #> 17         0.00               0.2500 0.50         5    Cohens_d #> 18         0.50               0.2500 0.50         5    Cohens_d #> 19         0.00               0.5000 0.50         5    Cohens_d #> 20         0.50               0.5000 0.50         5    Cohens_d #> 21         0.00               0.0000 0.75         5    Cohens_d #> 22         0.50               0.0000 0.75         5    Cohens_d #> 23         0.00               0.0625 0.75         5    Cohens_d #> 24         0.50               0.0625 0.75         5    Cohens_d #> 25         0.00               0.1250 0.75         5    Cohens_d #> 26         0.50               0.1250 0.75         5    Cohens_d #> 27         0.00               0.2500 0.75         5    Cohens_d #> 28         0.50               0.2500 0.75         5    Cohens_d #> 29         0.00               0.5000 0.75         5    Cohens_d #> 30         0.50               0.5000 0.75         5    Cohens_d #> 31         0.00               0.0000 0.00        10    Cohens_d #> 32         0.50               0.0000 0.00        10    Cohens_d #> 33         0.00               0.0625 0.00        10    Cohens_d #> 34         0.50               0.0625 0.00        10    Cohens_d #> 35         0.00               0.1250 0.00        10    Cohens_d #> 36         0.50               0.1250 0.00        10    Cohens_d #> 37         0.00               0.2500 0.00        10    Cohens_d #> 38         0.50               0.2500 0.00        10    Cohens_d #> 39         0.00               0.5000 0.00        10    Cohens_d #> 40         0.50               0.5000 0.00        10    Cohens_d #> 41         0.00               0.0000 0.50        10    Cohens_d #> 42         0.50               0.0000 0.50        10    Cohens_d #> 43         0.00               0.0625 0.50        10    Cohens_d #> 44         0.50               0.0625 0.50        10    Cohens_d #> 45         0.00               0.1250 0.50        10    Cohens_d #> 46         0.50               0.1250 0.50        10    Cohens_d #> 47         0.00               0.2500 0.50        10    Cohens_d #> 48         0.50               0.2500 0.50        10    Cohens_d #> 49         0.00               0.5000 0.50        10    Cohens_d #> 50         0.50               0.5000 0.50        10    Cohens_d #> 51         0.00               0.0000 0.75        10    Cohens_d #> 52         0.50               0.0000 0.75        10    Cohens_d #> 53         0.00               0.0625 0.75        10    Cohens_d #> 54         0.50               0.0625 0.75        10    Cohens_d #> 55         0.00               0.1250 0.75        10    Cohens_d #> 56         0.50               0.1250 0.75        10    Cohens_d #> 57         0.00               0.2500 0.75        10    Cohens_d #> 58         0.50               0.2500 0.75        10    Cohens_d #> 59         0.00               0.5000 0.75        10    Cohens_d #> 60         0.50               0.5000 0.75        10    Cohens_d #> 61         0.00               0.0000 0.00        20    Cohens_d #> 62         0.50               0.0000 0.00        20    Cohens_d #> 63         0.00               0.0625 0.00        20    Cohens_d #> 64         0.50               0.0625 0.00        20    Cohens_d #> 65         0.00               0.1250 0.00        20    Cohens_d #> 66         0.50               0.1250 0.00        20    Cohens_d #> 67         0.00               0.2500 0.00        20    Cohens_d #> 68         0.50               0.2500 0.00        20    Cohens_d #> 69         0.00               0.5000 0.00        20    Cohens_d #> 70         0.50               0.5000 0.00        20    Cohens_d #> 71         0.00               0.0000 0.50        20    Cohens_d #> 72         0.50               0.0000 0.50        20    Cohens_d #> 73         0.00               0.0625 0.50        20    Cohens_d #> 74         0.50               0.0625 0.50        20    Cohens_d #> 75         0.00               0.1250 0.50        20    Cohens_d #> 76         0.50               0.1250 0.50        20    Cohens_d #> 77         0.00               0.2500 0.50        20    Cohens_d #> 78         0.50               0.2500 0.50        20    Cohens_d #> 79         0.00               0.5000 0.50        20    Cohens_d #> 80         0.50               0.5000 0.50        20    Cohens_d #> 81         0.00               0.0000 0.75        20    Cohens_d #> 82         0.50               0.0000 0.75        20    Cohens_d #> 83         0.00               0.0625 0.75        20    Cohens_d #> 84         0.50               0.0625 0.75        20    Cohens_d #> 85         0.00               0.1250 0.75        20    Cohens_d #> 86         0.50               0.1250 0.75        20    Cohens_d #> 87         0.00               0.2500 0.75        20    Cohens_d #> 88         0.50               0.2500 0.75        20    Cohens_d #> 89         0.00               0.5000 0.75        20    Cohens_d #> 90         0.50               0.5000 0.75        20    Cohens_d #> 91         0.00               0.0000 0.00        40    Cohens_d #> 92         0.50               0.0000 0.00        40    Cohens_d #> 93         0.00               0.0625 0.00        40    Cohens_d #> 94         0.50               0.0625 0.00        40    Cohens_d #> 95         0.00               0.1250 0.00        40    Cohens_d #> 96         0.50               0.1250 0.00        40    Cohens_d #> 97         0.00               0.2500 0.00        40    Cohens_d #> 98         0.50               0.2500 0.00        40    Cohens_d #> 99         0.00               0.5000 0.00        40    Cohens_d #> 100        0.50               0.5000 0.00        40    Cohens_d #> 101        0.00               0.0000 0.50        40    Cohens_d #> 102        0.50               0.0000 0.50        40    Cohens_d #> 103        0.00               0.0625 0.50        40    Cohens_d #> 104        0.50               0.0625 0.50        40    Cohens_d #> 105        0.00               0.1250 0.50        40    Cohens_d #> 106        0.50               0.1250 0.50        40    Cohens_d #> 107        0.00               0.2500 0.50        40    Cohens_d #> 108        0.50               0.2500 0.50        40    Cohens_d #> 109        0.00               0.5000 0.50        40    Cohens_d #> 110        0.50               0.5000 0.50        40    Cohens_d #> 111        0.00               0.0000 0.75        40    Cohens_d #> 112        0.50               0.0000 0.75        40    Cohens_d #> 113        0.00               0.0625 0.75        40    Cohens_d #> 114        0.50               0.0625 0.75        40    Cohens_d #> 115        0.00               0.1250 0.75        40    Cohens_d #> 116        0.50               0.1250 0.75        40    Cohens_d #> 117        0.00               0.2500 0.75        40    Cohens_d #> 118        0.50               0.2500 0.75        40    Cohens_d #> 119        0.00               0.5000 0.75        40    Cohens_d #> 120        0.50               0.5000 0.75        40    Cohens_d #> 121        0.00               0.0000 0.00        80    Cohens_d #> 122        0.50               0.0000 0.00        80    Cohens_d #> 123        0.00               0.0625 0.00        80    Cohens_d #> 124        0.50               0.0625 0.00        80    Cohens_d #> 125        0.00               0.1250 0.00        80    Cohens_d #> 126        0.50               0.1250 0.00        80    Cohens_d #> 127        0.00               0.2500 0.00        80    Cohens_d #> 128        0.50               0.2500 0.00        80    Cohens_d #> 129        0.00               0.5000 0.00        80    Cohens_d #> 130        0.50               0.5000 0.00        80    Cohens_d #> 131        0.00               0.0000 0.50        80    Cohens_d #> 132        0.50               0.0000 0.50        80    Cohens_d #> 133        0.00               0.0625 0.50        80    Cohens_d #> 134        0.50               0.0625 0.50        80    Cohens_d #> 135        0.00               0.1250 0.50        80    Cohens_d #> 136        0.50               0.1250 0.50        80    Cohens_d #> 137        0.00               0.2500 0.50        80    Cohens_d #> 138        0.50               0.2500 0.50        80    Cohens_d #> 139        0.00               0.5000 0.50        80    Cohens_d #> 140        0.50               0.5000 0.50        80    Cohens_d #> 141        0.00               0.0000 0.75        80    Cohens_d #> 142        0.50               0.0000 0.75        80    Cohens_d #> 143        0.00               0.0625 0.75        80    Cohens_d #> 144        0.50               0.0625 0.75        80    Cohens_d #> 145        0.00               0.1250 0.75        80    Cohens_d #> 146        0.50               0.1250 0.75        80    Cohens_d #> 147        0.00               0.2500 0.75        80    Cohens_d #> 148        0.50               0.2500 0.75        80    Cohens_d #> 149        0.00               0.5000 0.75        80    Cohens_d #> 150        0.50               0.5000 0.75        80    Cohens_d #> 151        0.00               0.0060 0.00         5       LogOR #> 152        0.03               0.0060 0.00         5       LogOR #> 153        0.06               0.0060 0.00         5       LogOR #> 154        0.00               0.0060 0.50         5       LogOR #> 155        0.03               0.0060 0.50         5       LogOR #> 156        0.06               0.0060 0.50         5       LogOR #> 157        0.00               0.0060 0.00        10       LogOR #> 158        0.03               0.0060 0.00        10       LogOR #> 159        0.06               0.0060 0.00        10       LogOR #> 160        0.00               0.0060 0.50        10       LogOR #> 161        0.03               0.0060 0.50        10       LogOR #> 162        0.06               0.0060 0.50        10       LogOR #> 163        0.00               0.0060 0.00        20       LogOR #> 164        0.03               0.0060 0.00        20       LogOR #> 165        0.06               0.0060 0.00        20       LogOR #> 166        0.00               0.0060 0.50        20       LogOR #> 167        0.03               0.0060 0.50        20       LogOR #> 168        0.06               0.0060 0.50        20       LogOR #> 169        0.00               0.0060 0.00        40       LogOR #> 170        0.03               0.0060 0.00        40       LogOR #> 171        0.06               0.0060 0.00        40       LogOR #> 172        0.00               0.0060 0.50        40       LogOR #> 173        0.03               0.0060 0.50        40       LogOR #> 174        0.06               0.0060 0.50        40       LogOR #> 175        0.00               0.0060 0.00        80       LogOR #> 176        0.03               0.0060 0.00        80       LogOR #> 177        0.06               0.0060 0.00        80       LogOR #> 178        0.00               0.0060 0.50        80       LogOR #> 179        0.03               0.0060 0.50        80       LogOR #> 180        0.06               0.0060 0.50        80       LogOR #> 181        0.00               0.0000 0.00       100    Cohens_d #> 182        0.50               0.0000 0.00       100    Cohens_d #> 183        0.00               0.0625 0.00       100    Cohens_d #> 184        0.50               0.0625 0.00       100    Cohens_d #> 185        0.00               0.1250 0.00       100    Cohens_d #> 186        0.50               0.1250 0.00       100    Cohens_d #> 187        0.00               0.2500 0.00       100    Cohens_d #> 188        0.50               0.2500 0.00       100    Cohens_d #> 189        0.00               0.5000 0.00       100    Cohens_d #> 190        0.50               0.5000 0.00       100    Cohens_d #> 191        0.00               0.0000 0.50       100    Cohens_d #> 192        0.50               0.0000 0.50       100    Cohens_d #> 193        0.00               0.0625 0.50       100    Cohens_d #> 194        0.50               0.0625 0.50       100    Cohens_d #> 195        0.00               0.1250 0.50       100    Cohens_d #> 196        0.50               0.1250 0.50       100    Cohens_d #> 197        0.00               0.2500 0.50       100    Cohens_d #> 198        0.50               0.2500 0.50       100    Cohens_d #> 199        0.00               0.5000 0.50       100    Cohens_d #> 200        0.50               0.5000 0.50       100    Cohens_d #> 201        0.00               0.0000 0.75       100    Cohens_d #> 202        0.50               0.0000 0.75       100    Cohens_d #> 203        0.00               0.0625 0.75       100    Cohens_d #> 204        0.50               0.0625 0.75       100    Cohens_d #> 205        0.00               0.1250 0.75       100    Cohens_d #> 206        0.50               0.1250 0.75       100    Cohens_d #> 207        0.00               0.2500 0.75       100    Cohens_d #> 208        0.50               0.2500 0.75       100    Cohens_d #> 209        0.00               0.5000 0.75       100    Cohens_d #> 210        0.50               0.5000 0.75       100    Cohens_d #> 211        0.00               0.0000 0.00       200    Cohens_d #> 212        0.50               0.0000 0.00       200    Cohens_d #> 213        0.00               0.0625 0.00       200    Cohens_d #> 214        0.50               0.0625 0.00       200    Cohens_d #> 215        0.00               0.1250 0.00       200    Cohens_d #> 216        0.50               0.1250 0.00       200    Cohens_d #> 217        0.00               0.2500 0.00       200    Cohens_d #> 218        0.50               0.2500 0.00       200    Cohens_d #> 219        0.00               0.5000 0.00       200    Cohens_d #> 220        0.50               0.5000 0.00       200    Cohens_d #> 221        0.00               0.0000 0.50       200    Cohens_d #> 222        0.50               0.0000 0.50       200    Cohens_d #> 223        0.00               0.0625 0.50       200    Cohens_d #> 224        0.50               0.0625 0.50       200    Cohens_d #> 225        0.00               0.1250 0.50       200    Cohens_d #> 226        0.50               0.1250 0.50       200    Cohens_d #> 227        0.00               0.2500 0.50       200    Cohens_d #> 228        0.50               0.2500 0.50       200    Cohens_d #> 229        0.00               0.5000 0.50       200    Cohens_d #> 230        0.50               0.5000 0.50       200    Cohens_d #> 231        0.00               0.0000 0.75       200    Cohens_d #> 232        0.50               0.0000 0.75       200    Cohens_d #> 233        0.00               0.0625 0.75       200    Cohens_d #> 234        0.50               0.0625 0.75       200    Cohens_d #> 235        0.00               0.1250 0.75       200    Cohens_d #> 236        0.50               0.1250 0.75       200    Cohens_d #> 237        0.00               0.2500 0.75       200    Cohens_d #> 238        0.50               0.2500 0.75       200    Cohens_d #> 239        0.00               0.5000 0.75       200    Cohens_d #> 240        0.50               0.5000 0.75       200    Cohens_d #> 241        0.00               0.0000 0.00       400    Cohens_d #> 242        0.50               0.0000 0.00       400    Cohens_d #> 243        0.00               0.0625 0.00       400    Cohens_d #> 244        0.50               0.0625 0.00       400    Cohens_d #> 245        0.00               0.1250 0.00       400    Cohens_d #> 246        0.50               0.1250 0.00       400    Cohens_d #> 247        0.00               0.2500 0.00       400    Cohens_d #> 248        0.50               0.2500 0.00       400    Cohens_d #> 249        0.00               0.5000 0.00       400    Cohens_d #> 250        0.50               0.5000 0.00       400    Cohens_d #> 251        0.00               0.0000 0.50       400    Cohens_d #> 252        0.50               0.0000 0.50       400    Cohens_d #> 253        0.00               0.0625 0.50       400    Cohens_d #> 254        0.50               0.0625 0.50       400    Cohens_d #> 255        0.00               0.1250 0.50       400    Cohens_d #> 256        0.50               0.1250 0.50       400    Cohens_d #> 257        0.00               0.2500 0.50       400    Cohens_d #> 258        0.50               0.2500 0.50       400    Cohens_d #> 259        0.00               0.5000 0.50       400    Cohens_d #> 260        0.50               0.5000 0.50       400    Cohens_d #> 261        0.00               0.0000 0.75       400    Cohens_d #> 262        0.50               0.0000 0.75       400    Cohens_d #> 263        0.00               0.0625 0.75       400    Cohens_d #> 264        0.50               0.0625 0.75       400    Cohens_d #> 265        0.00               0.1250 0.75       400    Cohens_d #> 266        0.50               0.1250 0.75       400    Cohens_d #> 267        0.00               0.2500 0.75       400    Cohens_d #> 268        0.50               0.2500 0.75       400    Cohens_d #> 269        0.00               0.5000 0.75       400    Cohens_d #> 270        0.50               0.5000 0.75       400    Cohens_d #> 271        0.00               0.0000 0.00       800    Cohens_d #> 272        0.50               0.0000 0.00       800    Cohens_d #> 273        0.00               0.0625 0.00       800    Cohens_d #> 274        0.50               0.0625 0.00       800    Cohens_d #> 275        0.00               0.1250 0.00       800    Cohens_d #> 276        0.50               0.1250 0.00       800    Cohens_d #> 277        0.00               0.2500 0.00       800    Cohens_d #> 278        0.50               0.2500 0.00       800    Cohens_d #> 279        0.00               0.5000 0.00       800    Cohens_d #> 280        0.50               0.5000 0.00       800    Cohens_d #> 281        0.00               0.0000 0.50       800    Cohens_d #> 282        0.50               0.0000 0.50       800    Cohens_d #> 283        0.00               0.0625 0.50       800    Cohens_d #> 284        0.50               0.0625 0.50       800    Cohens_d #> 285        0.00               0.1250 0.50       800    Cohens_d #> 286        0.50               0.1250 0.50       800    Cohens_d #> 287        0.00               0.2500 0.50       800    Cohens_d #> 288        0.50               0.2500 0.50       800    Cohens_d #> 289        0.00               0.5000 0.50       800    Cohens_d #> 290        0.50               0.5000 0.50       800    Cohens_d #> 291        0.00               0.0000 0.75       800    Cohens_d #> 292        0.50               0.0000 0.75       800    Cohens_d #> 293        0.00               0.0625 0.75       800    Cohens_d #> 294        0.50               0.0625 0.75       800    Cohens_d #> 295        0.00               0.1250 0.75       800    Cohens_d #> 296        0.50               0.1250 0.75       800    Cohens_d #> 297        0.00               0.2500 0.75       800    Cohens_d #> 298        0.50               0.2500 0.75       800    Cohens_d #> 299        0.00               0.5000 0.75       800    Cohens_d #> 300        0.50               0.5000 0.75       800    Cohens_d #> 301        0.00               0.0060 0.00       100       LogOR #> 302        0.03               0.0060 0.00       100       LogOR #> 303        0.06               0.0060 0.00       100       LogOR #> 304        0.00               0.0060 0.50       100       LogOR #> 305        0.03               0.0060 0.50       100       LogOR #> 306        0.06               0.0060 0.50       100       LogOR #> 307        0.00               0.0060 0.00       200       LogOR #> 308        0.03               0.0060 0.00       200       LogOR #> 309        0.06               0.0060 0.00       200       LogOR #> 310        0.00               0.0060 0.50       200       LogOR #> 311        0.03               0.0060 0.50       200       LogOR #> 312        0.06               0.0060 0.50       200       LogOR #> 313        0.00               0.0060 0.00       400       LogOR #> 314        0.03               0.0060 0.00       400       LogOR #> 315        0.06               0.0060 0.00       400       LogOR #> 316        0.00               0.0060 0.50       400       LogOR #> 317        0.03               0.0060 0.50       400       LogOR #> 318        0.06               0.0060 0.50       400       LogOR #> 319        0.00               0.0060 0.00       800       LogOR #> 320        0.03               0.0060 0.00       800       LogOR #> 321        0.06               0.0060 0.00       800       LogOR #> 322        0.00               0.0060 0.50       800       LogOR #> 323        0.03               0.0060 0.50       800       LogOR #> 324        0.06               0.0060 0.50       800       LogOR #>               sample_sizes condition_id #> 1    32, 64, 125, 250, 500            1 #> 2    32, 64, 125, 250, 500            2 #> 3    32, 64, 125, 250, 500            3 #> 4    32, 64, 125, 250, 500            4 #> 5    32, 64, 125, 250, 500            5 #> 6    32, 64, 125, 250, 500            6 #> 7    32, 64, 125, 250, 500            7 #> 8    32, 64, 125, 250, 500            8 #> 9    32, 64, 125, 250, 500            9 #> 10   32, 64, 125, 250, 500           10 #> 11   32, 64, 125, 250, 500           11 #> 12   32, 64, 125, 250, 500           12 #> 13   32, 64, 125, 250, 500           13 #> 14   32, 64, 125, 250, 500           14 #> 15   32, 64, 125, 250, 500           15 #> 16   32, 64, 125, 250, 500           16 #> 17   32, 64, 125, 250, 500           17 #> 18   32, 64, 125, 250, 500           18 #> 19   32, 64, 125, 250, 500           19 #> 20   32, 64, 125, 250, 500           20 #> 21   32, 64, 125, 250, 500           21 #> 22   32, 64, 125, 250, 500           22 #> 23   32, 64, 125, 250, 500           23 #> 24   32, 64, 125, 250, 500           24 #> 25   32, 64, 125, 250, 500           25 #> 26   32, 64, 125, 250, 500           26 #> 27   32, 64, 125, 250, 500           27 #> 28   32, 64, 125, 250, 500           28 #> 29   32, 64, 125, 250, 500           29 #> 30   32, 64, 125, 250, 500           30 #> 31   32, 64, 125, 250, 500           31 #> 32   32, 64, 125, 250, 500           32 #> 33   32, 64, 125, 250, 500           33 #> 34   32, 64, 125, 250, 500           34 #> 35   32, 64, 125, 250, 500           35 #> 36   32, 64, 125, 250, 500           36 #> 37   32, 64, 125, 250, 500           37 #> 38   32, 64, 125, 250, 500           38 #> 39   32, 64, 125, 250, 500           39 #> 40   32, 64, 125, 250, 500           40 #> 41   32, 64, 125, 250, 500           41 #> 42   32, 64, 125, 250, 500           42 #> 43   32, 64, 125, 250, 500           43 #> 44   32, 64, 125, 250, 500           44 #> 45   32, 64, 125, 250, 500           45 #> 46   32, 64, 125, 250, 500           46 #> 47   32, 64, 125, 250, 500           47 #> 48   32, 64, 125, 250, 500           48 #> 49   32, 64, 125, 250, 500           49 #> 50   32, 64, 125, 250, 500           50 #> 51   32, 64, 125, 250, 500           51 #> 52   32, 64, 125, 250, 500           52 #> 53   32, 64, 125, 250, 500           53 #> 54   32, 64, 125, 250, 500           54 #> 55   32, 64, 125, 250, 500           55 #> 56   32, 64, 125, 250, 500           56 #> 57   32, 64, 125, 250, 500           57 #> 58   32, 64, 125, 250, 500           58 #> 59   32, 64, 125, 250, 500           59 #> 60   32, 64, 125, 250, 500           60 #> 61   32, 64, 125, 250, 500           61 #> 62   32, 64, 125, 250, 500           62 #> 63   32, 64, 125, 250, 500           63 #> 64   32, 64, 125, 250, 500           64 #> 65   32, 64, 125, 250, 500           65 #> 66   32, 64, 125, 250, 500           66 #> 67   32, 64, 125, 250, 500           67 #> 68   32, 64, 125, 250, 500           68 #> 69   32, 64, 125, 250, 500           69 #> 70   32, 64, 125, 250, 500           70 #> 71   32, 64, 125, 250, 500           71 #> 72   32, 64, 125, 250, 500           72 #> 73   32, 64, 125, 250, 500           73 #> 74   32, 64, 125, 250, 500           74 #> 75   32, 64, 125, 250, 500           75 #> 76   32, 64, 125, 250, 500           76 #> 77   32, 64, 125, 250, 500           77 #> 78   32, 64, 125, 250, 500           78 #> 79   32, 64, 125, 250, 500           79 #> 80   32, 64, 125, 250, 500           80 #> 81   32, 64, 125, 250, 500           81 #> 82   32, 64, 125, 250, 500           82 #> 83   32, 64, 125, 250, 500           83 #> 84   32, 64, 125, 250, 500           84 #> 85   32, 64, 125, 250, 500           85 #> 86   32, 64, 125, 250, 500           86 #> 87   32, 64, 125, 250, 500           87 #> 88   32, 64, 125, 250, 500           88 #> 89   32, 64, 125, 250, 500           89 #> 90   32, 64, 125, 250, 500           90 #> 91   32, 64, 125, 250, 500           91 #> 92   32, 64, 125, 250, 500           92 #> 93   32, 64, 125, 250, 500           93 #> 94   32, 64, 125, 250, 500           94 #> 95   32, 64, 125, 250, 500           95 #> 96   32, 64, 125, 250, 500           96 #> 97   32, 64, 125, 250, 500           97 #> 98   32, 64, 125, 250, 500           98 #> 99   32, 64, 125, 250, 500           99 #> 100  32, 64, 125, 250, 500          100 #> 101  32, 64, 125, 250, 500          101 #> 102  32, 64, 125, 250, 500          102 #> 103  32, 64, 125, 250, 500          103 #> 104  32, 64, 125, 250, 500          104 #> 105  32, 64, 125, 250, 500          105 #> 106  32, 64, 125, 250, 500          106 #> 107  32, 64, 125, 250, 500          107 #> 108  32, 64, 125, 250, 500          108 #> 109  32, 64, 125, 250, 500          109 #> 110  32, 64, 125, 250, 500          110 #> 111  32, 64, 125, 250, 500          111 #> 112  32, 64, 125, 250, 500          112 #> 113  32, 64, 125, 250, 500          113 #> 114  32, 64, 125, 250, 500          114 #> 115  32, 64, 125, 250, 500          115 #> 116  32, 64, 125, 250, 500          116 #> 117  32, 64, 125, 250, 500          117 #> 118  32, 64, 125, 250, 500          118 #> 119  32, 64, 125, 250, 500          119 #> 120  32, 64, 125, 250, 500          120 #> 121  32, 64, 125, 250, 500          121 #> 122  32, 64, 125, 250, 500          122 #> 123  32, 64, 125, 250, 500          123 #> 124  32, 64, 125, 250, 500          124 #> 125  32, 64, 125, 250, 500          125 #> 126  32, 64, 125, 250, 500          126 #> 127  32, 64, 125, 250, 500          127 #> 128  32, 64, 125, 250, 500          128 #> 129  32, 64, 125, 250, 500          129 #> 130  32, 64, 125, 250, 500          130 #> 131  32, 64, 125, 250, 500          131 #> 132  32, 64, 125, 250, 500          132 #> 133  32, 64, 125, 250, 500          133 #> 134  32, 64, 125, 250, 500          134 #> 135  32, 64, 125, 250, 500          135 #> 136  32, 64, 125, 250, 500          136 #> 137  32, 64, 125, 250, 500          137 #> 138  32, 64, 125, 250, 500          138 #> 139  32, 64, 125, 250, 500          139 #> 140  32, 64, 125, 250, 500          140 #> 141  32, 64, 125, 250, 500          141 #> 142  32, 64, 125, 250, 500          142 #> 143  32, 64, 125, 250, 500          143 #> 144  32, 64, 125, 250, 500          144 #> 145  32, 64, 125, 250, 500          145 #> 146  32, 64, 125, 250, 500          146 #> 147  32, 64, 125, 250, 500          147 #> 148  32, 64, 125, 250, 500          148 #> 149  32, 64, 125, 250, 500          149 #> 150  32, 64, 125, 250, 500          150 #> 151 50, 100, 100, 250, 500          151 #> 152 50, 100, 100, 250, 500          152 #> 153 50, 100, 100, 250, 500          153 #> 154 50, 100, 100, 250, 500          154 #> 155 50, 100, 100, 250, 500          155 #> 156 50, 100, 100, 250, 500          156 #> 157 50, 100, 100, 250, 500          157 #> 158 50, 100, 100, 250, 500          158 #> 159 50, 100, 100, 250, 500          159 #> 160 50, 100, 100, 250, 500          160 #> 161 50, 100, 100, 250, 500          161 #> 162 50, 100, 100, 250, 500          162 #> 163 50, 100, 100, 250, 500          163 #> 164 50, 100, 100, 250, 500          164 #> 165 50, 100, 100, 250, 500          165 #> 166 50, 100, 100, 250, 500          166 #> 167 50, 100, 100, 250, 500          167 #> 168 50, 100, 100, 250, 500          168 #> 169 50, 100, 100, 250, 500          169 #> 170 50, 100, 100, 250, 500          170 #> 171 50, 100, 100, 250, 500          171 #> 172 50, 100, 100, 250, 500          172 #> 173 50, 100, 100, 250, 500          173 #> 174 50, 100, 100, 250, 500          174 #> 175 50, 100, 100, 250, 500          175 #> 176 50, 100, 100, 250, 500          176 #> 177 50, 100, 100, 250, 500          177 #> 178 50, 100, 100, 250, 500          178 #> 179 50, 100, 100, 250, 500          179 #> 180 50, 100, 100, 250, 500          180 #> 181  32, 64, 125, 250, 500          181 #> 182  32, 64, 125, 250, 500          182 #> 183  32, 64, 125, 250, 500          183 #> 184  32, 64, 125, 250, 500          184 #> 185  32, 64, 125, 250, 500          185 #> 186  32, 64, 125, 250, 500          186 #> 187  32, 64, 125, 250, 500          187 #> 188  32, 64, 125, 250, 500          188 #> 189  32, 64, 125, 250, 500          189 #> 190  32, 64, 125, 250, 500          190 #> 191  32, 64, 125, 250, 500          191 #> 192  32, 64, 125, 250, 500          192 #> 193  32, 64, 125, 250, 500          193 #> 194  32, 64, 125, 250, 500          194 #> 195  32, 64, 125, 250, 500          195 #> 196  32, 64, 125, 250, 500          196 #> 197  32, 64, 125, 250, 500          197 #> 198  32, 64, 125, 250, 500          198 #> 199  32, 64, 125, 250, 500          199 #> 200  32, 64, 125, 250, 500          200 #> 201  32, 64, 125, 250, 500          201 #> 202  32, 64, 125, 250, 500          202 #> 203  32, 64, 125, 250, 500          203 #> 204  32, 64, 125, 250, 500          204 #> 205  32, 64, 125, 250, 500          205 #> 206  32, 64, 125, 250, 500          206 #> 207  32, 64, 125, 250, 500          207 #> 208  32, 64, 125, 250, 500          208 #> 209  32, 64, 125, 250, 500          209 #> 210  32, 64, 125, 250, 500          210 #> 211  32, 64, 125, 250, 500          211 #> 212  32, 64, 125, 250, 500          212 #> 213  32, 64, 125, 250, 500          213 #> 214  32, 64, 125, 250, 500          214 #> 215  32, 64, 125, 250, 500          215 #> 216  32, 64, 125, 250, 500          216 #> 217  32, 64, 125, 250, 500          217 #> 218  32, 64, 125, 250, 500          218 #> 219  32, 64, 125, 250, 500          219 #> 220  32, 64, 125, 250, 500          220 #> 221  32, 64, 125, 250, 500          221 #> 222  32, 64, 125, 250, 500          222 #> 223  32, 64, 125, 250, 500          223 #> 224  32, 64, 125, 250, 500          224 #> 225  32, 64, 125, 250, 500          225 #> 226  32, 64, 125, 250, 500          226 #> 227  32, 64, 125, 250, 500          227 #> 228  32, 64, 125, 250, 500          228 #> 229  32, 64, 125, 250, 500          229 #> 230  32, 64, 125, 250, 500          230 #> 231  32, 64, 125, 250, 500          231 #> 232  32, 64, 125, 250, 500          232 #> 233  32, 64, 125, 250, 500          233 #> 234  32, 64, 125, 250, 500          234 #> 235  32, 64, 125, 250, 500          235 #> 236  32, 64, 125, 250, 500          236 #> 237  32, 64, 125, 250, 500          237 #> 238  32, 64, 125, 250, 500          238 #> 239  32, 64, 125, 250, 500          239 #> 240  32, 64, 125, 250, 500          240 #> 241  32, 64, 125, 250, 500          241 #> 242  32, 64, 125, 250, 500          242 #> 243  32, 64, 125, 250, 500          243 #> 244  32, 64, 125, 250, 500          244 #> 245  32, 64, 125, 250, 500          245 #> 246  32, 64, 125, 250, 500          246 #> 247  32, 64, 125, 250, 500          247 #> 248  32, 64, 125, 250, 500          248 #> 249  32, 64, 125, 250, 500          249 #> 250  32, 64, 125, 250, 500          250 #> 251  32, 64, 125, 250, 500          251 #> 252  32, 64, 125, 250, 500          252 #> 253  32, 64, 125, 250, 500          253 #> 254  32, 64, 125, 250, 500          254 #> 255  32, 64, 125, 250, 500          255 #> 256  32, 64, 125, 250, 500          256 #> 257  32, 64, 125, 250, 500          257 #> 258  32, 64, 125, 250, 500          258 #> 259  32, 64, 125, 250, 500          259 #> 260  32, 64, 125, 250, 500          260 #> 261  32, 64, 125, 250, 500          261 #> 262  32, 64, 125, 250, 500          262 #> 263  32, 64, 125, 250, 500          263 #> 264  32, 64, 125, 250, 500          264 #> 265  32, 64, 125, 250, 500          265 #> 266  32, 64, 125, 250, 500          266 #> 267  32, 64, 125, 250, 500          267 #> 268  32, 64, 125, 250, 500          268 #> 269  32, 64, 125, 250, 500          269 #> 270  32, 64, 125, 250, 500          270 #> 271  32, 64, 125, 250, 500          271 #> 272  32, 64, 125, 250, 500          272 #> 273  32, 64, 125, 250, 500          273 #> 274  32, 64, 125, 250, 500          274 #> 275  32, 64, 125, 250, 500          275 #> 276  32, 64, 125, 250, 500          276 #> 277  32, 64, 125, 250, 500          277 #> 278  32, 64, 125, 250, 500          278 #> 279  32, 64, 125, 250, 500          279 #> 280  32, 64, 125, 250, 500          280 #> 281  32, 64, 125, 250, 500          281 #> 282  32, 64, 125, 250, 500          282 #> 283  32, 64, 125, 250, 500          283 #> 284  32, 64, 125, 250, 500          284 #> 285  32, 64, 125, 250, 500          285 #> 286  32, 64, 125, 250, 500          286 #> 287  32, 64, 125, 250, 500          287 #> 288  32, 64, 125, 250, 500          288 #> 289  32, 64, 125, 250, 500          289 #> 290  32, 64, 125, 250, 500          290 #> 291  32, 64, 125, 250, 500          291 #> 292  32, 64, 125, 250, 500          292 #> 293  32, 64, 125, 250, 500          293 #> 294  32, 64, 125, 250, 500          294 #> 295  32, 64, 125, 250, 500          295 #> 296  32, 64, 125, 250, 500          296 #> 297  32, 64, 125, 250, 500          297 #> 298  32, 64, 125, 250, 500          298 #> 299  32, 64, 125, 250, 500          299 #> 300  32, 64, 125, 250, 500          300 #> 301 50, 100, 100, 250, 500          301 #> 302 50, 100, 100, 250, 500          302 #> 303 50, 100, 100, 250, 500          303 #> 304 50, 100, 100, 250, 500          304 #> 305 50, 100, 100, 250, 500          305 #> 306 50, 100, 100, 250, 500          306 #> 307 50, 100, 100, 250, 500          307 #> 308 50, 100, 100, 250, 500          308 #> 309 50, 100, 100, 250, 500          309 #> 310 50, 100, 100, 250, 500          310 #> 311 50, 100, 100, 250, 500          311 #> 312 50, 100, 100, 250, 500          312 #> 313 50, 100, 100, 250, 500          313 #> 314 50, 100, 100, 250, 500          314 #> 315 50, 100, 100, 250, 500          315 #> 316 50, 100, 100, 250, 500          316 #> 317 50, 100, 100, 250, 500          317 #> 318 50, 100, 100, 250, 500          318 #> 319 50, 100, 100, 250, 500          319 #> 320 50, 100, 100, 250, 500          320 #> 321 50, 100, 100, 250, 500          321 #> 322 50, 100, 100, 250, 500          322 #> 323 50, 100, 100, 250, 500          323 #> 324 50, 100, 100, 250, 500          324"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/download_dgm.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Datasets of a DGM — download_dgm","title":"Download Datasets of a DGM — download_dgm","text":"function downloads datasets specified Data-Generating Mechanism (DGM). data located https://osf.io/exf3m/.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/download_dgm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Datasets of a DGM — download_dgm","text":"","code":"download_dgm_datasets(   dgm_name,   path = NULL,   overwrite = FALSE,   progress = TRUE )  download_dgm_results(dgm_name, path = NULL, overwrite = FALSE, progress = TRUE)  download_dgm_measures(   dgm_name,   path = NULL,   overwrite = FALSE,   progress = TRUE )"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/download_dgm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Datasets of a DGM — download_dgm","text":"dgm_name Character string specifying name DGM dataset download. path Character string specifying directory path datasets/results/measures saved. Defaults location specified via PublicationBiasBenchmark.get_option(\"simulation_directory\"). objects stored dgm_name/datasets, dgm_name/results, dgm_name/measures subfolders. overwrite Logical indicating whether overwrite existing files. Defaults FALSE, means missing files downloaded. progress Logical indicating whether show progress downloading files. Defaults TRUE.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/download_dgm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download Datasets of a DGM — download_dgm","text":"TRUE download successful, otherwise error raised.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/download_dgm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Datasets of a DGM — download_dgm","text":"","code":"if (FALSE) { # \\dontrun{   download_dgm_datasets(\"no_bias\") } # }"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/measures.html","id":null,"dir":"Reference","previous_headings":"","what":"Performance Measures and Monte Carlo Standard Errors — measures","title":"Performance Measures and Monte Carlo Standard Errors — measures","text":"comprehensive set functions computing performance measures Monte Carlo Standard Errors (MCSE) simulation studies. functions based definitions Table 3 Siepe et al. (2024) . Winkler interval score defined Winkler (1972) . Positive negative likelihood ratios defined Huang Trinquart (2023)  Deeks Altman (2004) . Also see Morris et al. (2019)  additional details. Bias relative bias modified account possibly different true values across repetitions.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/measures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performance Measures and Monte Carlo Standard Errors — measures","text":"","code":"bias(theta_hat, theta)  bias_mcse(theta_hat)  relative_bias(theta_hat, theta)  relative_bias_mcse(theta_hat, theta)  mse(theta_hat, theta)  mse_mcse(theta_hat, theta)  rmse(theta_hat, theta)  rmse_mcse(theta_hat, theta)  empirical_variance(theta_hat)  empirical_variance_mcse(theta_hat)  empirical_se(theta_hat)  empirical_se_mcse(theta_hat)  coverage(ci_lower, ci_upper, theta)  coverage_mcse(ci_lower, ci_upper, theta)  power(test_rejects_h0)  power_mcse(test_rejects_h0)  mean_ci_width(ci_upper, ci_lower)  mean_ci_width_mcse(ci_upper, ci_lower)  mean_generic_statistic(G)  mean_generic_statistic_mcse(G)  positive_likelihood_ratio(tp, fp, fn, tn)  positive_likelihood_ratio_mcse(tp, fp, fn, tn)  negative_likelihood_ratio(tp, fp, fn, tn)  negative_likelihood_ratio_mcse(tp, fp, fn, tn)  interval_score(ci_lower, ci_upper, theta, alpha = 0.05)  interval_score_mcse(ci_lower, ci_upper, theta, alpha = 0.05)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/measures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performance Measures and Monte Carlo Standard Errors — measures","text":"theta_hat Vector parameter estimates simulations theta True parameter value ci_lower Vector lower confidence interval bounds ci_upper Vector upper confidence interval bounds test_rejects_h0 Logical vector indicating whether statistical tests reject null hypothesis G Vector generic statistics simulations tp Numeric count true positive hypothesis tests fp Numeric count false positive hypothesis tests fn Numeric count false negative hypothesis tests tn Numeric count true negative hypothesis tests alpha Numeric indicating 1 - coverage level interval_score calculation","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/measures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performance Measures and Monte Carlo Standard Errors — measures","text":"metric function returns numeric value representing performance measure. MCSE function returns numeric value representing Monte Carlo standard error.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/measures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Performance Measures and Monte Carlo Standard Errors — measures","text":"package provides following performance measures corresponding MCSE functions: bias(theta_hat, theta): Bias estimate relative_bias(theta_hat, theta): Relative bias estimate mse(theta_hat, theta): Mean Square Error rmse(theta_hat, theta): Root Mean Square Error empirical_variance(theta_hat): Empirical variance empirical_se(theta_hat): Empirical standard error coverage(ci_lower, ci_upper, theta): Coverage probability mean_ci_width(ci_upper, ci_lower): Mean confidence interval width interval_score(ci_lower, ci_upper, theta, alpha): interval_score power(test_rejects_h0): Statistical power positive_likelihood_ratio(tp, fp, fn, tn): Log positive likelihood ratio negative_likelihood_ratio(tp, fp, fn, tn): Log negative likelihood ratio mean_generic_statistic(G): Mean generic statistic","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/measures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performance Measures and Monte Carlo Standard Errors — measures","text":"","code":"# Generate some example data set.seed(123) theta_true <- 0.5 theta_estimates <- rnorm(1000, mean = theta_true, sd = 0.1)  # Compute bias and its MCSE bias_est <- bias(theta_estimates, theta_true) bias_se <- bias_mcse(theta_estimates)  # Compute MSE and its MCSE mse_est <- mse(theta_estimates, theta_true) mse_se <- mse_mcse(theta_estimates, theta_true)  # Example with coverage ci_lower <- theta_estimates - 1.96 * 0.1 ci_upper <- theta_estimates + 1.96 * 0.1 coverage_est <- coverage(ci_lower, ci_upper, theta_true) coverage_se <- coverage_mcse(ci_lower, ci_upper, theta_true)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.AK.html","id":null,"dir":"Reference","previous_headings":"","what":"AK Method — method.AK","title":"AK Method — method.AK","text":"Implements Andrews & Kasy (AK) method publication bias correction meta-analysis. AK method categorizes estimated effects groups different probabilities published. AK1 uses symmetric selection grouping estimates significant (|t| ≥ 1.96) insignificant (|t| < 1.96) estimates. AK2 uses asymmetric selection four groups based significance sign: highly significant positive/negative effects marginally significant positive/negative effects, different publication probabilities. See Andrews Kasy (2019)  details.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.AK.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AK Method — method.AK","text":"","code":"# S3 method for class 'AK' method(method_name, data, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.AK.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"AK Method — method.AK","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes), sei (standard errors), study_id (clustering whereever available) settings List method settings (see Details.)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.AK.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"AK Method — method.AK","text":"Data frame AK results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.AK.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"AK Method — method.AK","text":"following settings implemented \"default\" Uses AK1 estimator (symmetric selection) \"AK1\" Symmetric selection model grouping estimates significant (|t| ≥ 1.96) insignificant (|t| < 1.96) categories relative publication probabilities 1 p1 respectively. \"AK2\" Asymmetric selection model four groups based t-statistics: () t ≥ 1.96, (b) t < -1.96, (c) -1.96 ≤ t < 0, (d) 0 ≤ t < 1.96, relative publication probabilities 1, p1, p2, p3 respectively.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.AK.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"AK Method — method.AK","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply AK method result <- run_method(\"AK\", data, \"default\") #> Warning: NaNs produced print(result) #>   method  estimate standard_error   ci_lower  ci_upper    p_value BF #> 1     AK 0.1239951     0.07280359 -0.1892534 0.4372437 0.09217477 NA #>   convergence note tau_estimate      tau2_se   bias_coefficient #> 1        TRUE   NA            0 1.084652e-10 0.0685673164403796 #>   bias_coefficient_se version method_setting #> 1   0.110251775402335     AK1        default"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.EK.html","id":null,"dir":"Reference","previous_headings":"","what":"Endogenous Kink Method — method.EK","title":"Endogenous Kink Method — method.EK","text":"Implements endogenous kink (EK) method proposed Bom Rachinger publication bias correction meta-analysis. method modifies PET-PEESE approach incorporating non-linear relationship publication bias standard errors kinked regression specification. method recognizes true effect non-zero, minimal publication selection standard errors small (since estimates significant), selection increases standard errors grow. kink point endogenously determined using two-step procedure based confidence interval initial effect estimate. See Bom Rachinger (2019)  details.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.EK.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Endogenous Kink Method — method.EK","text":"","code":"# S3 method for class 'EK' method(method_name, data, settings = NULL)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.EK.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Endogenous Kink Method — method.EK","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes) sei (standard errors) settings List method settings (settings version implemented)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.EK.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Endogenous Kink Method — method.EK","text":"Data frame EK results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.EK.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Endogenous Kink Method — method.EK","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply EK method result <- run_method(\"EK\", data) print(result) #>   method   estimate standard_error   ci_lower ci_upper   p_value BF convergence #> 1     EK -0.1360294      0.1863442 -0.7290598 0.457001 0.5182334 NA        TRUE #>   note method_setting #> 1   NA        default"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.FMA.html","id":null,"dir":"Reference","previous_headings":"","what":"Fixed Effects Meta-Analysis Method — method.FMA","title":"Fixed Effects Meta-Analysis Method — method.FMA","text":"Implements publication bias-unadjusted fixed effects meta-analysis.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.FMA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fixed Effects Meta-Analysis Method — method.FMA","text":"","code":"# S3 method for class 'FMA' method(method_name, data, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.FMA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fixed Effects Meta-Analysis Method — method.FMA","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes) sei (standard errors) settings List method settings (see Details.)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.FMA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fixed Effects Meta-Analysis Method — method.FMA","text":"Data frame FMA results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.FMA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fixed Effects Meta-Analysis Method — method.FMA","text":"following settings implemented \"default\" T-distribution adjustment (test = \"t\") cluster robust standard errors small-sample adjustment (converged, otherwise small-sample adjustment cluster robust standard errors) fixed effects meta-analysis study_ids specified data","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.FMA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fixed Effects Meta-Analysis Method — method.FMA","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply FMA method result <- run_method(\"FMA\", data) print(result) #>   method  estimate standard_error   ci_lower  ci_upper     p_value BF #> 1    FMA 0.2179928     0.04501055 0.09302349 0.3429621 0.008380921 NA #>   convergence note tau_p_value method_setting #> 1        TRUE   NA   0.2941821        default"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PEESE.html","id":null,"dir":"Reference","previous_headings":"","what":"PEESE (Precision-Effect Estimate with Standard Errors) Method — method.PEESE","title":"PEESE (Precision-Effect Estimate with Standard Errors) Method — method.PEESE","text":"Implements Precision-Effect Estimate Standard Errors method publication bias correction. PEESE regresses effect sizes standard errors^2 correct publication bias. intercept represents bias-corrected effect size estimate. See Stanley Doucouliagos (2014)  details.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PEESE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PEESE (Precision-Effect Estimate with Standard Errors) Method — method.PEESE","text":"","code":"# S3 method for class 'PEESE' method(method_name, data, settings = NULL)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PEESE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PEESE (Precision-Effect Estimate with Standard Errors) Method — method.PEESE","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes) sei (standard errors) settings List method settings (settings version implemented)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PEESE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PEESE (Precision-Effect Estimate with Standard Errors) Method — method.PEESE","text":"Data frame PEESE results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PEESE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PEESE (Precision-Effect Estimate with Standard Errors) Method — method.PEESE","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply PEESE method result <- run_method(\"PEESE\", data) print(result) #>             method   estimate standard_error   ci_lower  ci_upper   p_value BF #> (Intercept)  PEESE 0.06720823     0.09919638 -0.1272167 0.2616331 0.5466436 NA #>             convergence note bias_coefficient bias_p_value method_setting #> (Intercept)        TRUE   NA         14.88532    0.1927957        default"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PET.html","id":null,"dir":"Reference","previous_headings":"","what":"PET (Precision-Effect Test) Method — method.PET","title":"PET (Precision-Effect Test) Method — method.PET","text":"Implements Precision-Effect Test publication bias correction. PET regresses effect sizes standard errors test correct publication bias. intercept represents bias-corrected effect size estimate. See Stanley Doucouliagos (2014)  details.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PET.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PET (Precision-Effect Test) Method — method.PET","text":"","code":"# S3 method for class 'PET' method(method_name, data, settings = NULL)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PET.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PET (Precision-Effect Test) Method — method.PET","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes) sei (standard errors) settings List method settings (settings version implemented)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PET.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PET (Precision-Effect Test) Method — method.PET","text":"Data frame PET results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PET.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PET (Precision-Effect Test) Method — method.PET","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply PET method result <- run_method(\"PET\", data) print(result) #>             method   estimate standard_error  ci_lower  ci_upper   p_value BF #> (Intercept)    PET -0.1360294      0.1863442 -0.501264 0.2292052 0.5182334 NA #>             convergence note bias_coefficient bias_p_value method_setting #> (Intercept)        TRUE   NA          3.59473     0.147487        default"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PETPEESE.html","id":null,"dir":"Reference","previous_headings":"","what":"PET-PEESE (Precision-Effect Test and Precision-Effect Estimate with Standard Errors) Method — method.PETPEESE","title":"PET-PEESE (Precision-Effect Test and Precision-Effect Estimate with Standard Errors) Method — method.PETPEESE","text":"Implements Precision-Effect Test Precision-Effect Estimate Standard Errors (PET-PEESE) regresses effect sizes standard errors^2 correct publication bias. intercept represents bias-corrected effect size estimate. See Stanley Doucouliagos (2014)  details.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PETPEESE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PET-PEESE (Precision-Effect Test and Precision-Effect Estimate with Standard Errors) Method — method.PETPEESE","text":"","code":"# S3 method for class 'PETPEESE' method(method_name, data, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PETPEESE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PET-PEESE (Precision-Effect Test and Precision-Effect Estimate with Standard Errors) Method — method.PETPEESE","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes) sei (standard errors) settings List method settings (see Details)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PETPEESE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PET-PEESE (Precision-Effect Test and Precision-Effect Estimate with Standard Errors) Method — method.PETPEESE","text":"Data frame PET-PEESE results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PETPEESE.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PET-PEESE (Precision-Effect Test and Precision-Effect Estimate with Standard Errors) Method — method.PETPEESE","text":"following settings implemented \"default\" (conditional_alpha = 0.10) determines whether use PET (PET's effect significant alpha = 0.10 PEESE estimate (PET's effect significant alpha = 0.10)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.PETPEESE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PET-PEESE (Precision-Effect Test and Precision-Effect Estimate with Standard Errors) Method — method.PETPEESE","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply PETPEESE method result <- run_method(\"PETPEESE\", data) print(result) #>               method   estimate standard_error  ci_lower  ci_upper   p_value BF #> (Intercept) PETPEESE -0.1360294      0.1863442 -0.501264 0.2292052 0.5182334 NA #>             convergence note bias_coefficient bias_p_value selected_method #> (Intercept)        TRUE   NA          3.59473     0.147487             PET #>             method_setting #> (Intercept)        default"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.RMA.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Effects Meta-Analysis Method — method.RMA","title":"Random Effects Meta-Analysis Method — method.RMA","text":"Implements publication bias-unadjusted random effects meta-analysis.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.RMA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Effects Meta-Analysis Method — method.RMA","text":"","code":"# S3 method for class 'RMA' method(method_name, data, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.RMA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Effects Meta-Analysis Method — method.RMA","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes) sei (standard errors) settings List method settings (see Details.)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.RMA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Effects Meta-Analysis Method — method.RMA","text":"Data frame RMA results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.RMA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Effects Meta-Analysis Method — method.RMA","text":"following settings implemented \"default\" Restricted Maximum Likelihood estimator (method = \"REML\") Knapp-Hartung adjustment (test = \"knha\") simple random effects meta-analysis Restricted Maximum Likelihood estimator (method = \"REML\") t-distribution adjustment (test = \"t\") cluster robust standard errors small-sample adjustment (converged, otherwise small-sample adjustment cluster robust standard errors) multilevel random effects meta-analysis study_ids specified data","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.RMA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Effects Meta-Analysis Method — method.RMA","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply RMA method result <- run_method(\"RMA\", data) print(result) #>   method  estimate standard_error   ci_lower  ci_upper    p_value BF #> 1    RMA 0.2255651     0.05033069 0.08582468 0.3653055 0.01097584 NA #>   convergence note tau_estimate tau_ci_lower tau_ci_upper tau_p_value #> 1        TRUE   NA   0.05721499            0    0.3038259   0.2941821 #>   method_setting #> 1        default"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.RoBMA.html","id":null,"dir":"Reference","previous_headings":"","what":"Robust Bayesian Meta-Analysis (RoBMA) Method — method.RoBMA","title":"Robust Bayesian Meta-Analysis (RoBMA) Method — method.RoBMA","text":"Implements robust Bayesian meta-analysis (RoBMA) method uses Bayesian model-averaging combine results across several complementary publication bias adjustment methods. See Maier et al. (2023)  Bartoš et al. (2023)  details. Note prior settings dispatched based \"es_type\" column attached dataset. resulting estimates summarized scale dataset input (\"r\", heterogeneity summarized Fisher's z).","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.RoBMA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robust Bayesian Meta-Analysis (RoBMA) Method — method.RoBMA","text":"","code":"# S3 method for class 'RoBMA' method(method_name, data, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.RoBMA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robust Bayesian Meta-Analysis (RoBMA) Method — method.RoBMA","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes), sei (standard errors), es_type (either \"SMD\" Cohen's d / Hedge's g, \"logOR\" log odds ratio, \"z\" Fisher's z, \"r\" correlations. Defaults \"none\" re-scales default priors unit-information width based total sample size supplied \"ni\".) settings List method settings (see Details.)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.RoBMA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Robust Bayesian Meta-Analysis (RoBMA) Method — method.RoBMA","text":"Data frame RoBMA results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.RoBMA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Robust Bayesian Meta-Analysis (RoBMA) Method — method.RoBMA","text":"following settings implemented \"default\" RoBMA-PSMA publication bias adjustment described Bartoš et al. (2023) . (MCMC settings reduced speed-simulations) three-level specification whenever \"study_ids\" supplied data \"PSMA\" RoBMA-PSMA publication bias adjustment described Bartoš et al. (2023) . (MCMC settings reduced speed-simulations) three-level specification whenever \"study_ids\" supplied data","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.RoBMA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Robust Bayesian Meta-Analysis (RoBMA) Method — method.RoBMA","text":"","code":"if (FALSE) { # \\dontrun{ # Generate some example data data <- data.frame(   yi      = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei     = c(0.1, 0.15, 0.08, 0.12, 0.09),   es_type = \"SMD\" )  # Apply RoBMA method result <- run_method(\"RoBMA\", data) print(result) } # }"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.SM.html","id":null,"dir":"Reference","previous_headings":"","what":"SM (Selection Models) Method — method.SM","title":"SM (Selection Models) Method — method.SM","text":"Implements Selection Models publication bias correction meta-analysis. method first fits random effects meta-analysis model, applies selection modeling adjust publication bias using metafor package. Selection models account probability studies published based p-values effect sizes. See Vevea Hedges (1995)  details.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.SM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SM (Selection Models) Method — method.SM","text":"","code":"# S3 method for class 'SM' method(method_name, data, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.SM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SM (Selection Models) Method — method.SM","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes) sei (standard errors) settings List method settings (see Details.)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.SM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"SM (Selection Models) Method — method.SM","text":"Data frame SM results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.SM.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"SM (Selection Models) Method — method.SM","text":"following settings implemented \"default\" \"3PSM\" 3-parameter step function selection model Maximum Likelihood estimator (method = \"ML\") one step one-sided p = 0.025 (.e., selection significance)) \"4PSM\" 4-parameter step function selection model Maximum Likelihood estimator (method = \"ML\") two steps one-sided p = 0.025 p = 0.50 (.e., selection significance direction effect)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.SM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"SM (Selection Models) Method — method.SM","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply SM method result <- run_method(\"SM\", data, \"3PSM\") #> Error : Optimizer (optim) did not achieve convergence (convergence = 1). print(result) #>   method estimate standard_error ci_lower ci_upper p_value BF convergence #> 1     SM       NA             NA       NA       NA      NA NA       FALSE #>                                                                         note #> 1 Error : Optimizer (optim) did not achieve convergence (convergence = 1).\\n #>   tau_estimate tau_ci_lower tau_ci_upper tau_p_value bias_coefficient #> 1           NA           NA           NA          NA               NA #>   bias_coefficient_se bias_p_value method_setting #> 1                  NA           NA           3PSM"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WAAPWLS.html","id":null,"dir":"Reference","previous_headings":"","what":"WAAPWLS (Weighted Average of Adequately Powered Studies) Method — method.WAAPWLS","title":"WAAPWLS (Weighted Average of Adequately Powered Studies) Method — method.WAAPWLS","text":"Implements WAAPWLS method meta-analysis, combines WLS WAAP approaches. First fits WLS model studies, identifies high-powered studies based criterion WLS estimate divided 2.8 greater equal standard error. least 2 high-powered studies found, uses WAAP (weighted average adequate power studies ), otherwise uses original WLS estimate. See Stanley et al. (2017)  details.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WAAPWLS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"WAAPWLS (Weighted Average of Adequately Powered Studies) Method — method.WAAPWLS","text":"","code":"# S3 method for class 'WAAPWLS' method(method_name, data, settings = NULL)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WAAPWLS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"WAAPWLS (Weighted Average of Adequately Powered Studies) Method — method.WAAPWLS","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes) sei (standard errors) settings List method settings (settings version implemented)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WAAPWLS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"WAAPWLS (Weighted Average of Adequately Powered Studies) Method — method.WAAPWLS","text":"Data frame WAAPWLS results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WAAPWLS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"WAAPWLS (Weighted Average of Adequately Powered Studies) Method — method.WAAPWLS","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply WAAPWLS method result <- run_method(\"WAAPWLS\", data) print(result) #>              method  estimate standard_error  ci_lower  ci_upper    p_value BF #> (Intercept) WAAPWLS 0.2179928     0.04998789 0.1200165 0.3159691 0.01205352 NA #>             convergence note selected_method n_high_powered method_setting #> (Intercept)        TRUE   NA             WLS              0        default"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WILS.html","id":null,"dir":"Reference","previous_headings":"","what":"Weighted and Iterated Least Squares (WILS) Method — method.WILS","title":"Weighted and Iterated Least Squares (WILS) Method — method.WILS","text":"Implements weighted iterated least squares (WILS) method publication bias correction meta-analysis. method based idea using excess statistical significance (ESS) identify many underpowered studies removed reduce publication selection bias. See Stanley Doucouliagos (2024)  details.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WILS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weighted and Iterated Least Squares (WILS) Method — method.WILS","text":"","code":"# S3 method for class 'WILS' method(method_name, data, settings = NULL)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WILS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weighted and Iterated Least Squares (WILS) Method — method.WILS","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes) sei (standard errors) settings List method settings (settings version implemented)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WILS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Weighted and Iterated Least Squares (WILS) Method — method.WILS","text":"Data frame WILS results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WILS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Weighted and Iterated Least Squares (WILS) Method — method.WILS","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply WILS method result <- run_method(\"WILS\", data) print(result) #>             method  estimate standard_error   ci_lower  ci_upper   p_value BF #> (Intercept)   WILS 0.1390244     0.04878049 0.04341463 0.2346341 0.2148312 NA #>             convergence note n_removed method_setting #> (Intercept)        TRUE   NA         3        default"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WLS.html","id":null,"dir":"Reference","previous_headings":"","what":"WLS (Weighted Least Squares) Method — method.WLS","title":"WLS (Weighted Least Squares) Method — method.WLS","text":"Implements Weighted Least Squares method meta-analysis. WLS fits weighted regression model effect sizes outcome weights based inverse squared standard errors. intercept represents weighted average effect size estimate.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WLS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"WLS (Weighted Least Squares) Method — method.WLS","text":"","code":"# S3 method for class 'WLS' method(method_name, data, settings = NULL)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WLS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"WLS (Weighted Least Squares) Method — method.WLS","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes) sei (standard errors) settings List method settings (settings version implemented)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WLS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"WLS (Weighted Least Squares) Method — method.WLS","text":"Data frame WLS results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.WLS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"WLS (Weighted Least Squares) Method — method.WLS","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply WLS method result <- run_method(\"WLS\", data) print(result) #>             method  estimate standard_error  ci_lower  ci_upper    p_value BF #> (Intercept)    WLS 0.2179928     0.04998789 0.1200165 0.3159691 0.01205352 NA #>             convergence note method_setting #> (Intercept)        TRUE   NA        default"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Default method handler — method.default","title":"Default method handler — method.default","text":"Default method handler","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default method handler — method.default","text":"","code":"# Default S3 method method(method_name, data, settings = list())"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default method handler — method.default","text":"method_name Character string specifying method type data Data frame containing yi (effect sizes) sei (standard errors) settings Either character identifying method version list containing method-specific settings. emty input result running default (first implemented) version method.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.html","id":null,"dir":"Reference","previous_headings":"","what":"Method Method — method","title":"Method Method — method","text":"S3 Method defining methods. See run_method() usage details.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Method Method — method","text":"","code":"method(method_name, data, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Method Method — method","text":"method_name Character string specifying method type data Data frame containing yi (effect sizes) sei (standard errors) settings Either character identifying method version list containing method-specific settings. emty input result running default (first implemented) version method.","code":""},{"path":[]},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Method Method — method","text":"","code":"data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4),   sei = c(0.1, 0.15, 0.08, 0.12) ) result <- run_method(\"RMA\", data, \"default\")"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean Method — method.mean","title":"Mean Method — method.mean","text":"Implements unweighted mean method. .e., mean observed effect sizes.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean Method — method.mean","text":"","code":"# S3 method for class 'mean' method(method_name, data, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean Method — method.mean","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes) settings List method settings (see Details.)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean Method — method.mean","text":"Data frame mean results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.mean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean Method — method.mean","text":"following settings implemented \"default\" settings","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean Method — method.mean","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply mean method result <- run_method(\"mean\", data) print(result) #>   method estimate standard_error ci_lower ci_upper      p_value BF convergence #> 1   mean     0.25     0.04955805 0.152868 0.347132 4.544962e-07 NA        TRUE #>   note method_setting #> 1   NA        default"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.pcurve.html","id":null,"dir":"Reference","previous_headings":"","what":"pcurve (P-Curve) Method — method.pcurve","title":"pcurve (P-Curve) Method — method.pcurve","text":"Implements P-Curve method. P-Curve analyzes distribution p-values significant studies assess whether significant findings reflect true effects QRP/publication bias. method also provides tests evidential value, lack evidential value, p-hacking. See Simonsohn et al. (2014)  details.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.pcurve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pcurve (P-Curve) Method — method.pcurve","text":"","code":"# S3 method for class 'pcurve' method(method_name, data, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.pcurve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pcurve (P-Curve) Method — method.pcurve","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes), sei (standard errors), ni (sample sizes wherever available, otherwise set Inf) settings List method settings (see Details)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.pcurve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pcurve (P-Curve) Method — method.pcurve","text":"Data frame P-Curve results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.pcurve.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"pcurve (P-Curve) Method — method.pcurve","text":"following settings implemented \"default\" options","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.pcurve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"pcurve (P-Curve) Method — method.pcurve","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply pcurve method result <- run_method(\"pcurve\", data) print(result) #>   method estimate standard_error ci_lower ci_upper p_value BF convergence note #> 1 pcurve  3.99994             NA       NA       NA      NA NA        TRUE   NA #>   p_value_evidence p_value_lack p_value_hack method_setting #> 1        0.3699365    0.6300635    0.1962818        default"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.puniform.html","id":null,"dir":"Reference","previous_headings":"","what":"puniform (P-Uniform) Method — method.puniform","title":"puniform (P-Uniform) Method — method.puniform","text":"Implements P-Uniform method publication bias detection correction. P-Uniform uses distribution p-values significant studies test publication bias estimate effect size corrected publication bias. method assumes p-values follow uniform distribution null hypothesis effect, uses detect correct bias. See Van Assen et al. (2015)  van Aert van Assen (2025)  details.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.puniform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"puniform (P-Uniform) Method — method.puniform","text":"","code":"# S3 method for class 'puniform' method(method_name, data, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.puniform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"puniform (P-Uniform) Method — method.puniform","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes) sei (standard errors) settings List method settings (see Details)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.puniform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"puniform (P-Uniform) Method — method.puniform","text":"Data frame P-Uniform results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.puniform.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"puniform (P-Uniform) Method — method.puniform","text":"following settings implemented \"default\" Default p-uniform analysis settings.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.puniform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"puniform (P-Uniform) Method — method.puniform","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply puniform method result <- run_method(\"puniform\", data) print(result) #>     method   estimate standard_error  ci_lower  ci_upper   p_value BF #> 1 puniform 0.03038879             NA -2.250357 0.3192963 0.4631793 NA #>   convergence note  version tau_estimate tau_ci_lower tau_ci_upper tau_p_value #> 1        TRUE   NA original           NA           NA           NA          NA #>   bias_p_value method_setting #> 1    0.1467798        default"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.trimfill.html","id":null,"dir":"Reference","previous_headings":"","what":"Trim-and-Fill Meta-Analysis Method — method.trimfill","title":"Trim-and-Fill Meta-Analysis Method — method.trimfill","text":"Implements trim--fill method adjusting publication bias meta-analysis using metafor package.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.trimfill.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trim-and-Fill Meta-Analysis Method — method.trimfill","text":"","code":"# S3 method for class 'trimfill' method(method_name, data, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.trimfill.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trim-and-Fill Meta-Analysis Method — method.trimfill","text":"method_name Method name (automatically passed) data Data frame yi (effect sizes) sei (standard errors) settings List method settings (see Details.)","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.trimfill.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trim-and-Fill Meta-Analysis Method — method.trimfill","text":"Data frame trim--fill results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.trimfill.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Trim-and-Fill Meta-Analysis Method — method.trimfill","text":"following settings implemented \"default\" Random effects model fitted Restricted Maximum Likelihood estimator (method = \"REML\") Knapp-Hartung adjustment (test = \"knha\"), followed trim--fill using left-side trimming (side = \"left\") L0 estimator (estimator = \"L0\").","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method.trimfill.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trim-and-Fill Meta-Analysis Method — method.trimfill","text":"","code":"# Generate some example data data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4, 0.25),   sei = c(0.1, 0.15, 0.08, 0.12, 0.09) )  # Apply trimfill method result <- run_method(\"trimfill\", data) print(result) #>     method  estimate standard_error   ci_lower  ci_upper      p_value BF #> 1 trimfill 0.1774672     0.05366124 0.07229309 0.2826413 0.0009424154 NA #>   convergence note tau_estimate tau_ci_lower tau_ci_upper tau_p_value k_missing #> 1        TRUE   NA    0.0877971            0    0.3178726   0.1226888         2 #>   k_missing_se method_setting #> 1     1.602467        default"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method_extra_columns.html","id":null,"dir":"Reference","previous_headings":"","what":"Method Extra Columns — method_extra_columns","title":"Method Extra Columns — method_extra_columns","text":"Retrieves character vector custom columns given method. method-specific columns beyond standard columns (method, estimate, standard_error, ci_lower, ci_upper, p_value, BF, convergence, note) method returns.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method_extra_columns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Method Extra Columns — method_extra_columns","text":"","code":"get_method_extra_columns(method_name)  method_extra_columns(method_name)  # Default S3 method method_extra_columns(method_name)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method_extra_columns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Method Extra Columns — method_extra_columns","text":"method_name Character string method name","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method_extra_columns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Method Extra Columns — method_extra_columns","text":"Character vector extra column names, empty character vector extra columns defined method","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method_extra_columns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Method Extra Columns — method_extra_columns","text":"","code":"# Get extra columns for PET method get_method_extra_columns(\"PET\") #> [1] \"bias_coefficient\" \"bias_p_value\"      # Get extra columns for RMA method get_method_extra_columns(\"RMA\") #> [1] \"tau_estimate\" \"tau_ci_lower\" \"tau_ci_upper\" \"tau_p_value\""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method_settings.html","id":null,"dir":"Reference","previous_headings":"","what":"Return Pre-specified Method Settings — method_settings","title":"Return Pre-specified Method Settings — method_settings","text":"function returns list pre-specified settings given Method","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method_settings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return Pre-specified Method Settings — method_settings","text":"","code":"method_settings(method_name)  get_method_setting(method_name, version_id)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method_settings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return Pre-specified Method Settings — method_settings","text":"method_name Character string specifying method type version_id method version used.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method_settings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return Pre-specified Method Settings — method_settings","text":"list containing pre-specified settings. methods, list contains extension function call, however, elaborate list settings dispatched within method call possible.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/method_settings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return Pre-specified Method Settings — method_settings","text":"","code":"method_settings(\"RMA\") #> $default #> $default$method #> [1] \"REML\" #>  #> $default$test.uni #> [1] \"knha\" #>  #> $default$test.mv #> [1] \"t\" #>  #> $default$control #> $default$control$stepadj #> [1] 0.5 #>  #> $default$control$maxiter #> [1] 500 #>  #>  #>  get_method_setting(\"RMA\", version_id = \"default\") #> $method #> [1] \"REML\" #>  #> $test.uni #> [1] \"knha\" #>  #> $test.mv #> [1] \"t\" #>  #> $control #> $control$stepadj #> [1] 0.5 #>  #> $control$maxiter #> [1] 500 #>  #>"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve a Pre-Simulated Condition and Repetition From a DGM — retrieve_dgm_dataset","title":"Retrieve a Pre-Simulated Condition and Repetition From a DGM — retrieve_dgm_dataset","text":"function returns pre-simulated dataset given repetition condition dgm. pre-simulated datasets must already stored locally. See download_dgm_datasets() function guidance.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve a Pre-Simulated Condition and Repetition From a DGM — retrieve_dgm_dataset","text":"","code":"retrieve_dgm_dataset(dgm_name, condition_id, repetition_id = NULL, path = NULL)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve a Pre-Simulated Condition and Repetition From a DGM — retrieve_dgm_dataset","text":"dgm_name Character string specifying DGM type condition_id conditions settings returned . repetition_id repetition returned. complete condition can returned setting either NULL. path Character string specifying directory path datasets/results/measures saved. Defaults location specified via PublicationBiasBenchmark.get_option(\"simulation_directory\"). objects stored dgm_name/datasets, dgm_name/results, dgm_name/measures subfolders.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_dataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve a Pre-Simulated Condition and Repetition From a DGM — retrieve_dgm_dataset","text":"data.frame","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_dataset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve a Pre-Simulated Condition and Repetition From a DGM — retrieve_dgm_dataset","text":"","code":"if (FALSE) { # \\dontrun{   # get condition 1, repetition 1   retrieve_dgm_dataset(\"no_bias\", condition_id = 1, repetition_id = 1)    # get condition 1, all repetitions   retrieve_dgm_dataset(\"no_bias\", condition_id = 1) } # }"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_measures.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Pre-Computed Performance measures for a DGM — retrieve_dgm_measures","title":"Retrieve Pre-Computed Performance measures for a DGM — retrieve_dgm_measures","text":"function returns pre-computed performance measures specified Data-Generating Mechanism (DGM). pre-computed measures must already stored locally. See download_dgm_measures() function guidance.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_measures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Pre-Computed Performance measures for a DGM — retrieve_dgm_measures","text":"","code":"retrieve_dgm_measures(   dgm_name,   measure = NULL,   method = NULL,   condition_id = NULL,   path = NULL,   replacement = FALSE )"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_measures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Pre-Computed Performance measures for a DGM — retrieve_dgm_measures","text":"dgm_name Character string specifying DGM type measure performance measure returned (e.g., \"bias\", \"mse\", \"coverage\"). measures can returned setting NULL. method method returned. methods can returned setting NULL. condition_id conditions settings returned . path Character string specifying directory path datasets/results/measures saved. Defaults location specified via PublicationBiasBenchmark.get_option(\"simulation_directory\"). objects stored dgm_name/datasets, dgm_name/results, dgm_name/measures subfolders. replacement Whether performance measures computed using replacement returned. Defaults FALSE.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_measures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Pre-Computed Performance measures for a DGM — retrieve_dgm_measures","text":"data.frame","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_measures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve Pre-Computed Performance measures for a DGM — retrieve_dgm_measures","text":"","code":"if (FALSE) { # \\dontrun{   # get bias measures for all methods and conditions   retrieve_dgm_measures(\"no_bias\", measure = \"bias\")    # get all measures for RMA method   retrieve_dgm_measures(\"no_bias\", method = \"RMA\")    # get MSE measures for PET method in condition 1   retrieve_dgm_measures(\"no_bias\", measure = \"mse\", method = \"PET\", condition_id = 1) } # }"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve a Pre-Computed Results of a Method Applied to DGM — retrieve_dgm_results","title":"Retrieve a Pre-Computed Results of a Method Applied to DGM — retrieve_dgm_results","text":"function returns pre-computed results given method specific repetition condition dgm. pre-computed results must already stored locally. See download_dgm_results() function guidance.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve a Pre-Computed Results of a Method Applied to DGM — retrieve_dgm_results","text":"","code":"retrieve_dgm_results(   dgm_name,   method = NULL,   method_setting = \"default\",   condition_id = NULL,   repetition_id = NULL,   path = NULL )"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve a Pre-Computed Results of a Method Applied to DGM — retrieve_dgm_results","text":"dgm_name Character string specifying DGM type method method returned. complete results can returned setting NULL. method_setting method setting returned. Defaults \"default\". condition_id conditions settings returned . repetition_id repetition returned. complete condition can returned setting either NULL. path Character string specifying directory path datasets/results/measures saved. Defaults location specified via PublicationBiasBenchmark.get_option(\"simulation_directory\"). objects stored dgm_name/datasets, dgm_name/results, dgm_name/measures subfolders.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve a Pre-Computed Results of a Method Applied to DGM — retrieve_dgm_results","text":"data.frame","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/retrieve_dgm_results.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve a Pre-Computed Results of a Method Applied to DGM — retrieve_dgm_results","text":"","code":"if (FALSE) { # \\dontrun{   # get condition 1, repetition 1 for default method setting   retrieve_dgm_results(\"no_bias\", condition_id = 1, repetition_id = 1)    # get condition 1, all repetitions for default method setting   retrieve_dgm_results(\"no_bias\", condition_id = 1) } # }"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/run_method.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic method function for publication bias correction — run_method","title":"Generic method function for publication bias correction — run_method","text":"function provides unified interface various publication bias correction methods. specific method determined first argument. See vignette(\"Adding_New_Methods\", package = \"PublicationBiasBenchmark\") details extending package new methods","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/run_method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic method function for publication bias correction — run_method","text":"","code":"run_method(method_name, data, settings = NULL)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/run_method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic method function for publication bias correction — run_method","text":"method_name Character string specifying method type data Data frame containing yi (effect sizes) sei (standard errors) settings Either character identifying method version list containing method-specific settings. emty input result running default (first implemented) version method.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/run_method.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generic method function for publication bias correction — run_method","text":"data frame standardized method results","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/run_method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generic method function for publication bias correction — run_method","text":"","code":"# Example usage with PET method data <- data.frame(   yi = c(0.2, 0.3, 0.1, 0.4),   sei = c(0.1, 0.15, 0.08, 0.12) ) result <- run_method(\"RMA\", data, \"default\")  # Example usage with PETPEESE method # result <- method(\"PETPEESE\", data)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/simulate_dgm.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate From Data-Generating Mechanism — simulate_dgm","title":"Simulate From Data-Generating Mechanism — simulate_dgm","text":"function provides unified interface various data-generating mechanisms simulation studies. specific DGM determined first argument. See vignette(\"Adding_New_DGMs\", package = \"PublicationBiasBenchmark\") details extending package new DGMs.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/simulate_dgm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate From Data-Generating Mechanism — simulate_dgm","text":"","code":"simulate_dgm(dgm_name, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/simulate_dgm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate From Data-Generating Mechanism — simulate_dgm","text":"dgm_name Character string specifying DGM type settings List containing required parameters DGM numeric condition_id","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/simulate_dgm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate From Data-Generating Mechanism — simulate_dgm","text":"data frame containing generated data standardized structure","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/simulate_dgm.html","id":"output-structure","dir":"Reference","previous_headings":"","what":"Output Structure","title":"Simulate From Data-Generating Mechanism — simulate_dgm","text":"returned data frame follows standardized schema downstream functions rely . Across currently implemented DGMs, following columns used: yi (numeric): effect size estimate. sei (numeric): Standard error yi. ni (integer): Total sample size estimate (e.g., sum groups applicable). es_type (character): Effect size type, used disambiguate scale yi. Currently used values \"SMD\" (standardized mean difference / Cohen's d), \"logOR\" (log odds ratio), \"none\" (unspecified generic continuous coefficient). study_id (integer/character, optional): Identifier primary study/cluster DGM yields multiple estimates per study (e.g., Alinaghi2018, PRE). absent, row treated independent study.","code":""},{"path":[]},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/simulate_dgm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate From Data-Generating Mechanism — simulate_dgm","text":"","code":"simulate_dgm(\"Carter2019\", 1) #>              yi        sei  ni es_type #> 1  -0.027406349 0.28285599  50     SMD #> 2  -0.096607006 0.07837172 652     SMD #> 3   0.016303565 0.25400447  62     SMD #> 4   0.002914326 0.14990642 178     SMD #> 5  -0.199668025 0.50124431  16     SMD #> 6   0.169618220 0.20888902  92     SMD #> 7  -0.403814247 0.45174844  20     SMD #> 8   0.250896476 0.27843914  52     SMD #> 9  -0.152818816 0.47209208  18     SMD #> 10  0.361928439 0.22543004  80     SMD  simulate_dgm(\"Carter2019\", list(mean_effect = 0, effect_heterogeneity = 0,                        bias = \"high\", QRP = \"high\", n_studies = 10)) #>           yi       sei  ni es_type #> 1  0.7838699 0.3281473  40     SMD #> 2  0.6203106 0.2961379  48     SMD #> 3  0.4809701 0.1971873 106     SMD #> 4  0.1201830 0.1645514 148     SMD #> 5  0.7183940 0.3273348  40     SMD #> 6  0.6595228 0.2853888  52     SMD #> 7  0.2868821 0.1319919 232     SMD #> 8  0.2173063 0.1052860 363     SMD #> 9  1.0274545 0.2855963  56     SMD #> 10 0.2882129 0.1368006 216     SMD  simulate_dgm(\"Alinaghi2018\", list(environment = \"FE\", mean_effect = 0,                        bias = \"positive\")) #>                yi        sei  ni study_id es_type #> 1    0.6673651443 3.54597081 100        1    none #> 2    0.1622042641 0.08463464 100        3    none #> 3    0.2660201468 0.14673895 100        5    none #> 4    0.6419042819 1.93442798 100        6    none #> 5    3.4631090299 3.08032800 100        7    none #> 6    2.6326859584 1.32749695 100       10    none #> 7    0.2791164217 0.56006193 100       11    none #> 8    0.0227364684 0.25764652 100       12    none #> 9    0.3202450566 2.50476522 100       13    none #> 10   0.0575689425 1.19594413 100       14    none #> 11   1.0830224215 1.82968912 100       18    none #> 12   5.1756936228 2.59027142 100       21    none #> 13   2.2248853806 1.83414371 100       23    none #> 14   0.1952145325 0.40816960 100       25    none #> 15   0.4584049916 1.29203049 100       26    none #> 16   1.1817420060 1.01854178 100       27    none #> 17   0.1215528210 0.24984615 100       28    none #> 18   1.6146988506 2.21364932 100       30    none #> 19  -1.1401693687 0.68643379 100       32    none #> 20   0.0070117236 0.13206920 100       33    none #> 21   3.1293513230 1.52186612 100       36    none #> 22   0.9670093465 1.87418491 100       41    none #> 23   2.0946455161 2.61526881 100       42    none #> 24   0.0810872642 0.25080256 100       43    none #> 25  -3.0857351751 1.93991731 100       44    none #> 26   1.8255534804 1.26413528 100       47    none #> 27   2.6673008567 2.27055806 100       49    none #> 28   0.4641090528 1.99111057 100       52    none #> 29   0.1735317852 0.50337945 100       53    none #> 30   3.5115197426 2.31998351 100       54    none #> 31  -1.3092334701 1.75258233 100       56    none #> 32  -0.5535636839 1.06689220 100       57    none #> 33   0.1704049678 0.28659481 100       60    none #> 34   0.6387828606 2.15251037 100       61    none #> 35  -0.1220359612 0.12949971 100       62    none #> 36   0.1423085635 0.28132706 100       64    none #> 37   1.5795949702 0.70083256 100       65    none #> 38   1.3741015880 2.23607783 100       68    none #> 39   1.2570039637 0.94127555 100       69    none #> 40   2.4911855665 2.10951158 100       72    none #> 41   0.0676049451 0.25217333 100       77    none #> 42   0.2047983887 0.15109037 100       80    none #> 43   2.8339785713 2.78188282 100       82    none #> 44   2.2741978057 1.03988018 100       83    none #> 45   2.4601247575 3.12304566 100       85    none #> 46   1.7857384274 1.58285655 100       86    none #> 47   2.2869649533 2.50892131 100       87    none #> 48   0.6028442392 2.74628957 100       88    none #> 49  -2.2975300988 2.99957888 100       89    none #> 50   0.8268032813 2.86995115 100       90    none #> 51   1.9183303492 2.13256056 100       91    none #> 52   0.6077731111 1.51992530 100       92    none #> 53   1.8721408007 2.11171385 100       93    none #> 54   0.8141265122 1.71401550 100       94    none #> 55   1.5932824511 2.17308635 100       95    none #> 56   0.5021494112 1.54617529 100       96    none #> 57   0.4878730572 0.56375878 100       98    none #> 58   1.1494067258 1.79655160 100      103    none #> 59   2.0372102456 2.34209492 100      104    none #> 60   3.7833378628 2.19419267 100      105    none #> 61   0.4725689308 0.32557139 100      109    none #> 62   1.2025932108 1.98904773 100      110    none #> 63  -0.8265697084 3.13034105 100      111    none #> 64   3.1470262056 2.87896388 100      112    none #> 65   0.5702160373 2.61825593 100      113    none #> 66   2.6282806228 1.85179399 100      115    none #> 67   1.4758050000 0.91276870 100      116    none #> 68   1.7089565331 1.50758446 100      118    none #> 69   0.2467130380 0.91831423 100      120    none #> 70   0.9863196379 1.05261488 100      121    none #> 71   0.8402908386 1.13112947 100      124    none #> 72   0.3101915857 1.94430170 100      125    none #> 73   4.4440914492 2.11429606 100      128    none #> 74   2.2502369877 1.66030417 100      130    none #> 75   1.5696856621 0.98136738 100      131    none #> 76   2.3026958776 2.84712557 100      132    none #> 77  -0.3863002599 1.43717172 100      133    none #> 78   0.4908222405 0.45422784 100      135    none #> 79   1.2719733719 2.25872862 100      136    none #> 80  -2.1433168739 1.72029097 100      138    none #> 81   0.4339303848 2.65619993 100      139    none #> 82   2.3771501819 2.11979640 100      142    none #> 83   1.6143518581 0.83473259 100      144    none #> 84   0.0072477119 0.39052654 100      145    none #> 85   4.8407461209 1.75296386 100      146    none #> 86   5.2063919969 2.43744009 100      148    none #> 87   0.2213821211 0.26214086 100      149    none #> 88   5.4655314125 2.99499195 100      151    none #> 89   2.0187324727 1.78029151 100      153    none #> 90   1.2574994678 1.13492686 100      154    none #> 91   3.0371645970 2.14437023 100      156    none #> 92  -0.0015816612 3.04489460 100      157    none #> 93   0.7866364526 0.80896730 100      158    none #> 94   0.0114709181 1.26463864 100      159    none #> 95   0.9691510973 1.79580046 100      160    none #> 96   0.6738452442 1.52157259 100      164    none #> 97  -6.4249671703 3.16169927 100      166    none #> 98   3.2277173073 1.96798606 100      168    none #> 99   1.1396969082 0.47897317 100      171    none #> 100  3.9450713774 3.53089735 100      173    none #> 101  1.8879900922 1.89805404 100      174    none #> 102  0.8221049923 2.85871872 100      179    none #> 103  4.2959389225 1.66373881 100      184    none #> 104  0.2684119714 0.88789759 100      186    none #> 105  0.3062505713 1.34176335 100      188    none #> 106  1.9744465506 2.98851289 100      189    none #> 107  0.0175246282 0.35981004 100      190    none #> 108  0.1131327358 2.22075248 100      192    none #> 109  1.3890877033 0.65463156 100      193    none #> 110  0.0476463032 0.14925833 100      195    none #> 111 -0.5828872506 0.98176125 100      196    none #> 112 -2.2151680944 2.70614575 100      197    none #> 113  0.8364932089 0.88356613 100      198    none #> 114  0.7501095280 2.07213704 100      201    none #> 115  3.7854854129 2.49784739 100      202    none #> 116  2.6076600472 2.31526900 100      203    none #> 117  0.8856545500 1.89464472 100      209    none #> 118 -0.0519641383 1.33135225 100      212    none #> 119  6.8480034432 1.80019021 100      213    none #> 120  0.0741473203 2.23886018 100      214    none #> 121  0.1483421164 1.62358048 100      215    none #> 122  0.0052714918 0.03588477 100      220    none #> 123  0.9219949477 0.48642417 100      225    none #> 124  1.3731876561 2.15771719 100      226    none #> 125  1.1743281826 2.58480161 100      228    none #> 126  1.7084151428 2.58530908 100      229    none #> 127  1.6665708305 2.05032415 100      231    none #> 128  2.5132287118 2.11756682 100      234    none #> 129  1.8902093394 2.21739115 100      235    none #> 130  3.8389565502 2.05366722 100      236    none #> 131  0.1034071018 0.42844420 100      240    none #> 132  0.9810004661 1.25266356 100      241    none #> 133  0.9177488423 2.53780526 100      243    none #> 134  0.7316123360 1.71677153 100      247    none #> 135  0.1853413241 2.23869996 100      251    none #> 136  1.2850400985 1.23506745 100      252    none #> 137  0.4539832625 1.33245014 100      253    none #> 138  0.1605780389 0.19914608 100      256    none #> 139  1.0945130271 0.63198053 100      257    none #> 140  0.1573751295 1.76606125 100      260    none #> 141  1.7708405733 0.86124605 100      261    none #> 142  4.2518034808 3.06372249 100      265    none #> 143  1.0025209680 1.81573430 100      266    none #> 144  0.9197986068 0.82897765 100      268    none #> 145  0.4562560825 1.24091343 100      269    none #> 146  2.3916115148 3.04396300 100      270    none #> 147  2.3017662352 2.80757178 100      273    none #> 148  0.0004578026 0.17165017 100      276    none #> 149  2.3043948202 2.30975875 100      277    none #> 150  0.0312321702 0.66830913 100      278    none #> 151  0.0721558805 0.27130203 100      282    none #> 152 -0.5023763590 0.61711295 100      284    none #> 153  0.0007606392 2.56055645 100      285    none #> 154  1.4964585485 2.57301154 100      286    none #> 155  1.4044512945 1.02569640 100      287    none #> 156  1.2435985146 2.73660661 100      289    none #> 157  0.1023495394 0.45768346 100      290    none #> 158  1.2177939047 2.36407751 100      291    none #> 159  0.8544145229 0.77810183 100      294    none #> 160  1.8791356750 2.54851629 100      295    none #> 161  0.0085101890 1.98563247 100      296    none #> 162 -0.0953263617 1.27566978 100      297    none #> 163  0.0611270528 0.16199074 100      298    none #> 164  1.2382332583 2.84687869 100      299    none #> 165  0.2197467129 0.63106549 100      300    none #> 166  1.7061076588 2.38312974 100      305    none #> 167  3.0450466638 2.41016677 100      307    none #> 168  0.8100141789 2.40492479 100      308    none #> 169  3.1103814194 2.46307583 100      309    none #> 170  2.7704116760 2.26479913 100      310    none #> 171  1.1511164936 0.69291455 100      312    none #> 172 -0.3675184098 0.10995027 100      314    none #> 173  0.1515103620 0.62017443 100      315    none #> 174  0.1017226711 0.09816821 100      318    none #> 175  2.1823115244 3.18859631 100      319    none #> 176  0.9872825003 1.21029256 100      321    none #> 177 -0.4462631910 0.51422664 100      323    none #> 178  3.2207702730 1.99979858 100      328    none #> 179  2.0856969773 3.47299372 100      329    none #> 180  0.5946776489 0.55651037 100      330    none #> 181  0.6341647605 1.10112374 100      331    none #> 182 -0.3267719060 1.81084139 100      332    none #> 183  0.4885130169 0.89630741 100      333    none #> 184  0.0493816217 0.99561426 100      335    none #> 185  2.0852143293 3.07790682 100      336    none #> 186 -0.3597166401 0.54295476 100      337    none #> 187  1.7272844391 3.01528228 100      340    none #> 188  3.0616550337 2.74234083 100      341    none #> 189  1.1142641212 1.63707326 100      343    none #> 190  1.4995404016 1.29102802 100      345    none #> 191  1.4681672283 1.91073490 100      350    none #> 192  0.0150660575 1.32846174 100      351    none #> 193 -0.8221561533 0.70947644 100      352    none #> 194  6.8023938709 3.73743820 100      354    none #> 195  0.3303756110 1.40815848 100      355    none #> 196  0.6562477422 3.12077833 100      358    none #> 197 -1.3753635698 2.31837097 100      360    none #> 198  0.0638486353 0.07433389 100      361    none #> 199  1.8409479199 2.69211208 100      362    none #> 200  1.5908138859 1.66856111 100      364    none #> 201  2.8323958755 3.63907808 100      367    none #> 202  1.7355625480 1.76610829 100      368    none #> 203  0.3177106976 1.20470484 100      369    none #> 204  0.1570942265 3.09057836 100      371    none #> 205  1.8121269957 1.14189693 100      375    none #> 206  1.4326914554 2.15991021 100      376    none #> 207 -0.9263397179 2.03164534 100      377    none #> 208  0.0187742260 0.04007185 100      378    none #> 209  1.9909906658 3.01962470 100      380    none #> 210  0.2620952748 0.78505570 100      381    none #> 211  0.0813846482 0.13401925 100      382    none #> 212  0.8877283375 1.06519558 100      383    none #> 213  1.2113094846 2.02588099 100      384    none #> 214  0.4758066501 0.46623542 100      385    none #> 215  0.9246085011 1.06007366 100      386    none #> 216  1.9245094400 1.78995306 100      387    none #> 217  0.6835289669 2.06019276 100      388    none #> 218  1.3669669518 2.38353909 100      389    none #> 219  1.3321417973 1.84498493 100      390    none #> 220  1.1486529972 2.54163408 100      392    none #> 221  2.1913839935 1.46830838 100      393    none #> 222  3.4197227748 2.58435773 100      395    none #> 223  0.3460778451 0.44946547 100      396    none #> 224  0.4350999366 0.27994418 100      398    none #> 225  2.0115209211 3.00790537 100      399    none #> 226  0.2336577526 0.15930366 100      401    none #> 227  2.9911553442 2.69901848 100      402    none #> 228  0.3221175403 2.30574423 100      403    none #> 229  0.2022780668 0.47602054 100      404    none #> 230  0.1505262674 0.17594513 100      405    none #> 231  4.1496156160 2.29716840 100      406    none #> 232  0.6432213017 3.17916103 100      410    none #> 233  0.0174725299 0.05001844 100      412    none #> 234  0.1739283036 2.09087627 100      414    none #> 235  0.8402698429 1.08110642 100      416    none #> 236  0.5306457757 0.42203239 100      417    none #> 237  5.9270645842 2.96733902 100      418    none #> 238  0.9266312894 2.37161784 100      419    none #> 239  0.4325362283 0.28849952 100      424    none #> 240  0.8086549735 0.94857889 100      425    none #> 241  2.3350455501 2.40758725 100      426    none #> 242  1.1708537259 1.16099830 100      430    none #> 243  2.8536211113 2.37990076 100      431    none #> 244  0.0115672560 0.56437443 100      433    none #> 245  0.8070050523 1.10479008 100      435    none #> 246  0.2059759288 0.70258969 100      436    none #> 247  3.4223756823 3.27875104 100      437    none #> 248  0.7911137758 0.66758738 100      439    none #> 249  0.0271288626 0.56303093 100      441    none #> 250  1.2545051981 1.35651286 100      442    none #> 251 -2.8977698854 1.52372082 100      443    none #> 252  1.8234125657 0.93098242 100      451    none #> 253  0.1289158197 2.01496128 100      456    none #> 254  0.1280562852 0.39112683 100      458    none #> 255  0.5710631157 1.71223651 100      459    none #> 256  2.3371173680 2.84335639 100      460    none #> 257  3.1014932946 2.52674847 100      461    none #> 258 -0.5193583204 1.73905906 100      463    none #> 259  1.1127386606 1.65918655 100      464    none #> 260  0.0013671979 0.65613241 100      465    none #> 261  0.5733544088 2.34549935 100      467    none #> 262  0.4339627362 0.48903297 100      468    none #> 263  0.4928574169 0.57493333 100      473    none #> 264  1.2414844317 1.49616858 100      479    none #> 265  3.6246758865 2.43704974 100      480    none #> 266  0.9530610241 3.05031485 100      481    none #> 267  1.5397744301 2.94555909 100      483    none #> 268  1.0952241835 0.91906248 100      488    none #> 269  0.0662134949 0.11706813 100      490    none #> 270  1.0451266403 1.06337970 100      491    none #> 271  1.6196972360 1.64823479 100      492    none #> 272  0.4991846295 2.44902777 100      496    none #> 273  1.5073662598 2.20109694 100      498    none #> 274  2.8994214597 2.83522952 100      501    none #> 275  1.5815336305 2.16353785 100      502    none #> 276  0.3147555509 0.18454810 100      504    none #> 277  0.3264962495 0.16398031 100      505    none #> 278  0.1531527764 0.95775183 100      508    none #> 279  0.2543808216 0.83956989 100      510    none #> 280  2.3908283729 2.19617689 100      511    none #> 281  3.0390173961 1.67079658 100      515    none #> 282  0.8802173505 1.63240727 100      517    none #> 283  0.3688581173 3.34226731 100      519    none #> 284 -0.8109959155 1.48848116 100      525    none #> 285  2.7214031614 1.29631230 100      529    none #> 286  0.9704987971 1.66807695 100      531    none #> 287  0.0396423495 0.05713836 100      532    none #> 288  3.7759843744 2.48712424 100      533    none #> 289  2.4269910149 1.29247535 100      535    none #> 290  3.2945350016 2.73314294 100      536    none #> 291  1.7609300231 2.03936930 100      537    none #> 292  2.4603340938 2.76947264 100      538    none #> 293  0.5462815462 1.98157446 100      540    none #> 294  0.6555314053 0.73995781 100      541    none #> 295  4.5008094619 2.56014536 100      544    none #> 296  1.2779170859 1.57299436 100      546    none #> 297 -0.9351370439 0.84245753 100      547    none #> 298  2.3307561313 2.26015963 100      548    none #> 299  1.4796017059 2.27599065 100      549    none #> 300  0.9486616622 0.58377145 100      550    none #> 301  1.0263312166 2.75307666 100      551    none #> 302  0.6212353323 0.26874273 100      552    none #> 303  1.6888998140 1.38993421 100      553    none #> 304  0.7228818152 2.27202188 100      554    none #> 305  0.8521024187 2.88940548 100      557    none #> 306  0.2002813910 0.35850461 100      560    none #> 307  1.3465787218 2.13872136 100      562    none #> 308  0.4025858885 2.71309926 100      563    none #> 309  0.1341137141 2.63926125 100      564    none #> 310  2.4288818381 1.69553319 100      565    none #> 311  1.9228277278 1.72215611 100      566    none #> 312  0.1906810678 2.17859664 100      567    none #> 313  1.9380088035 2.39223099 100      569    none #> 314  6.3868271663 2.87333195 100      570    none #> 315  0.0317696809 0.71351582 100      572    none #> 316  0.0472550783 0.53155990 100      573    none #> 317  0.5675676220 2.11286621 100      575    none #> 318  0.0548249966 0.05459939 100      576    none #> 319  2.4004885006 2.54869179 100      577    none #> 320 -0.7185041822 2.74581272 100      579    none #> 321  0.8890606669 0.83033545 100      582    none #> 322  0.3726175524 1.31765576 100      586    none #> 323 -2.3020711024 2.92707470 100      588    none #> 324  0.0227985790 0.04170190 100      589    none #> 325  0.6054706890 0.42856667 100      590    none #> 326  0.3971014998 2.77639809 100      592    none #> 327  0.6253428466 3.11668071 100      593    none #> 328  0.8149750800 1.68817476 100      594    none #> 329 -2.9844910668 1.96242708 100      597    none #> 330  2.4230292699 1.31259507 100      598    none #> 331  0.0610190549 1.17952930 100      600    none #> 332  0.0856342974 0.35898751 100      601    none #> 333  1.8959215700 2.18508424 100      603    none #> 334  1.6664289554 0.95614119 100      604    none #> 335  1.0623139494 2.04320500 100      606    none #> 336  0.1088293260 0.18168234 100      607    none #> 337  0.4505463262 0.34982722 100      608    none #> 338  0.8512516358 0.92703962 100      609    none #> 339  0.6435767725 0.69873904 100      611    none #> 340  0.2386732919 0.65688168 100      612    none #> 341  0.9946099475 1.43861989 100      614    none #> 342 -0.3480485370 1.50316214 100      615    none #> 343  0.2501586475 0.51642138 100      618    none #> 344  0.0236980197 1.69016853 100      619    none #> 345  0.0657530694 1.11774126 100      621    none #> 346  1.5942667252 0.92753737 100      622    none #> 347 -0.0165058890 0.44304506 100      624    none #> 348  0.0947350409 0.79818448 100      626    none #> 349  0.6439511965 0.78660917 100      627    none #> 350  0.5192772589 0.55392640 100      628    none #> 351  0.2682461686 1.13771150 100      630    none #> 352  4.5510381373 2.99575523 100      633    none #> 353  0.3081451105 0.29629244 100      634    none #> 354  1.3748529401 1.88419353 100      636    none #> 355  0.4437588206 0.40217874 100      638    none #> 356  4.7191410585 2.29001375 100      639    none #> 357  1.3998955107 2.06313257 100      640    none #> 358  3.1378248035 2.07650253 100      641    none #> 359  0.4048937431 0.35748333 100      645    none #> 360  0.0017556683 1.42836430 100      646    none #> 361  1.6384175102 0.88110652 100      648    none #> 362  1.3690261338 2.65532268 100      649    none #> 363  0.0340436733 2.71161606 100      650    none #> 364  0.9852947754 1.38510736 100      651    none #> 365 -4.6967132621 2.77884002 100      652    none #> 366  1.7069751322 1.47292790 100      655    none #> 367  0.4676871199 1.91949921 100      656    none #> 368 -1.7284002632 1.52454189 100      657    none #> 369  3.5687264477 2.01232415 100      658    none #> 370  0.2445441376 1.12798456 100      660    none #> 371  0.0362407178 0.67186439 100      662    none #> 372  3.5837164028 2.12030021 100      663    none #> 373  0.9662229927 2.81631405 100      665    none #> 374  0.3134613886 0.40724779 100      668    none #> 375  1.1981439332 1.03338168 100      669    none #> 376  1.4825499050 1.81645789 100      671    none #> 377  0.1171707229 2.22782417 100      672    none #> 378  0.9198607908 1.73244768 100      676    none #> 379  0.9355065557 0.77091623 100      678    none #> 380  2.1618003419 1.55834722 100      680    none #> 381  0.3932066082 0.67800786 100      681    none #> 382  1.4147291394 1.69141274 100      682    none #> 383  3.7885690773 1.78661395 100      683    none #> 384  1.5327246284 2.49893431 100      686    none #> 385  0.3290847053 1.51799184 100      687    none #> 386  1.5526211569 1.30704007 100      689    none #> 387 -0.1675704331 3.03678926 100      690    none #> 388  0.1742025359 2.74330022 100      691    none #> 389  5.2142418168 2.37282070 100      694    none #> 390  0.7975611245 1.53379022 100      696    none #> 391  3.9909940122 2.35525722 100      697    none #> 392  0.8472414412 2.32974081 100      699    none #> 393  3.1904484390 3.17535397 100      700    none #> 394  2.9887186947 2.38162724 100      701    none #> 395  2.5117594008 1.66599794 100      703    none #> 396  0.5076953388 1.84930828 100      704    none #> 397  0.4021389467 0.60598921 100      706    none #> 398  1.7569728200 1.72887614 100      708    none #> 399  0.8690009176 1.89332521 100      709    none #> 400  1.7157337953 1.00812856 100      711    none #> 401  1.5080628265 2.06393074 100      716    none #> 402  2.9248659075 1.68951370 100      717    none #> 403  0.5153886917 1.76761259 100      718    none #> 404  0.2284486937 0.55201287 100      720    none #> 405  2.0269406677 2.00476735 100      721    none #> 406  0.0473514278 0.19202448 100      724    none #> 407  0.8090755561 1.21881469 100      727    none #> 408  0.3629824660 0.72003017 100      728    none #> 409  0.1051426652 0.17831415 100      731    none #> 410  0.2218918454 1.30417661 100      733    none #> 411  0.3346517577 1.00263886 100      734    none #> 412  0.2023640231 0.25329435 100      738    none #> 413  0.2588964126 0.50014918 100      739    none #> 414  1.0391997947 1.47866165 100      740    none #> 415  0.0077506231 0.55853297 100      742    none #> 416  1.1893770147 1.72197225 100      743    none #> 417  0.0313252995 1.31497883 100      746    none #> 418  0.0613364815 1.55882445 100      748    none #> 419  0.2688734759 0.59866005 100      749    none #> 420 -2.0300838346 1.37612775 100      750    none #> 421  1.8563715370 1.26205860 100      751    none #> 422  1.0577566253 0.72391766 100      752    none #> 423  1.9385417989 2.24462535 100      753    none #> 424  0.6303297488 2.22886866 100      755    none #> 425  1.5784972080 1.10101633 100      758    none #> 426 -0.8438838022 2.17130495 100      761    none #> 427 -1.2050817773 2.92842957 100      762    none #> 428  2.5232433102 1.83711576 100      766    none #> 429  0.8335551806 0.81558724 100      768    none #> 430 -2.1381632597 2.79069832 100      769    none #> 431  1.6425902390 2.41077712 100      771    none #> 432  1.5746357078 0.62220290 100      772    none #> 433  3.9835086594 2.12991528 100      774    none #> 434  3.2617355275 3.89831503 100      778    none #> 435  0.4917110921 0.60260973 100      780    none #> 436  1.7361247835 2.78169451 100      781    none #> 437  2.7674535943 2.70647555 100      782    none #> 438  0.3219549409 0.68658841 100      785    none #> 439  0.0253846150 1.04737294 100      786    none #> 440  0.1366855104 0.13895440 100      787    none #> 441  0.2181921423 0.25692016 100      788    none #> 442 -3.1804867071 2.49878970 100      789    none #> 443 -0.5367996858 0.85135026 100      791    none #> 444  0.2184852717 0.83987653 100      796    none #> 445  0.4649602565 2.60671983 100      798    none #> 446  1.4756647214 1.91674384 100      799    none #> 447  1.3978077809 1.40240958 100      800    none #> 448 -2.8919987914 2.15252198 100      803    none #> 449  0.7775121597 2.26473972 100      804    none #> 450  0.9023505683 1.71505814 100      806    none #> 451  0.1489089101 0.89189550 100      809    none #> 452  0.2033439073 0.26768681 100      811    none #> 453  0.0346904841 0.07725942 100      812    none #> 454  0.5461501277 1.89070600 100      815    none #> 455  0.9592363215 0.99098931 100      817    none #> 456  1.2265930851 1.79190848 100      819    none #> 457  2.2295246034 2.07189671 100      820    none #> 458  0.4367507765 1.22021667 100      822    none #> 459  0.9804043758 1.89542876 100      823    none #> 460  1.3323836636 2.46568546 100      824    none #> 461  0.6562463739 2.82456324 100      825    none #> 462  1.9872650333 1.39535698 100      829    none #> 463  0.4595688163 0.47867153 100      831    none #> 464  1.2040396370 1.59408523 100      835    none #> 465  2.6077495213 2.22114727 100      837    none #> 466  0.3822879280 1.49998473 100      839    none #> 467  0.8859982110 2.37419124 100      842    none #> 468  2.2159465300 2.49597235 100      843    none #> 469  1.0237928866 0.97223914 100      845    none #> 470  0.9491195320 2.28261046 100      847    none #> 471  0.1578053449 0.46780659 100      848    none #> 472  0.5977359049 0.57215617 100      849    none #> 473  1.9264566838 1.25183598 100      852    none #> 474  0.0161653183 0.02140587 100      853    none #> 475  2.2126994936 1.63770952 100      854    none #> 476  2.2003566708 2.40960414 100      855    none #> 477 -1.4578076783 1.44962150 100      856    none #> 478 -0.4171076459 0.40096684 100      860    none #> 479  0.6023487914 0.61780366 100      864    none #> 480 -0.2699279148 0.29951092 100      869    none #> 481  0.5060489092 2.07276190 100      871    none #> 482  0.5239950932 2.66344283 100      874    none #> 483  3.5916279543 2.99656753 100      875    none #> 484  2.1392114521 2.65598024 100      879    none #> 485  0.2080740541 2.96363271 100      883    none #> 486  0.0241255326 1.83870718 100      885    none #> 487  1.1112458207 2.70252728 100      886    none #> 488  5.1105749947 2.67083372 100      888    none #> 489  0.2411829366 0.42351675 100      890    none #> 490  2.4750261661 1.98675267 100      892    none #> 491  0.1334895164 0.33064191 100      895    none #> 492  3.4291435156 2.15515225 100      896    none #> 493  0.2265401355 0.84480640 100      898    none #> 494  0.4193175048 0.50767875 100      899    none #> 495  0.1934383019 2.11736213 100      900    none #> 496  0.4249126912 2.50531084 100      901    none #> 497  0.1645273350 0.71205338 100      902    none #> 498  0.1951101641 1.84260496 100      903    none #> 499  0.2308698441 0.71532361 100      904    none #> 500  0.5434408354 0.37369015 100      906    none #> 501  0.4123077968 1.33500563 100      908    none #> 502  1.5291112822 0.95042998 100      910    none #> 503  0.9278400340 1.22486386 100      912    none #> 504  1.3911832503 0.52730408 100      913    none #> 505 -0.1055748334 0.65142801 100      915    none #> 506  1.9942175616 2.44200775 100      918    none #> 507  1.8484169088 1.18437064 100      920    none #> 508  0.4736232175 1.19785634 100      921    none #> 509  1.3702199664 2.96279715 100      923    none #> 510  0.0205074890 2.20043181 100      924    none #> 511  1.3300803645 2.56594490 100      926    none #> 512  0.4466011572 0.42785518 100      928    none #> 513  0.0180095031 2.31903473 100      931    none #> 514  0.5711740236 0.43049929 100      932    none #> 515  3.5397794745 2.50010798 100      933    none #> 516  2.0991891854 1.76872643 100      934    none #> 517  0.4840657522 0.49164527 100      936    none #> 518  0.4758889006 2.64116528 100      937    none #> 519  0.2183787541 0.62603070 100      938    none #> 520  2.0263067102 2.32768614 100      943    none #> 521  2.8176223580 2.88902041 100      944    none #> 522 -2.3867282118 2.31916135 100      945    none #> 523  0.1211148179 0.12739558 100      946    none #> 524  0.1836603514 0.56457566 100      947    none #> 525  1.5771233673 2.27970221 100      949    none #> 526  0.8779773620 2.13787934 100      953    none #> 527  1.2402226613 2.13692489 100      954    none #> 528 -2.2728274364 1.69891286 100      960    none #> 529  0.9663971303 2.34894606 100      962    none #> 530 -3.2146736067 2.11443518 100      965    none #> 531  0.1098470550 0.34541858 100      966    none #> 532  0.5169111220 0.47469169 100      969    none #> 533  0.1759071411 1.16919728 100      970    none #> 534 -2.9290088306 2.81626720 100      971    none #> 535  0.4963203146 0.25707874 100      973    none #> 536  0.3283727453 0.23714500 100      974    none #> 537  0.9793890509 2.50138144 100      975    none #> 538 -0.1165815506 0.37162458 100      976    none #> 539  0.9502734175 2.63355838 100      977    none #> 540  0.8311260419 0.64423445 100      979    none #> 541  1.3123121965 1.62433805 100      980    none #> 542  0.2290885536 0.70919185 100      982    none #> 543  2.3267822171 1.48286666 100      984    none #> 544  0.8148086208 2.43753825 100      986    none #> 545  0.5384360898 0.73520956 100      988    none #> 546 -0.4049768285 0.42701135 100      990    none #> 547  0.1118684845 1.84274670 100      991    none #> 548  1.5374554086 2.22910403 100      992    none #> 549  0.1823494167 1.39720249 100      994    none #> 550  1.0974132647 1.17040096 100      995    none #> 551  0.0296447668 0.38749650 100      997    none #> 552  0.1451068112 3.12289194 100     1000    none  simulate_dgm(\"Stanley2017\", list(environment = \"Cohens_d\", mean_effect = 0,                         effect_heterogeneity = 0, bias = 0, n_studies = 5,                         sample_sizes = c(32,64,125,250,500))) #>            yi        sei   ni es_type #> 1 -0.16937911 0.25044787   64     SMD #> 2  0.18199857 0.17714228  128     SMD #> 3  0.13930184 0.12664442  250     SMD #> 4  0.07431804 0.08947359  500     SMD #> 5 -0.03431257 0.06325021 1000     SMD"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/validate_dgm_setting.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate DGM Settings — validate_dgm_setting","title":"Validate DGM Settings — validate_dgm_setting","text":"function validates settings provided given Data Generating Mechanism (DGM).","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/validate_dgm_setting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate DGM Settings — validate_dgm_setting","text":"","code":"validate_dgm_setting(dgm_name, settings)"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/validate_dgm_setting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate DGM Settings — validate_dgm_setting","text":"dgm_name Character string specifying DGM type settings List containing required parameters DGM numeric condition_id","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/validate_dgm_setting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate DGM Settings — validate_dgm_setting","text":"Error TRUE depending whether settings valid specified DGM.","code":""},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/reference/validate_dgm_setting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate DGM Settings — validate_dgm_setting","text":"","code":"validate_dgm_setting(\"Carter2019\", list(mean_effect = 0,                         effect_heterogeneity = 0, bias = \"high\",                         QRP = \"high\", n_studies = 10))  validate_dgm_setting(\"Alinaghi2018\", list(environment = \"FE\",                         mean_effect = 0, bias = \"positive\"))  validate_dgm_setting(\"Stanley2017\", list(environment = \"Cohens_d\",                         mean_effect = 0,                         effect_heterogeneity = 0, bias = 0, n_studies = 5,                         sample_sizes = c(32,64,125,250,500)))"},{"path":"https://fbartos.github.io/PublicationBiasBenchmark/news/index.html","id":"publicationbiasbenchmark-010","dir":"Changelog","previous_headings":"","what":"PublicationBiasBenchmark 0.1.0","title":"PublicationBiasBenchmark 0.1.0","text":"Initial CRAN submission.","code":""}]
